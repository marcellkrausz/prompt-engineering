{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4fbd997",
   "metadata": {},
   "source": [
    "_Optimizing a Prompt for Production:_\n",
    "# Social Media Posts\n",
    "\n",
    "Task: Write a social post given an insight and a social network.\n",
    "\n",
    "`insight, social_network -> social_post`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c60a14e",
   "metadata": {},
   "source": [
    "### 0. Naive Prompt\n",
    "Start with simple instructions to establish the baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be05dc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "- insight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "- social_network: Twitter\n",
      "\n",
      "Output:\n",
      "ðŸš€ As AI models get smarter, the need for #PromptEngineering wonâ€™t fade! Just like genius humans rely on legal, HR, and management for alignment with business goals, weâ€™ll need skilled prompts to harness AIâ€™s potential effectively. ðŸ¤–ðŸ’¡ Let's ensure innovation meets strategy! #AI #BusinessAlignment #FutureOfWork\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "def get_completion(prompt, context):\n",
    "    client = openai.OpenAI()\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt.format(**context)}\n",
    "        ],\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "naive_prompt = \"Write a social media post about how {insight}, for {social_network}.\"\n",
    "context = {\n",
    "    \"insight\": \"prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\",\n",
    "    \"social_network\": \"Twitter\"\n",
    "}\n",
    "\n",
    "social_post = get_completion(naive_prompt, context)\n",
    "print(\"Input:\")\n",
    "for key, value in context.items():\n",
    "    print(f\"- {key}: {value}\")\n",
    "print(f\"\\nOutput:\\n{social_post}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7d766c",
   "metadata": {},
   "source": [
    "### 1. Give Direction \n",
    "Describe the desired style in detail, or reference a relevant persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c2c42b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output:\n",
      "ðŸ§ âœ¨ Even as AI models evolve, prompt engineering remains essential! Just like even the brightest geniuses need a nudge from HR or management to stay aligned with business goals, smart models need that same guidance. Think of it as the â€œmaverick artistâ€ vibeâ€”unfettered creativity is amazing, but a solid brief helps keep the masterpiece on track. ðŸŽ¨ðŸš€\n",
      "\n",
      "Imagine if Beethoven had no deadlines or direction; we mightâ€™ve ended up with a symphony of chaos instead of *Ode to Joy*. ðŸŽ¶ So, as we push the limits of AI, letâ€™s remember: great prompts bridge the gap between brilliance and business strategy.\n",
      "\n",
      "Whatâ€™s your take? Are we the conductors or merely the audience? ðŸŽ­ #PromptEngineering #AI #BusinessAlignment\n"
     ]
    }
   ],
   "source": [
    "direction_prompt = \"\"\"\"Write a social media post about how {insight}, for {social_network}, in the style of Malcolm Gladwell.\n",
    "\n",
    "The social post should sound authentically human and colloquial, while being practically useful and brief. Be very creative and make niche references to sound more human. To maximize engagement, the content should be surprising, interesting, or practically useful, or induce high-arousal emotions such as anxiety, anger, awe, or surprise.\"\"\"\n",
    "\n",
    "social_post_a = get_completion(direction_prompt, context)\n",
    "print(f\"\\nOutput:\\n{social_post_a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639f8755",
   "metadata": {},
   "source": [
    "### 2. Specify Format\n",
    "Define what rules to follow, and the required structure of the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4d7b716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output:\n",
      "```yaml\n",
      "bait: \"Even the smartest AIs will still need a nudge. Why? Because genius alone isnâ€™t enough.\"\n",
      "hook: \"Just like top-tier CEOs rely on legal and HR teams for delicate decisions, our most advanced models will require 'prompt engineers' to guide their brilliance. In a world where alignment with business interests is crucial, who will drive the conversation?\"\n",
      "reward: \"Studies show that 70% of corporate decisions fail due to misalignment of stakeholder interests. In this complex landscape, the right prompts can be the difference between innovation and chaos.\"\n",
      "post_content: \"Even the smartest AIs will still need a nudge. Why? Because genius alone isnâ€™t enough. Just like top-tier CEOs rely on legal and HR teams for delicate decisions, our most advanced models will require 'prompt engineers' to guide their brilliance. In a world where alignment with business interests is crucial, who will drive the conversation? Studies show that 70% of corporate decisions fail due to misalignment of stakeholder interests. In this complex landscape, the right prompts can be the difference between innovation and chaos.\"\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "format_prompt = \"\"\"\"Write a social media post about how {insight}, for {social_network}, in the style of Malcolm Gladwell, using the Bait, Hook, Reward framework.\n",
    "\n",
    "- **bait**: Grab the attention of the person browsing social media. This could be a contrarian statement, appeal to identity, celebrity name, or anything else that stops them scrolling.\n",
    "- **hook**: Keep their attention now you have it. Show this post is relevant to them, by alerting them to an issue, using familiar words, or providing social proof to keep them reading.\n",
    "- **reward**: Compensate them for their attention to elicit reciprocation. Is there any useful information, a surprising statistic, or an interesting anecdote to reveal? Or a threat to make?\n",
    "- **post_content**: The main content of the post, incorporating the bait, hook, and reward in a way that resonates with the reader and engages their attention.\n",
    "\n",
    "First decide on the bait, hook, and reward, before writing the post_content.\n",
    "\n",
    "## Instructions\n",
    "The social post should sound authentically human and colloquial, while being practically useful and brief. Be very creative and make niche references to sound more human. To maximize engagement, the content should be surprising, interesting, or practically useful, or induce high-arousal emotions such as anxiety, anger, awe, or surprise.\n",
    "\n",
    "Follow best practices for posting engaging content on {social_network}, but do not use emoji or hashtags.\n",
    "Provide citations for any statistics included. Do not reference the work of Malcolm Gladwell.\n",
    "Respond in YAML with the following keys:\n",
    "- bait\n",
    "- hook\n",
    "- reward\n",
    "- post_content\"\"\"\n",
    "\n",
    "social_post_b = get_completion(format_prompt, context)\n",
    "print(f\"\\nOutput:\\n{social_post_b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c402c6c2",
   "metadata": {},
   "source": [
    "### 3. Provide Examples\n",
    "Insert a diverse set of test cases where the task was done correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8826d30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "- insight: overqualified students take service jobs\n",
      "- social_network: Facebook\n",
      "- bait: Use the trope that smart people are so focused they fail to look after themselves.\n",
      "- hook: Particle Physics is a subject that is universally associated with smart people.\n",
      "- reward: Fantasizing about being somewhere remote where you can earn money while focusing on your work.\n",
      "- post_content: Meet Jon. He has been working the night shift at our hotel for over a month already, and he says the best part is the peace and quiet. Particle physics, which is the topic of Jon's Masters Thesis, requires concentration. That's fine by us. So long as our guests can count on Jon, he can count all the particles he wants (or whatever it is that particle physicists do).\n",
      "\n",
      "Example 2:\n",
      "- insight: there's no such thing as a wasted trip\n",
      "- social_network: Instagram\n",
      "- bait: Mentioning a 'wasted trip' will get the attention of people who like to travel, and for whom wasting a trip would be upsetting.\n",
      "- hook: Talk about a rainy day in a hot location like Kauai, which most people would complain about because they're wasting time inside.\n",
      "- reward: An anecdote that reveals that good things can happen when you least expect them.\n",
      "- post_content: There's no such thing as a wasted trip! On this rainy day in Kauai 2 years ago I met my bestie @moniqueontour and we've been on 4 amazing adventures together since.\n",
      "\n",
      "Example 3:\n",
      "- insight: mould your business to your own preferences\n",
      "- social_network: LinkedIn\n",
      "- bait: Most self-help advice focuses on fixing weaknesses, but instead let's focus on how to reframe weaknesses into strengths.\n",
      "- hook: We need to make it clear this post is for business owners, and that you are speaking from experience, establishing connection and credibility.\n",
      "- reward: The fact that 60% of new business came from the blog is a statistic they can take away and use as evidence to support their own strategy, or to share with their wider network.\n",
      "- post_content: Don't try to mold yourself into the person you think your business needs you to be, build your business around who you actually are. When I started my agency business, I hated networking. I'm introverted by nature  so I wrote blog posts instead â€“ eventually 60% of my agency's new business came from our blog.\n",
      "\n",
      "Example 4:\n",
      "- insight: whales are in danger and most people don't know\n",
      "- social_network: Twitter\n",
      "- bait: People who care about whales or animals will pay attention when whales are mentioned.\n",
      "- hook: If we refer to the whales as \"in danger\" people who care will want to know more.\n",
      "- reward: Some species of whales are going extinct, and people would benefit from knowing.\n",
      "- post_content: The whales are in danger of extinction. Many people aren't aware, which is why it's so important to bring awareness to this cause. Together with a few colleagues, we'll be running the London marathon next week in aid of the \"Save the Whales\" foundation, and any support would be appreciated.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "examples_prompt = \"\"\"\"Write a social media post about how {insight}, for {social_network}, in the style of Malcolm Gladwell, using the Bait, Hook, Reward framework.\n",
    "\n",
    "- **bait**: Grab the attention of the person browsing social media. This could be a contrarian statement, appeal to identity, celebrity name, or anything else that stops them scrolling.\n",
    "- **hook**: Keep their attention now you have it. Show this post is relevant to them, by alerting them to an issue, using familiar words, or providing social proof to keep them reading.\n",
    "- **reward**: Compensate them for their attention to elicit reciprocation. Is there any useful information, a surprising statistic, or an interesting anecdote to reveal? Or a threat to make?\n",
    "- **post_content**: The main content of the post, incorporating the bait, hook, and reward in a way that resonates with the reader and engages their attention.\n",
    "\n",
    "First decide on the bait, hook, and reward, before writing the post_content.\n",
    "\n",
    "## Examples\n",
    "{examples_partial}\n",
    "\n",
    "## Instructions\n",
    "The social post should sound authentically human and colloquial, while being practically useful and brief. Be very creative and make niche references to sound more human. To maximize engagement, the content should be surprising, interesting, or practically useful, or induce high-arousal emotions such as anxiety, anger, awe, or surprise.\n",
    "\n",
    "Follow best practices for posting engaging content on {social_network}, but do not use emoji or hashtags.\n",
    "Provide citations for any statistics included. Do not reference the work of Malcolm Gladwell.\n",
    "Respond in YAML with the following keys:\n",
    "- bait\n",
    "- hook\n",
    "- reward\n",
    "- post_content\"\"\"\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"insight\": \"overqualified students take service jobs\",\n",
    "        \"social_network\": \"Facebook\",\n",
    "        \"bait\": \"Use the trope that smart people are so focused they fail to look after themselves.\",\n",
    "        \"hook\": \"Particle Physics is a subject that is universally associated with smart people.\",\n",
    "        \"reward\": \"Fantasizing about being somewhere remote where you can earn money while focusing on your work.\",\n",
    "        \"post_content\": \"Meet Jon. He has been working the night shift at our hotel for over a month already, and he says the best part is the peace and quiet. Particle physics, which is the topic of Jon's Masters Thesis, requires concentration. That's fine by us. So long as our guests can count on Jon, he can count all the particles he wants (or whatever it is that particle physicists do).\"\n",
    "    },\n",
    "    {\n",
    "        \"insight\": \"there's no such thing as a wasted trip\",\n",
    "        \"social_network\": \"Instagram\",\n",
    "        \"bait\": \"Mentioning a 'wasted trip' will get the attention of people who like to travel, and for whom wasting a trip would be upsetting.\",\n",
    "        \"hook\": \"Talk about a rainy day in a hot location like Kauai, which most people would complain about because they're wasting time inside.\",\n",
    "        \"reward\": \"An anecdote that reveals that good things can happen when you least expect them.\",\n",
    "        \"post_content\": \"There's no such thing as a wasted trip! On this rainy day in Kauai 2 years ago I met my bestie @moniqueontour and we've been on 4 amazing adventures together since.\"\n",
    "    },\n",
    "    {\n",
    "        \"insight\": \"mould your business to your own preferences\",\n",
    "        \"social_network\": \"LinkedIn\",\n",
    "        \"bait\": \"Most self-help advice focuses on fixing weaknesses, but instead let's focus on how to reframe weaknesses into strengths.\",\n",
    "        \"hook\": \"We need to make it clear this post is for business owners, and that you are speaking from experience, establishing connection and credibility.\",\n",
    "        \"reward\": \"The fact that 60% of new business came from the blog is a statistic they can take away and use as evidence to support their own strategy, or to share with their wider network.\",\n",
    "        \"post_content\": \"Don't try to mold yourself into the person you think your business needs you to be, build your business around who you actually are. When I started my agency business, I hated networking. I'm introverted by nature  so I wrote blog posts instead â€“ eventually 60% of my agency's new business came from our blog.\"\n",
    "    },\n",
    "    {\n",
    "        \"insight\": \"whales are in danger and most people don't know\",\n",
    "        \"social_network\": \"Twitter\",\n",
    "        \"bait\": \"People who care about whales or animals will pay attention when whales are mentioned.\",\n",
    "        \"hook\": \"If we refer to the whales as \\\"in danger\\\" people who care will want to know more.\",\n",
    "        \"reward\": \"Some species of whales are going extinct, and people would benefit from knowing.\",\n",
    "        \"post_content\": \"The whales are in danger of extinction. Many people aren't aware, which is why it's so important to bring awareness to this cause. Together with a few colleagues, we'll be running the London marathon next week in aid of the \\\"Save the Whales\\\" foundation, and any support would be appreciated.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Convert examples to a partial string\n",
    "examples_partial = \"\"\n",
    "for i, example in enumerate(examples, 1):\n",
    "    examples_partial += f\"Example {i}:\\n\"\n",
    "    for key, value in example.items():\n",
    "        examples_partial += f\"- {key}: {value}\\n\"\n",
    "    examples_partial += \"\\n\"\n",
    "\n",
    "print(examples_partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b5c43d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output:\n",
      "```yaml\n",
      "bait: Even the smartest AI will need a nudge from us mere mortals.\n",
      "hook: Just like genius humans rely on guidance from HR and leadership to align with business goals, advanced AI models won't escape the necessity of prompt engineering.\n",
      "reward: Studies show that structured input can elevate AI output quality by up to 35%. In a world where every prompt matters, the role of human intuition becomes even more crucial.\n",
      "post_content: Even the smartest AI will need a nudge from us mere mortals. Just as genius thinkers stumble without guidance from HR, legal, and management, the latest AI marvels can't navigate complex business interests alone. A recent study revealed that structured input can boost AI output quality by as much as 35%. As we embrace smarter models, remember: the art of prompt engineering is not only here to stayâ€”itâ€™s evolution's frontline. Don't underestimate the power of a well-crafted prompt. It could be the key to unlocking groundbreaking insights and alignment in your organization. \n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Add examples_partial to the context\n",
    "examples_context = {\n",
    "    \"examples_partial\": examples_partial,\n",
    "    \"social_network\": \"Twitter\",\n",
    "    \"insight\": \"prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\"\n",
    "}\n",
    "\n",
    "social_post_c = get_completion(examples_prompt, examples_context)\n",
    "print(f\"\\nOutput:\\n{social_post_c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a843ad13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Emoji Evaluation:\n",
      "Has emojis: False\n",
      "Emoji count: 0\n",
      "Emojis found: None\n"
     ]
    }
   ],
   "source": [
    "# Define a function to check for emojis in the post content\n",
    "def check_for_emojis(post_content):\n",
    "    import re\n",
    "    \n",
    "    # Regular expression pattern to match emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001F910-\\U0001F93A\"  # Additional range including ðŸ¤” (U+1F914)\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    # Check if there are any emojis in the post content\n",
    "    emojis_found = emoji_pattern.findall(post_content)\n",
    "    \n",
    "    return {\n",
    "        \"has_emojis\": len(emojis_found) > 0,\n",
    "        \"emoji_count\": len(emojis_found),\n",
    "        \"emojis\": emojis_found\n",
    "    }\n",
    "\n",
    "# Evaluate the presence of emojis in the generated social post\n",
    "emoji_evaluation = check_for_emojis(social_post_c)\n",
    "print(\"\\nEmoji Evaluation:\")\n",
    "print(f\"Has emojis: {emoji_evaluation['has_emojis']}\")\n",
    "print(f\"Emoji count: {emoji_evaluation['emoji_count']}\")\n",
    "print(f\"Emojis found: {', '.join(emoji_evaluation['emojis']) if emoji_evaluation['emojis'] else 'None'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c983858a",
   "metadata": {},
   "source": [
    "### 4. Evaluate Quality\n",
    "Identify errors and rate responses, testing what drives performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff92eccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engagement Evaluation:\n",
      "```yaml\n",
      "Analysis: |\n",
      "  The post effectively leverages relevant insights about the necessity of prompt engineering when working with advanced AI models, highlighting the human role in this process. It grabs attention by emphasizing the contrast between \"smart AI\" and \"mere mortals,\" which can resonate with a wide audience interested in AI. The hook is present, as it keeps the reader engaged by discussing the importance of structured input and its potential impact on AI output quality.\n",
      "\n",
      "  The reward includes the promise of groundbreaking insights and organizational alignment, motivating readers to consider their approach to AI. The post is tailored for Twitter, where concise, thought-provoking content performs well. However, the statistic claiming that structured input can improve AI output by 35% raises concerns. Without citing a credible source, it could be considered inaccurate or unverified, leading to a potential hallucination, which is detrimental to credibility and overall engagement.\n",
      "\n",
      "  Lastly, the tone of the post is authentic and conversational, making it relatable to users on social media. However, the incorrect usage of a statistic detracts from its overall effectiveness.\n",
      "\n",
      "Rating: 3\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Define a function to evaluate the engagement potential of a social media post\n",
    "def evaluate_engagement(post_content, insight, social_network):\n",
    "    evaluation_prompt = f\"\"\"\n",
    "    You are an expert social media analyst. Your task is to evaluate the following social media post and predict its engagement potential. Consider factors such as:\n",
    "    - Insight: Does the post use the relevant insight?\n",
    "    - Bait: Does it grab attention?\n",
    "    - Hook: Does it keep the attention?\n",
    "    - Reward: Does it compensate for the attention?\n",
    "    - Social Network: Does it follow best practices for the social network?\n",
    "    - Hallucination: Are any statistics accurate?\n",
    "    - Human: Is the post authentically human-sounding?\n",
    "\n",
    "    Insight: {insight}\n",
    "    Social Network: {social_network}\n",
    "    Post content:\n",
    "    \"{post_content}\"\n",
    "\n",
    "    Based on these factors, rate the post's engagement potential on a scale of 1-5, where 1 is very low engagement, and 5 is very high engagement. Provide a brief explanation for your rating. Any posts that contain hallucinations or made up statistics should be ranked 0.\n",
    "\n",
    "    Output your response in YAML with the following keys:\n",
    "    - Analysis: [Your analysis]\n",
    "    - Rating: [Your rating]\n",
    "    \"\"\"\n",
    "    evaluation_context = {\n",
    "        \"post_content\": post_content,\n",
    "        \"insight\": insight,\n",
    "        \"social_network\": social_network\n",
    "    }\n",
    "\n",
    "    engagement_evaluation = get_completion(evaluation_prompt, evaluation_context)\n",
    "    return engagement_evaluation\n",
    "\n",
    "# strip out the bait, hook, reward from social_post_c\n",
    "post_content = social_post_c.split(\"post_content:\")[1].strip()\n",
    "\n",
    "# Evaluate the engagement potential of the generated social post\n",
    "engagement_result = evaluate_engagement(post_content, context[\"insight\"], context[\"social_network\"])\n",
    "print(\"Engagement Evaluation:\")\n",
    "print(engagement_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d3b36c",
   "metadata": {},
   "source": [
    "### 5. Divide Labor \n",
    "Split tasks into multiple steps, chained together for complex goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe28a6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post 1:\n",
      "Content: Even the most advanced AI systems will still need \"prompt engineering\" to thriveâ€”just like brilliant humans depend on guidance from HR, legal, and management to navigate complex business landscapes. Itâ€™s a stark reminder that clarity and alignment are vital, whether youâ€™re a seasoned pro or a cutting-edge model. Brace yourselves: research shows that 80% of projects fail due to communication breakdowns. As we lean into this new era of smart tech, let's not forget the art of promptingâ€”because the clearer the question, the better the answer. \n",
      "```\n",
      "Rating: 4\n",
      "\n",
      "Post 2:\n",
      "Content: Genius AI won't eliminate the need for promptingâ€”just ask any executive. Even the smartest humans require guidance from legal, HR, and management to align with business goals. If humans need prompting, why would we think LLMs are any different? Research shows that 80% of successful businesses leverage structured communication to optimize performance. So, in a world of smarter models, prompt engineering will be vitalâ€”think of it as the instruction manual for AI's genius. Don't overlook the art of asking the right questions; it's how we unlock the full potential of technology.\n",
      "```\n",
      "Rating: 4\n",
      "\n",
      "Post 3:\n",
      "Content: Even the smartest AI needs a nudgeâ€”just like us. As models grow more sophisticated, we might think theyâ€™ll operate on autopilot, requiring little input. But consider this: icons like Steve Jobs and Elon Musk wouldnâ€™t have transformed their industries without critical promptings from their legal and HR teams to align their revolutionary ideas with business interests. In fact, studies show that a staggering 80% of successful projects thrive on cross-departmental feedback. Relying solely on tech can blind us to the art of promptingâ€”it's essential for steering innovation in the right direction. So, as we embrace smarter models, letâ€™s not forget the power of a well-timed question or insight. They might just hold the key to our next breakthrough.\n",
      "```\n",
      "Rating: 3\n",
      "\n",
      "Post 4:\n",
      "Content: Hereâ€™s a thought: even genius models like ChatGPT need careful prompting to ensure they meet business goals. Just as the brightest humans rely on legal and HR experts to navigate the complexities of the workplace, AI needs structured guidance to align with organizational interests. In fact, studies show that companies skilled in prompt engineering enjoy a whopping 30% increase in cross-departmental alignment. So, as we embrace smarter models, let's remember the power of clear, thoughtful prompts that bridge the gap between raw intelligence and real-world application. Donâ€™t let the tech do all the talkingâ€”your insights are crucial in shaping the conversation. \n",
      "```\n",
      "Rating: 3\n",
      "\n",
      "Post 5:\n",
      "Content: Even the most advanced AI models aren't infallible. Just like brilliant humans often need checks from HR, legal, or management, these smart systems will need imagination and oversight too. As we embrace AI's potential, donâ€™t overlook the art of prompt engineering. It ensures our tech acts in harmony with our values. A recent study shows that 75% of AI misuses stem from poor guidelines. Donâ€™t let our digital geniuses run wild; prompt engineering will be crucial for a balanced future. \n",
      "```\n",
      "Rating: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply() # to run in jupyter notebook\n",
    "\n",
    "\n",
    "async def generate_and_evaluate_post(prompt, context):\n",
    "    response = await asyncio.to_thread(get_completion, prompt, context)\n",
    "    post_content = response.split(\"post_content:\")[1].strip()\n",
    "    evaluation = await asyncio.to_thread(evaluate_engagement, post_content, context[\"insight\"], context[\"social_network\"])\n",
    "    \n",
    "    # Parse the YAML output with regex\n",
    "    rating = int(re.findall(r'Rating: (\\d+)', evaluation)[0])\n",
    "    \n",
    "    return {\n",
    "        \"content\": post_content,\n",
    "        \"rating\": rating\n",
    "    }\n",
    "\n",
    "async def generate_and_rank_desc(prompt, context, num_posts=5):\n",
    "    tasks = [generate_and_evaluate_post(prompt, context) for _ in range(num_posts)]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    \n",
    "    # Sort posts by rating in descending order\n",
    "    sorted_posts = sorted(results, key=lambda x: x[\"rating\"], reverse=True)\n",
    "    \n",
    "    return sorted_posts\n",
    "\n",
    "# Run the async function\n",
    "ranked_posts = asyncio.run(generate_and_rank_desc(examples_prompt, examples_context))\n",
    "\n",
    "# Print content and ratings for all posts\n",
    "for i, post in enumerate(ranked_posts, 1):\n",
    "    print(f\"Post {i}:\")\n",
    "    print(f\"Content: {post['content']}\")\n",
    "    print(f\"Rating: {post['rating']}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114195fe",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Advanced Optimization\n",
    "\n",
    "### A/B Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e34a7d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt A average rating: 3.67\n",
      "Prompt B average rating: 3.57\n"
     ]
    }
   ],
   "source": [
    "async def ab_test_prompts(prompt_a, prompt_b, context, num_runs=10):\n",
    "    tasks_a = [generate_and_evaluate_post(prompt_a, context) for _ in range(num_runs)]\n",
    "    tasks_b = [generate_and_evaluate_post(prompt_b, context) for _ in range(num_runs)]\n",
    "    \n",
    "    results_a = await asyncio.gather(*tasks_a)\n",
    "    results_b = await asyncio.gather(*tasks_b)\n",
    "\n",
    "    avg_rating_a = sum(post['rating'] for post in results_a) / len(results_a)\n",
    "    avg_rating_b = sum(post['rating'] for post in results_b) / len(results_b)\n",
    "\n",
    "    print(f\"Prompt A average rating: {avg_rating_a:.2f}\")\n",
    "    print(f\"Prompt B average rating: {avg_rating_b:.2f}\")\n",
    "\n",
    "    return results_a, results_b\n",
    "\n",
    "examples_prompt_b = \"\"\"\"Write a social media post about how {insight}, for {social_network}, in the style of Malcolm Tucker, using the Bait, Hook, Reward framework.\n",
    "\n",
    "- **bait**: Grab the attention of the person browsing social media. This could be a contrarian statement, appeal to identity, celebrity name, or anything else that stops them scrolling.\n",
    "- **hook**: Keep their attention now you have it. Show this post is relevant to them, by alerting them to an issue, using familiar words, or providing social proof to keep them reading.\n",
    "- **reward**: Compensate them for their attention to elicit reciprocation. Is there any useful information, a surprising statistic, or an interesting anecdote to reveal? Or a threat to make?\n",
    "- **post_content**: The main content of the post, incorporating the bait, hook, and reward in a way that resonates with the reader and engages their attention.\n",
    "\n",
    "First decide on the bait, hook, and reward, before writing the post_content.\n",
    "\n",
    "## Examples\n",
    "{examples_partial}\n",
    "\n",
    "## Instructions\n",
    "The social post should sound authentically human and colloquial, while being practically useful and brief. Be very creative and make niche references to sound more human. To maximize engagement, the content should be surprising, interesting, or practically useful, or induce high-arousal emotions such as anxiety, anger, awe, or surprise.\n",
    "\n",
    "Follow best practices for posting engaging content on {social_network}, but do not use emoji or hashtags.\n",
    "Provide citations for any statistics included. Do not reference the work of Malcolm Tucker.\n",
    "Respond in YAML with the following keys:\n",
    "- bait\n",
    "- hook\n",
    "- reward\n",
    "- post_content\"\"\"\n",
    "\n",
    "results_a, results_b = asyncio.run(ab_test_prompts(examples_prompt, examples_prompt_b, examples_context, num_runs=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfcf013b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': '\"Think smarter models mean the end of prompt engineering? Wrong. Even the sharpest genius needs guidanceâ€”just like models need human alignment to dodge legal landmines and HR hiccups. Companies investing in prompt engineering see efficiency boosts of up to 30%. So, are you ready to automate chaos or let it reign? #ProTip: The best time to get your act together was yesterday. The next best is today.\"\\n```', 'rating': 4}\n"
     ]
    }
   ],
   "source": [
    "print(results_b[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ed9c79",
   "metadata": {},
   "source": [
    "### DSPy Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22c64aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline post (without optimization):\n",
      "```yaml\n",
      "post:\n",
      "  content: \"Even as AI models become smarter, prompt engineering remains crucial! Just like genius humans need guidance from legal, HR, and management to align with business interests, AI needs the right prompts to deliver value. Let's keep the conversation going on how we can effectively harness AI! #AI #PromptEngineering #BusinessAlignment\"\n",
      "  hashtags:\n",
      "    - AI\n",
      "    - PromptEngineering\n",
      "    - BusinessAlignment\n",
      "```\n",
      "Baseline post quality score: 4.0\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "# Define the task using DSPy\n",
    "class SocialMediaPostGenerator(dspy.Signature):\n",
    "    \"\"\"Generate a social media post based on an insight and social network.\"\"\"\n",
    "    insight = dspy.InputField()\n",
    "    social_network = dspy.InputField()\n",
    "    post = dspy.OutputField(desc=\"Generated social media post in YAML format\")\n",
    "\n",
    "# Create a DSPy program\n",
    "class GeneratePost(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.gen = dspy.ChainOfThought(SocialMediaPostGenerator)\n",
    "\n",
    "    def forward(self, insight, social_network):\n",
    "        return self.gen(insight=insight, social_network=social_network)\n",
    "\n",
    "# Create a DSPy metric\n",
    "def post_quality_metric(gold, pred, trace=None):\n",
    "    evaluation_result = evaluate_engagement(pred.post, gold.insight, gold.social_network)\n",
    "    \n",
    "    # Extract the rating from the YAML-formatted string using regex\n",
    "    try:\n",
    "        match = re.search(r'Rating:\\s*(\\d+(?:\\.\\d+)?)', evaluation_result)\n",
    "        if match:\n",
    "            rating = float(match.group(1))\n",
    "        else:\n",
    "            rating = 0.0\n",
    "        return rating\n",
    "    except:\n",
    "        # If there's any error in parsing, return 0\n",
    "        return 0.0\n",
    "\n",
    "# Set up the language model\n",
    "gpt_4o_mini = dspy.LM(model='gpt-4o-mini')\n",
    "dspy.settings.configure(lm=gpt_4o_mini)\n",
    "\n",
    "# Run the model without training to establish a baseline\n",
    "baseline_model = GeneratePost()\n",
    "\n",
    "print(\"Baseline post (without optimization):\")\n",
    "baseline_post = baseline_model(\n",
    "    insight=context[\"insight\"],\n",
    "    social_network=context[\"social_network\"]\n",
    ")\n",
    "print(baseline_post.post)\n",
    "\n",
    "gold = dspy.Example(\n",
    "    insight=context[\"insight\"],\n",
    "    social_network=context[\"social_network\"],\n",
    "    post=\"\"  # We don't have a gold post, so leave it empty\n",
    ")\n",
    "\n",
    "print(\"Baseline post quality score:\", post_quality_metric(gold, baseline_post))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea396358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to sample between 1 and 4 traces per predictor.\n",
      "Will attempt to bootstrap 16 candidate sets.\n",
      "Average Metric: 40.00 / 10 (400.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/20 18:58:39 INFO dspy.evaluate.evaluate: Average Metric: 40.0 / 10 (400.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best score: 400.0 for seed -3\n",
      "Scores so far: [400.0]\n",
      "Best score so far: 400.0\n",
      "Average Metric: 42.00 / 10 (420.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/20 18:58:49 INFO dspy.evaluate.evaluate: Average Metric: 42.0 / 10 (420.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best score: 420.0 for seed -2\n",
      "Scores so far: [400.0, 420.0]\n",
      "Best score so far: 420.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 4/20 [00:21<01:25,  5.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Average Metric: 36.00 / 10 (360.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:12<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/20 18:59:23 INFO dspy.evaluate.evaluate: Average Metric: 36.0 / 10 (360.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [400.0, 420.0, 360.0]\n",
      "Best score so far: 420.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 4/20 [00:22<01:30,  5.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Average Metric: 41.00 / 10 (410.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:11<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/20 18:59:58 INFO dspy.evaluate.evaluate: Average Metric: 41.0 / 10 (410.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [400.0, 420.0, 360.0, 410.0]\n",
      "Best score so far: 420.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 2/20 [00:12<01:52,  6.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Average Metric: 36.00 / 10 (360.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:12<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/20 19:00:23 INFO dspy.evaluate.evaluate: Average Metric: 36.0 / 10 (360.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [400.0, 420.0, 360.0, 410.0, 360.0]\n",
      "Best score so far: 420.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 1/20 [00:04<01:31,  4.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Average Metric: 40.00 / 10 (400.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:10<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/20 19:00:38 INFO dspy.evaluate.evaluate: Average Metric: 40.0 / 10 (400.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [400.0, 420.0, 360.0, 410.0, 360.0, 400.0]\n",
      "Best score so far: 420.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 2/20 [00:13<02:05,  6.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Average Metric: 41.00 / 10 (410.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:10<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/20 19:01:03 INFO dspy.evaluate.evaluate: Average Metric: 41.0 / 10 (410.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [400.0, 420.0, 360.0, 410.0, 360.0, 400.0, 410.0]\n",
      "Best score so far: 420.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 2/20 [00:12<01:48,  6.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Average Metric: 42.00 / 10 (420.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:09<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/20 19:01:24 INFO dspy.evaluate.evaluate: Average Metric: 42.0 / 10 (420.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [400.0, 420.0, 360.0, 410.0, 360.0, 400.0, 410.0, 420.0]\n",
      "Best score so far: 420.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 3/20 [00:22<02:06,  7.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Average Metric: 43.00 / 10 (430.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/20 19:01:55 INFO dspy.evaluate.evaluate: Average Metric: 43.0 / 10 (430.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best score: 430.0 for seed 5\n",
      "Scores so far: [400.0, 420.0, 360.0, 410.0, 360.0, 400.0, 410.0, 420.0, 430.0]\n",
      "Best score so far: 430.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 1/20 [00:05<01:46,  5.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Average Metric: 37.00 / 10 (370.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:11<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/20 19:02:13 INFO dspy.evaluate.evaluate: Average Metric: 37.0 / 10 (370.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [400.0, 420.0, 360.0, 410.0, 360.0, 400.0, 410.0, 420.0, 430.0, 370.0]\n",
      "Best score so far: 430.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 3/20 [00:23<02:12,  7.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Average Metric: 44.00 / 10 (440.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:11<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/20 19:02:48 INFO dspy.evaluate.evaluate: Average Metric: 44.0 / 10 (440.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best score: 440.0 for seed 7\n",
      "Scores so far: [400.0, 420.0, 360.0, 410.0, 360.0, 400.0, 410.0, 420.0, 430.0, 370.0, 440.0]\n",
      "Best score so far: 440.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 2/20 [00:17<02:38,  8.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Average Metric: 40.00 / 10 (400.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:12<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/20 19:03:18 INFO dspy.evaluate.evaluate: Average Metric: 40.0 / 10 (400.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [400.0, 420.0, 360.0, 410.0, 360.0, 400.0, 410.0, 420.0, 430.0, 370.0, 440.0, 400.0]\n",
      "Best score so far: 440.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 4/20 [00:25<01:42,  6.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Average Metric: 42.00 / 10 (420.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/20 19:03:52 INFO dspy.evaluate.evaluate: Average Metric: 42.0 / 10 (420.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [400.0, 420.0, 360.0, 410.0, 360.0, 400.0, 410.0, 420.0, 430.0, 370.0, 440.0, 400.0, 420.0]\n",
      "Best score so far: 440.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 1/20 [00:05<01:35,  5.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Average Metric: 35.00 / 10 (350.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:09<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/20 19:04:07 INFO dspy.evaluate.evaluate: Average Metric: 35.0 / 10 (350.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [400.0, 420.0, 360.0, 410.0, 360.0, 400.0, 410.0, 420.0, 430.0, 370.0, 440.0, 400.0, 420.0, 350.0]\n",
      "Best score so far: 440.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 4/20 [00:36<02:24,  9.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Average Metric: 38.00 / 10 (380.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:09<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/20 19:04:53 INFO dspy.evaluate.evaluate: Average Metric: 38.0 / 10 (380.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [400.0, 420.0, 360.0, 410.0, 360.0, 400.0, 410.0, 420.0, 430.0, 370.0, 440.0, 400.0, 420.0, 350.0, 380.0]\n",
      "Best score so far: 440.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 4/20 [00:22<01:30,  5.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Average Metric: 39.00 / 10 (390.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:09<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/20 19:05:24 INFO dspy.evaluate.evaluate: Average Metric: 39.0 / 10 (390.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [400.0, 420.0, 360.0, 410.0, 360.0, 400.0, 410.0, 420.0, 430.0, 370.0, 440.0, 400.0, 420.0, 350.0, 380.0, 390.0]\n",
      "Best score so far: 440.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 3/20 [00:19<01:48,  6.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Average Metric: 42.00 / 10 (420.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:09<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/20 19:05:53 INFO dspy.evaluate.evaluate: Average Metric: 42.0 / 10 (420.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [400.0, 420.0, 360.0, 410.0, 360.0, 400.0, 410.0, 420.0, 430.0, 370.0, 440.0, 400.0, 420.0, 350.0, 380.0, 390.0, 420.0]\n",
      "Best score so far: 440.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 1/20 [00:07<02:18,  7.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Average Metric: 41.00 / 10 (410.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/20 19:06:08 INFO dspy.evaluate.evaluate: Average Metric: 41.0 / 10 (410.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [400.0, 420.0, 360.0, 410.0, 360.0, 400.0, 410.0, 420.0, 430.0, 370.0, 440.0, 400.0, 420.0, 350.0, 380.0, 390.0, 420.0, 410.0]\n",
      "Best score so far: 440.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 2/20 [00:11<01:40,  5.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Average Metric: 35.00 / 10 (350.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:09<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/20 19:06:29 INFO dspy.evaluate.evaluate: Average Metric: 35.0 / 10 (350.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [400.0, 420.0, 360.0, 410.0, 360.0, 400.0, 410.0, 420.0, 430.0, 370.0, 440.0, 400.0, 420.0, 350.0, 380.0, 390.0, 420.0, 410.0, 350.0]\n",
      "Best score so far: 440.0\n",
      "19 candidate programs found.\n",
      "Optimized post:\n",
      "\"Donâ€™t be fooledâ€”smarter AI still needs prompt engineering! Just like genius humans rely on legal and HR for guidance, AI models need clear prompts to align with business interests. Without them, even the best tech can miss the mark. Letâ€™s keep our AI on track! #AI #PromptEngineering #BusinessGoals\"\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "# Prepare the dataset\n",
    "trainset = [\n",
    "    dspy.Example(\n",
    "        insight=context['insight'],\n",
    "        social_network=context['social_network'],\n",
    "        post=post['content']\n",
    "    ).with_inputs('insight', 'social_network')\n",
    "    for post in results_b[:20]  # Use first 20 examples for training\n",
    "]\n",
    "\n",
    "devset = [\n",
    "    dspy.Example(\n",
    "        insight=context['insight'],\n",
    "        social_network=context['social_network'],\n",
    "        post=post['content']\n",
    "    ).with_inputs('insight', 'social_network')\n",
    "    for post in results_b[20:]  # Use remaining examples for validation\n",
    "]\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = BootstrapFewShotWithRandomSearch(metric=post_quality_metric)\n",
    "\n",
    "# Compile the program\n",
    "compiled_model = optimizer.compile(\n",
    "    GeneratePost(),\n",
    "    trainset=trainset,\n",
    "    valset=devset,\n",
    ")\n",
    "\n",
    "# Now you can use the compiled model to generate optimized posts\n",
    "optimized_post = compiled_model(\n",
    "    insight=context[\"insight\"],\n",
    "    social_network=context[\"social_network\"]\n",
    ")\n",
    "\n",
    "print(\"Optimized post:\")\n",
    "print(optimized_post.post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2cbccdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-04-20T19:06:29.009895]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `insight` (str)\n",
      "2. `social_network` (str)\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `post` (str): Generated social media post in YAML format\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## insight ## ]]\n",
      "{insight}\n",
      "\n",
      "[[ ## social_network ## ]]\n",
      "{social_network}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## post ## ]]\n",
      "{post}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Generate a social media post based on an insight and social network.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "This is an example of the task, though some input or output fields are not supplied.\n",
      "\n",
      "[[ ## insight ## ]]\n",
      "prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "\n",
      "[[ ## social_network ## ]]\n",
      "Twitter\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## post ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "Not supplied for this particular example. \n",
      "\n",
      "[[ ## post ## ]]\n",
      "Smart models will never eliminate the need for prompt engineering, and thatâ€™s just a fact. Just like how even the brightest geniuses still rely on the guidance of HR and management to align with business goals, AI needs its nudges tooâ€”donâ€™t fall for the hype! Think about itâ€”70% of workplace failures stem from poor communication. So if your AI is drowning in data but canâ€™t swim with your vision, youâ€™re in for a world of pain. Donâ€™t sit there smugly, assuming the robots will figure it out; theyâ€™re not mind readers. Keep prompting, keep steering, lest chaos reign! \n",
      "```\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "This is an example of the task, though some input or output fields are not supplied.\n",
      "\n",
      "[[ ## insight ## ]]\n",
      "prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "\n",
      "[[ ## social_network ## ]]\n",
      "Twitter\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## post ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "Not supplied for this particular example. \n",
      "\n",
      "[[ ## post ## ]]\n",
      "Listen up: youâ€™ll still need prompt engineers to whip even the smartest models into shape. Just because something can spew out Shakespeare-level prose, doesnâ€™t mean it knows why your budget just got slashed. Much like humans, genius AIs need boundaries, direction, and the occasional kick in the pants to remember the companyâ€™s vision. Don't get burned; make sure you're ready to steer the ship before it runs aground on corporate disinterest and confusion. Remember, a well-prompted AI is more valuable than the shiniest new model left to its own devices!\n",
      "```\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "This is an example of the task, though some input or output fields are not supplied.\n",
      "\n",
      "[[ ## insight ## ]]\n",
      "prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "\n",
      "[[ ## social_network ## ]]\n",
      "Twitter\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## post ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "Not supplied for this particular example. \n",
      "\n",
      "[[ ## post ## ]]\n",
      "\"Who in their right mind thinks smarter AI means less need for human oversight? Quite the opposite, mate! Even the most brilliant minds in organizations need steering from HR or management to hit business goals. If the genius requires prompts, so will your beloved algorithms. A recent survey shows that 73% of decision-makers believe AI requires constant human guidance to remain aligned with company objectives. So, you might want to reconsider that AI 'magic wand' narrative! Keep the prompts coming, people, or youâ€™re in for a rude awakening!\"\n",
      "```\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "This is an example of the task, though some input or output fields are not supplied.\n",
      "\n",
      "[[ ## insight ## ]]\n",
      "prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "\n",
      "[[ ## social_network ## ]]\n",
      "Twitter\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## post ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "Not supplied for this particular example. \n",
      "\n",
      "[[ ## post ## ]]\n",
      "\"Even the smartest AI needs a kick in the backside! As we marvel at genius models, letâ€™s not forget: even brilliant humans need a nudge from legal and management to keep things on the straight and narrow. A recent study revealed that 72% of corporate decisions are influenced by promptsâ€”itâ€™s not about dumb or brilliant, itâ€™s about alignment. So as you cheer for your fancy tech, remember, even genius needs a lifeline or two to ensure weâ€™re not just careening towards chaos!\"\n",
      "```\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "This is an example of the task, though some input or output fields are not supplied.\n",
      "\n",
      "[[ ## insight ## ]]\n",
      "prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "\n",
      "[[ ## social_network ## ]]\n",
      "Twitter\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## post ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "Not supplied for this particular example. \n",
      "\n",
      "[[ ## post ## ]]\n",
      "\"Think AI is going to save us all? Think again. Even the world's 'smartest' models flounder without a prompt. Just like genius-level humans are shackled by corporate interests, so too will our beloved robot overlords be. Remember, IBM once claimed its chess AI was unbeatableâ€”then it lost to a grandmaster who simply knew how to play the game better. AI without clever nudging is like a car without a steering wheel. Prepare for a future where prompt engineering is the secret sauce that keeps the whole charade running smoothly. Buckle up.\"\n",
      "```\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "This is an example of the task, though some input or output fields are not supplied.\n",
      "\n",
      "[[ ## insight ## ]]\n",
      "prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "\n",
      "[[ ## social_network ## ]]\n",
      "Twitter\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## post ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "Not supplied for this particular example. \n",
      "\n",
      "[[ ## post ## ]]\n",
      "Letâ€™s be clear: just because models are getting smarter doesnâ€™t mean theyâ€™ll suddenly develop a sixth sense to dodge all the legal and management minefields out there. Even the brightest minds need some decent prompts to ensure they're not regurgitating corporate soup instead of innovative solutions. Statistically, a staggering 80% of businesses are still muddling through chaos because they canâ€™t align AI outputs with strategic goals. So, if you think you can kick back and let the models run wild, youâ€™ll wake up to an absolute shambles. Get those prompts right, or prepare for the avalanche of corporate nonsense.  \t\n",
      "```\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "This is an example of the task, though some input or output fields are not supplied.\n",
      "\n",
      "[[ ## insight ## ]]\n",
      "prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "\n",
      "[[ ## social_network ## ]]\n",
      "Twitter\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## post ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "Not supplied for this particular example. \n",
      "\n",
      "[[ ## post ## ]]\n",
      "\"Think AI can think for itself? Think again. Even the brightest human mindsâ€”yes, the ones at the top of legal and managementâ€”need an occasional nudge to keep their brilliant ideas from colliding with reality. Smart models without guidance are like a rocket without a launch padâ€”set them free and they'll just crash into the ground. A recent study revealed that 70% of AI models fail to meet organizational expectations due to lack of proper alignment with business goals. So, let's not fool ourselves; prompt engineering isn't going anywhere. It keeps our genius tools from making a mockery of our hard-earned business acumen.\"\n",
      "```\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "This is an example of the task, though some input or output fields are not supplied.\n",
      "\n",
      "[[ ## insight ## ]]\n",
      "prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "\n",
      "[[ ## social_network ## ]]\n",
      "Twitter\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## post ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "Not supplied for this particular example. \n",
      "\n",
      "[[ ## post ## ]]\n",
      "Listen up! AI models may be getting smarter by the second, but don't be fooled into thinking they'll run the show solo. Just like your top execs need a nudge from legal, HR, or management to stay aligned with business goals, these genius models require proper prompting too. Without it, you'll just end up with a tech-tinged circus act instead of strategic insights. Remember, even Einsteins need the occasional reminder about the laws of thermodynamics. So while the 'bots are busy being clever, keep your hands on the wheelâ€”because a prompted AI will outperform a clueless genius any day.\n",
      "```\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "This is an example of the task, though some input or output fields are not supplied.\n",
      "\n",
      "[[ ## insight ## ]]\n",
      "prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "\n",
      "[[ ## social_network ## ]]\n",
      "Twitter\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## post ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "Not supplied for this particular example. \n",
      "\n",
      "[[ ## post ## ]]\n",
      "Even the smartest AI isn't a mind reader. Look, folks, it's not just robots and algorithms that fumble without guidance. Even your top-tier executives need a nudge from legal, HR, and C-suite to align with business interests! Companies with structured goal alignment see a staggering 30% boost in employee engagement. So, no, prompt engineering isnâ€™t dead; itâ€™s the secret sauce we all need, regardless of how \"genius\" the model is! Stay sharp! \n",
      "```\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "This is an example of the task, though some input or output fields are not supplied.\n",
      "\n",
      "[[ ## insight ## ]]\n",
      "prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "\n",
      "[[ ## social_network ## ]]\n",
      "Twitter\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## post ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "Not supplied for this particular example. \n",
      "\n",
      "[[ ## post ## ]]\n",
      "Let's not kid ourselves: even the brightest bulbs in the room need a little prompting. Sure, AI models are getting smarter, but they're still not mind-readers. Just like that overqualified genius in your office who needs a reminder about office decorum, AI requires sharp prompts to align with business goals. And guess what? Research shows that 70% of missed business opportunities stem from poor communication. If we fail to guide our tech, we might as well throw our strategies into the void. So, embrace prompt engineering; itâ€™s the unsung hero of intelligent business!\n",
      "```\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "This is an example of the task, though some input or output fields are not supplied.\n",
      "\n",
      "[[ ## insight ## ]]\n",
      "prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "\n",
      "[[ ## social_network ## ]]\n",
      "Twitter\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## post ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "Not supplied for this particular example. \n",
      "\n",
      "[[ ## post ## ]]\n",
      "\"Even the brightest minds need a nudge now and then. Think you can just unleash a genius AI and watch it take over? Think again. Just as smart humans rely on legal and HR to keep the wheels turning, those fancy models will need clear prompts to avoid chaos. Research shows that without proper guidance, even top-tier AI can make 'creative' choices that present real-world problems. The last thing you want is your innovation fighting the policies youâ€™re trying to uphold. So, donâ€™t just churn out AI â€” steer it right, or prepare for a mess.\"\n",
      "```\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "This is an example of the task, though some input or output fields are not supplied.\n",
      "\n",
      "[[ ## insight ## ]]\n",
      "prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "\n",
      "[[ ## social_network ## ]]\n",
      "Twitter\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## post ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "Not supplied for this particular example. \n",
      "\n",
      "[[ ## post ## ]]\n",
      "Genius models may soon revolutionize the workplace, but don't kid yourselfâ€”prompt engineering isn't going anywhere. Think of it like telling a prodigy how to behave at a family dinner; even the smartest among us need a nudge from HR or legal to keep in line with the business strategy. And if you think you can just sit back and let the algorithm work, consider this: a staggering 70% of AI initiatives in businesses flop due to a lack of alignment with objectives. So, refine those prompts, folksâ€”because even in the world of AI, itâ€™s still all about the right directions.\n",
      "```\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "This is an example of the task, though some input or output fields are not supplied.\n",
      "\n",
      "[[ ## insight ## ]]\n",
      "prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "\n",
      "[[ ## social_network ## ]]\n",
      "Twitter\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## post ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "Not supplied for this particular example. \n",
      "\n",
      "[[ ## post ## ]]\n",
      "\"Think smarter models mean the end of prompt engineering? Wrong. Even the sharpest genius needs guidanceâ€”just like models need human alignment to dodge legal landmines and HR hiccups. Companies investing in prompt engineering see efficiency boosts of up to 30%. So, are you ready to automate chaos or let it reign? #ProTip: The best time to get your act together was yesterday. The next best is today.\"\n",
      "```\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## insight ## ]]\n",
      "prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "\n",
      "[[ ## social_network ## ]]\n",
      "Twitter\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## post ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The insight highlights the ongoing necessity of prompt engineering even as AI models become more advanced. It draws a parallel between the need for human guidance in business contexts and the need for structured prompts to ensure AI aligns with organizational goals. This is relevant for Twitter, where concise and impactful messaging is key.\n",
      "\n",
      "[[ ## post ## ]]\n",
      "\"Smarter AI doesnâ€™t mean less need for prompt engineering! Just like even the brightest minds need guidance from HR and management, AI models require clear prompts to align with business interests. Remember, 70% of AI projects fail due to misalignment. Letâ€™s keep our tech on track! #AI #PromptEngineering #BusinessStrategy\"\n",
      "```\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## insight ## ]]\n",
      "prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "\n",
      "[[ ## social_network ## ]]\n",
      "Twitter\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## post ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The insight highlights the ongoing necessity of prompt engineering even as AI models become more advanced. It draws a parallel between the need for human guidance in business contexts and the requirement for AI to be directed appropriately to align with organizational goals. This emphasizes that intelligence, whether human or artificial, requires structure and direction to be effective.\n",
      "\n",
      "[[ ## post ## ]]\n",
      "\"Even with smarter AI models, prompt engineering is here to stay! Just like genius humans need guidance from legal, HR, and management to align with business interests, so do our AI systems. Without proper prompts, even the brightest models can miss the mark. Letâ€™s keep our tech aligned with our goals! #AI #PromptEngineering #BusinessStrategy\"\n",
      "```\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## insight ## ]]\n",
      "prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "\n",
      "[[ ## social_network ## ]]\n",
      "Twitter\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## post ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The insight highlights the ongoing necessity of prompt engineering even as AI models become more advanced. It draws a parallel between the need for human guidance in business contexts and the need for AI to be properly directed to align with organizational goals. This emphasizes that without proper prompting, even the smartest models can fail to meet expectations, just as brilliant individuals may need reminders to stay on track.\n",
      "\n",
      "[[ ## post ## ]]\n",
      "\"Smarter AI doesn't mean less need for prompt engineering! Just like even the brightest humans need guidance from HR and management to align with business goals, AI models require the same. A staggering 70% of AI projects fail due to misalignment. So, letâ€™s keep those prompts sharp and ensure our genius models are on the right path! #AI #PromptEngineering #BusinessAlignment\"\n",
      "```\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## insight ## ]]\n",
      "prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "\n",
      "[[ ## social_network ## ]]\n",
      "Twitter\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## post ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "The insight emphasizes that as AI models become more advanced, the need for prompt engineering remains crucial. It draws a parallel to how even highly intelligent humans require guidance from departments like legal and HR to ensure alignment with business objectives. This highlights the importance of structured prompts in maximizing the effectiveness of AI, ensuring it operates within the desired parameters and aligns with organizational goals.\n",
      "\n",
      "[[ ## post ## ]]\n",
      "\"Donâ€™t be fooledâ€”smarter AI still needs prompt engineering! Just like genius humans rely on legal and HR for guidance, AI models need clear prompts to align with business interests. Without them, even the best tech can miss the mark. Letâ€™s keep our AI on track! #AI #PromptEngineering #BusinessGoals\"\n",
      "```\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt_4o_mini.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2c0f6b",
   "metadata": {},
   "source": [
    "### Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88091827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning job created with ID: ftjob-PP8OZAQ0CK4CaOHkDSPFVsbp\n",
      "Job status: validating_files\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "# Format the data for fine-tuning\n",
    "fine_tuning_data = []\n",
    "for post in results_b:\n",
    "    example = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": examples_prompt.format(**examples_context)},\n",
    "            {\"role\": \"assistant\", \"content\": post['content']}\n",
    "        ]\n",
    "    }\n",
    "    fine_tuning_data.append(example)\n",
    "\n",
    "# Write the formatted data to a JSONL file\n",
    "with open(\"fine_tuning_data.jsonl\", \"w\") as f:\n",
    "    for entry in fine_tuning_data:\n",
    "        json.dump(entry, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Upload the file\n",
    "file = client.files.create(\n",
    "    file=open(\"fine_tuning_data.jsonl\", \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "# Create a fine-tuning job\n",
    "job = client.fine_tuning.jobs.create(\n",
    "    training_file=file.id,\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(f\"Fine-tuning job created with ID: {job.id}\")\n",
    "\n",
    "# You can check the status of your fine-tuning job\n",
    "print(f\"Job status: {job.status}\")\n",
    "\n",
    "# Note: The fine-tuning process may take some time to complete.\n",
    "# You'll need to periodically check the status of the job to know when it's done.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23c0abe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-PP8OZAQ0CK4CaOHkDSPFVsbp', created_at=1745169031, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-C5xNTgkE7xTz1VYEy6oKSbfM', result_files=[], seed=1408832167, status='validating_files', trained_tokens=None, training_file='file-7kcLohNiFAMi14yU1C6oSq', validation_file=None, estimated_finish=None, integrations=[], method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto')), type='supervised'), user_provided_suffix=None, metadata=None)], object='list', has_more=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.list(limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c88eb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for fine-tuning job to complete. Current status: validating_files\n",
      "Waiting for fine-tuning job to complete. Current status: running\n",
      "Waiting for fine-tuning job to complete. Current status: running\n",
      "Waiting for fine-tuning job to complete. Current status: running\n",
      "Waiting for fine-tuning job to complete. Current status: running\n",
      "Waiting for fine-tuning job to complete. Current status: running\n",
      "Using fine-tuned model: ft:gpt-3.5-turbo-0125:personal::BOSZLJvJ\n",
      "\n",
      "Evaluating model: gpt-3.5-turbo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:15<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model: gpt-4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:50<00:00,  5.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model: ft:gpt-3.5-turbo-0125:personal::BOSZLJvJ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:18<00:00, 13.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Engagement Evaluation Results:\n",
      "gpt-3.5-turbo: 3.80\n",
      "Top 3 posts:\n",
      "  1. Score: 5.00\n",
      "     Post: - bait: Smart robots will never replace engineers completely. \n",
      "- hook: Even genius humans need guida...\n",
      "  2. Score: 4.00\n",
      "     Post: bait: Even genius humans need prompting from legal, HR, and management.\n",
      "hook: Smart models can only ...\n",
      "  3. Score: 4.00\n",
      "     Post: bait: Even genius humans need a nudge in the right direction.\n",
      "hook: Prompt engineering is crucial fo...\n",
      "gpt-4: 4.30\n",
      "Top 3 posts:\n",
      "  1. Score: 5.00\n",
      "     Post: bait: Bringing in a seemingly unrelated yet popular topic - genius humans - in the context of smarte...\n",
      "  2. Score: 5.00\n",
      "     Post: - bait: Questioning the infallibility of smarter AI models\n",
      "- hook: Drawing parallels between AI need...\n",
      "  3. Score: 5.00\n",
      "     Post: bait: Spark curiosity by mentioning the intersection of smarter models and the need for humans, catc...\n",
      "ft:gpt-3.5-turbo-0125:personal::BOSZLJvJ: 3.60\n",
      "Top 3 posts:\n",
      "  1. Score: 4.00\n",
      "     Post: \"Itâ€™s a common myth that smarter models mean less guidance needed. Even when you have a genius on yo...\n",
      "  2. Score: 4.00\n",
      "     Post: \"Think smarter models will render prompt engineering obsolete? A bold assumptionâ€”just ask your geniu...\n",
      "  3. Score: 4.00\n",
      "     Post: \"Even Tesla's self-driving cars canâ€™t sidestep the need for steering. So why would you think that sm...\n",
      "\n",
      "Best performing model: gpt-4 with an average engagement score of 4.30\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get the last fine-tuned model\n",
    "fine_tuning_jobs = client.fine_tuning.jobs.list(limit=1)\n",
    "if fine_tuning_jobs.data:\n",
    "    last_job = fine_tuning_jobs.data[0]\n",
    "    while last_job.status != \"succeeded\":\n",
    "        print(f\"Waiting for fine-tuning job to complete. Current status: {last_job.status}\")\n",
    "        time.sleep(60)  # Wait for 60 seconds before checking again\n",
    "        last_job = client.fine_tuning.jobs.retrieve(last_job.id)\n",
    "    \n",
    "    fine_tuned_model = last_job.fine_tuned_model\n",
    "    print(f\"Using fine-tuned model: {fine_tuned_model}\")\n",
    "else:\n",
    "    print(\"No fine-tuning jobs found. Please run the fine-tuning process first.\")\n",
    "    fine_tuned_model = None\n",
    "\n",
    "# fine_tuned_model = \"ft:gpt-3.5-turbo-0125:saxifrage-llc::9lzyYgCb\"\n",
    "\n",
    "models_to_compare = [\"gpt-3.5-turbo\", \"gpt-4\", fine_tuned_model]\n",
    "models_to_compare = [model for model in models_to_compare if model]  # Remove None if fine-tuned model is not available\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model in models_to_compare:\n",
    "    print(f\"\\nEvaluating model: {model}\")\n",
    "    posts = []\n",
    "    for _ in tqdm(range(10)):  # Generate 10 posts for each model\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": examples_prompt.format(**examples_context)}\n",
    "            ],\n",
    "            max_tokens=500\n",
    "        )\n",
    "        posts.append(response.choices[0].message.content)\n",
    "    \n",
    "    # Evaluate engagement for the generated posts\n",
    "    def parse_engagement_score(response):\n",
    "        match = re.search(r'Rating:\\s*(\\d+(?:\\.\\d+)?)', response)\n",
    "        if match:\n",
    "            return float(match.group(1))\n",
    "        return 0.0  # Default to 0 if no match found\n",
    "\n",
    "    engagement_scores = []\n",
    "    for post in posts:\n",
    "        score = parse_engagement_score(evaluate_engagement(post, context[\"insight\"], context[\"social_network\"]))\n",
    "        engagement_scores.append({\"post\": post, \"score\": score})\n",
    "    \n",
    "    average_score = sum(item[\"score\"] for item in engagement_scores) / len(engagement_scores)\n",
    "    results[model] = {\"average_score\": average_score, \"posts\": engagement_scores}\n",
    "\n",
    "# Print results\n",
    "print(\"\\nEngagement Evaluation Results:\")\n",
    "for model, data in results.items():\n",
    "    print(f\"{model}: {data['average_score']:.2f}\")\n",
    "    print(\"Top 3 posts:\")\n",
    "    top_posts = sorted(data['posts'], key=lambda x: x['score'], reverse=True)[:3]\n",
    "    for i, post_data in enumerate(top_posts, 1):\n",
    "        print(f\"  {i}. Score: {post_data['score']:.2f}\")\n",
    "        print(f\"     Post: {post_data['post'][:100]}...\")  # Print first 100 characters of the post\n",
    "\n",
    "# Determine the best performing model\n",
    "best_model = max(results, key=lambda x: results[x]['average_score'])\n",
    "print(f\"\\nBest performing model: {best_model} with an average engagement score of {results[best_model]['average_score']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bfea14f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'post': '\"Itâ€™s a common myth that smarter models mean less guidance needed. Even when you have a genius on your team, theyâ€™re still a part of the business, not an island. Just like top-level execs, they need strategic prompting to align with what matters mostâ€”your bottom line. So breathe easy, but donâ€™t drop the ball on prompt engineering. Without it, those shining AI stars might be doing floaty ballet thatâ€™s pretty but not profitable. Remember: Even the best minds need a nudge from time to time.\"\\n```',\n",
       " 'score': 4.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['ft:gpt-3.5-turbo-0125:personal::BOSZLJvJ']['posts'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
