{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.pinecone.io/learn/openai-gen-qa/\n",
    "# Pincone is a service that provides Indexing and vector search as a service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU openai pinecone datasets cohere tiktoken --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the openai secret key:\n",
    "import getpass\n",
    "\n",
    "secret_key = getpass.getpass('Please enter your openai key:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from IPython.display import display, Math, Markdown\n",
    "\n",
    "client = OpenAI(api_key=secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, PodSpec\n",
    "import os\n",
    "\n",
    "PINECONE_API_KEY = getpass.getpass(\"Please enter your pinecone key: \")\n",
    "\n",
    "# Initialize connection (get API key at app.pinecone.io):\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The history of the United States is rich and complex, spanning several centuries and involving various cultural and political developments. Below is an overview of key events and periods in U.S. history:\\n\\n### Pre-Columbian and Indigenous Peoples (Before 1492)\\nBefore European contact, the Americas were inhabited by a diverse array of indigenous peoples, with distinct cultures, languages, and societies. Major civilizations such as the Aztecs, Maya, and Inca thrived in other parts of the Americas, while North America was home to tribes like the Sioux, Navajo, and Iroquois.\\n\\n### European Exploration and Colonization (1492-1607)\\nChristopher Columbus's voyage in 1492 marked the beginning of European exploration of the Americas. Subsequent expeditions led to the establishment of various colonies by Spain, France, England, and the Netherlands. The Spanish established settlements in the Southwest, while the French focused on the fur trade in the Northeast and along the Mississippi River.\\n\\n### Colonial America (1607-1775)\\nIn 1607, the English established their first permanent settlement in Jamestown, Virginia. Over the next century, thirteen colonies were established along the Atlantic coast. These colonies developed distinct economies and cultures, characterized by agriculture in the South, commerce in the Middle colonies, and a more diversified economy in New England. Tensions grew between the colonies and England over taxation and governance, particularly after the French and Indian War (1754-1763).\\n\\n### The American Revolution (1775-1783)\\nConflict escalated into the American Revolutionary War, which began in 1775 as colonists sought independence from British rule. The Declaration of Independence, written by Thomas Jefferson and adopted on July 4, 1776, formally announced this intention. The war ended in 1783 with the Treaty of Paris, recognizing the independence of the United States.\\n\\n### Formation of the New Nation (1783-1815)\\nAfter the war, the U.S. struggled to establish a stable government under the Articles of Confederation. The Constitutional Convention of 1787 resulted in the U.S. Constitution, which created a stronger federal government. The Bill of Rights, ratified in 1791, guaranteed individual freedoms.\\n\\n### Expansion and Conflict (1815-1860)\\nThe U.S. expanded westward during the 19th century, driven by the idea of Manifest Destiny. This period saw the Louisiana Purchase (1803) and conflicts with Native American tribes, as well as the Mexican-American War (1846-1848), which resulted in acquiring territories like California and Texas. However, expansion increased tensions over slavery, particularly in new territories.\\n\\n### Civil War and Reconstruction (1861-1877)\\nSlavery became a central issue, leading to the secession of Southern states and the formation of the Confederacy. The Civil War, fought between 1861 and 1865, resulted in a Northern victory and the abolition of slavery through the 13th Amendment. The Reconstruction era aimed to integrate formerly enslaved people into society and rebuild the South, but faced significant challenges and resistance.\\n\\n### Industrialization and the Gilded Age (1877-1900)\\nPost-Reconstruction, the U.S. underwent rapid industrialization, leading to urbanization, economic growth, and significant social changes. However, this era also saw increased inequality, labor unrest, and the rise of monopolies and corrupt practices.\\n\\n### Progressive Era and World War I (1900-1918)\\nThe early 20th century brought about reforms to address issues brought by industrialization, including labor rights and women's suffrage. The U.S. entered World War I in 1917, shifting global power dynamics.\\n\\n### The Roaring Twenties and Great Depression (1920-1939)\\nThe post-war economy initially thrived. However, the stock market crash of 1929 led to the Great Depression, drastically affecting the economy and society.\\n\\n### World War II (1939-1945)\\nThe U.S. entered World War II in 1941 following the attack on Pearl Harbor. The war effort revitalized the economy and led to significant social changes, including the beginning of the civil rights movement.\\n\\n### Cold War Era (1947-1991)\\nPost-war, the U.S. emerged as a superpower, leading to a prolonged Cold War with the Soviet Union. This period included the Korean War, the Vietnam War, and significant domestic movements for civil rights and against the war.\\n\\n### Contemporary Era (1991-Present)\\nThe Cold War ended with the dissolution of the Soviet Union in 1991. The U.S. has since been involved in various conflicts, including the Gulf War, the War on Terror, and the wars in Afghanistan and Iraq. Domestically, issues such as economic inequality, healthcare, race relations, and climate change have remained significant.\\n\\nThis overview encapsulates the key phases of U.S. history, but the complexities and nuances of each period are vast and deserve deeper exploration.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Tell me about the history of the United States of America.\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model =\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=4000,\n",
    "    temperature=1,\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"When you have only related sentence pairs, a few training approaches can be especially effective for training sentence transformers:\\n\\n1. **Contrastive Learning**: In this approach, you focus on minimizing the distance between related sentence pairs while maximizing the distance between unrelated sentences (or sampling negative instances). If you only have related pairs, you can still generate negative samples by using random sentences from your dataset or other datasets.\\n\\n2. **Triplet Loss**: You can create triplets consisting of an anchor (one sentence), a positive (a related sentence), and a negative (an unrelated sentence) sample. The goal is to ensure that the positive sample is closer to the anchor than the negative one. Similar to contrastive learning, you'll need to create or sample negative pairs.\\n\\n3. **Siamese Networks**: You can use a Siamese network architecture where two identical subnetworks process the two sentences in a pair. The loss can be based on the similarity of the embeddings generated by these two branches. You may have to explore or generate negative samples as mentioned previously.\\n\\n4. **Fine-tuning on Pre-trained Models**: If youâ€™re working with a pre-trained sentence transformer, you might want to fine-tune it using your related pairs directly with a suitable loss function (like cosine similarity or binary cross-entropy) that reflects the idea of similarity without needing explicitly negative examples.\\n\\n5. **Self-Supervised Learning**: If your dataset is large enough, you can consider self-supervised approaches, where you can create pseudo-labels from your data. For example, you can use methods like data augmentation to create variations of the same sentence and treat them as related.\\n\\n6. **Denoising Autoencoder**: Build a model that tries to reconstruct or predict parts of a sentence given other parts. This can help the model learn the structure of related sentences even if only pairs are available.\\n\\nGiven the limitation that you only have related pairs, your best approach may be to leverage contrastive learning or triplet loss by effectively creating or sourcing negative pairs for optimal training outcomes.\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First let's make it simpler to get answers\n",
    "def askGpt(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=4000,\n",
    "        temperature=1,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "query = (\n",
    "    \"Which training approach is best for sentence transformers when I only have related sentence pairs?\"\n",
    ")\n",
    "\n",
    "askGpt(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = \"text-embedding-ada-002\"\n",
    "\n",
    "res = client.embeddings.create(\n",
    "    input=[\n",
    "        \"Sample document text goes here\",\n",
    "        \"there will be several phrases in each batch\"\n",
    "    ], model=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Embedding(embedding=[-0.0031264047138392925, 0.011723595671355724, -0.005217977799475193, -0.027155056595802307, -0.016435954719781876, 0.03246741741895676, -0.01624719239771366, -0.0010095506440848112, -0.025928091257810593, -0.006556179840117693, 0.0201303381472826, 0.01667865179479122, -0.009155056439340115, 0.02344719134271145, -0.010247191414237022, 0.013449438847601414, 0.025213483721017838, -0.016853932291269302, 0.0121617978438735, -0.01624719239771366, -0.0043820226565003395, -0.006495506037026644, -0.004368539433926344, 0.020723596215248108, -0.01062471978366375, -0.0037584269884973764, 0.013712359592318535, -0.026251686736941338, -0.0003962781047448516, -0.002147190971300006, 0.005831460934132338, -0.010092135518789291, -0.028179775923490524, -0.016206741333007812, -0.004317977465689182, 0.007469663396477699, -0.002902247244492173, -0.031550563871860504, 0.024000000208616257, -0.03338427096605301, -0.0003642556257545948, 0.013051685877144337, 0.007186517119407654, -0.005642696749418974, 0.0031870787497609854, -0.02985168620944023, 0.02626516856253147, -0.004651685710996389, 0.006630337331444025, 0.017339326441287994, 0.02742471918463707, 0.01576179824769497, -0.022139325737953186, 0.0029410114511847496, -0.006583146285265684, 0.006451685447245836, -0.017002247273921967, 0.0200898889452219, 0.0035494384355843067, -0.0034752809442579746, -0.0011005618143826723, 0.0035662923473864794, -0.00267303385771811, -0.01259325910359621, -0.0180134829133749, -0.03543370962142944, -0.03173932805657387, 0.007496629375964403, 0.0072067417204380035, 0.0055348314344882965, 0.020804494619369507, 0.011029213666915894, -0.011521348729729652, -0.01744719222187996, 0.006626966409385204, 0.01013258472084999, -0.012175281532108784, -0.012465168721973896, 0.000285042158793658, -0.0011679775780066848, 0.004644943866878748, -0.026723597198724747, -0.002341011306270957, 0.032062921673059464, 0.009060674346983433, 0.014022472314536572, 0.018256179988384247, 0.02906966395676136, -0.021020226180553436, -0.017352810129523277, -0.006047191098332405, 0.015869664028286934, -0.00440561817958951, 0.01709662936627865, -0.013186517171561718, 0.02199101261794567, -0.00543033704161644, 0.024323595687747, 0.003819101257249713, -0.04085393249988556, 0.008467416279017925, 0.009964045137166977, -0.012121348641812801, -0.009600000455975533, -0.03942472115159035, 0.005807865411043167, 0.016260674223303795, -0.014844944700598717, 0.016125842928886414, 0.014507865533232689, -0.021519102156162262, 0.012707865796983242, -0.004702247213572264, -0.03322247415781021, 0.014400000683963299, 0.004614606965333223, -0.004439326003193855, -0.02203146182000637, 0.0011081461561843753, -0.0051573035307228565, -0.01330112386494875, 0.026157304644584656, 0.04007191210985184, -0.016570787876844406, 0.01395505666732788, 0.023649439215660095, -0.005130337085574865, -0.03192809224128723, 0.012842697091400623, -0.0059797754511237144, 0.018121348693966866, 0.042606744915246964, 0.024215731769800186, 0.020588764920830727, -0.02820674329996109, 0.018849438056349754, -0.04549213498830795, 0.01922696642577648, -0.021802248433232307, -0.017555056139826775, 0.00885842740535736, 0.03494831547141075, -0.006128089968115091, -0.006249438505619764, 0.006943820510059595, 0.011164044961333275, 0.0006421348662115633, -0.021155057474970818, 0.01077303383499384, -0.013833708129823208, 0.010874157771468163, 0.0023797752801328897, -0.007166292518377304, 0.01205393299460411, 0.003680899040773511, 0.02626516856253147, 0.012357303872704506, -0.003916854038834572, -0.011386517435312271, -0.020494382828474045, 0.00820449460297823, 0.01457528118044138, 0.019321348518133163, -0.010071910917758942, 0.010422471910715103, 0.04150112345814705, 0.002576966304332018, -0.01077977567911148, 0.00036088484921492636, -0.01766292192041874, -0.02453932724893093, 0.016880899667739868, -0.04565393552184105, 0.003964045085012913, -0.03322247415781021, 0.024593260139226913, 0.014925843104720116, 0.015087640844285488, -0.008973034098744392, -0.02315056324005127, -0.01977977529168129, 0.007941572926938534, 0.011858426965773106, 0.03724044933915138, -0.03662022575736046, -0.00367752811871469, -0.015775281935930252, 0.0005119382403790951, 0.002644382184371352, 0.0007259831763803959, 0.007968539372086525, 0.010496629402041435, 0.005069663282483816, -0.023555057123303413, -0.6899056434631348, -0.021182022988796234, -0.003812359645962715, -0.011669663712382317, 0.025752810761332512, 0.020629214122891426, 0.011737079359591007, 0.010334831662476063, -0.010442697443068027, 0.014346067793667316, -0.02311011403799057, 0.0053022475913167, -0.010995506308972836, -0.0028955056332051754, -0.01771685481071472, -0.0190112367272377, 0.00014968399773351848, 0.00377865182235837, -0.019200000911951065, 0.0078067416325211525, 0.0002972612564917654, 0.013503370806574821, -0.02906966395676136, 0.01384719181805849, 0.012620225548744202, -0.0010129213333129883, 0.005005618091672659, -0.016476405784487724, 0.00298651703633368, 0.024471910670399666, -0.037510111927986145, -0.0111842704936862, -0.005113483406603336, 0.022449439391493797, 0.05377078801393509, -6.44662941340357e-05, -1.1843838365166448e-05, -0.0074292137287557125, 0.011238202452659607, 0.013274157419800758, -0.018391011282801628, -0.01754157431423664, 0.006202247459441423, -0.015910113230347633, -0.0014039325760677457, 0.0015817416133359075, 0.03001348488032818, 0.011669663712382317, 0.01770337112247944, 0.02730337157845497, -0.0056561799719929695, 0.0009455056278966367, 0.015586517751216888, -0.0059157307259738445, 0.011858426965773106, 0.0019213483901694417, 0.03675505891442299, -0.02444494515657425, 0.016557304188609123, 0.026844944804906845, 0.005248314701020718, 0.022705618292093277, -0.014548314735293388, -0.0180134829133749, -0.005861797835677862, 0.006782022770494223, -0.010038202628493309, 0.004055056255310774, 0.02751910127699375, -0.014817978255450726, 0.011137079447507858, 0.018849438056349754, -0.021006742492318153, -0.024417977780103683, 0.00545393256470561, 0.012000000104308128, 0.013793258927762508, -0.00500898901373148, -0.01140674203634262, 0.01680000126361847, 0.018647192046046257, 0.007901123724877834, -0.03705168515443802, -0.01568089984357357, 0.018862921744585037, -0.003940449561923742, -0.04206741601228714, -0.006471910513937473, 0.002123595681041479, 0.009060674346983433, 0.009957303293049335, 0.021492134779691696, -0.006643820554018021, 0.0069303372874855995, 0.00503258453682065, 0.011474157683551311, -0.0029426966793835163, 0.006519101560115814, 0.009283146820962429, -0.005568539723753929, 0.0023578652180731297, 0.02444494515657425, -0.014224719256162643, 0.006991011556237936, 0.030687641352415085, 0.0017966292798519135, -0.0019365169573575258, 0.011217977851629257, 0.01697528176009655, -0.014116854406893253, 0.002674719085916877, -0.0002783005766104907, -0.008676405064761639, -0.024134831503033638, -0.017137078568339348, -0.03144269809126854, 0.01187865249812603, 0.00035014047170989215, 0.015276405028998852, 0.009795505553483963, 0.01973932608962059, 0.010287640616297722, -0.0026292135007679462, 0.0007061798241920769, 0.015573034062981606, 0.006525842938572168, -0.010638202540576458, -0.03238651901483536, -0.0029477528296411037, -0.011993259191513062, -0.012020224705338478, 0.002821348374709487, 0.04535730555653572, -0.01624719239771366, 0.013570787385106087, 0.004226966295391321, 0.019038202241063118, -0.00630674185231328, -0.005457303486764431, -0.014035956002771854, -0.023474158719182014, 0.015033707953989506, -0.006970786955207586, -0.011157304048538208, 0.009869663044810295, -0.020197752863168716, -0.024647191166877747, -0.0023022473324090242, 0.004001123830676079, -0.0044831461273133755, -0.011265168897807598, -0.010543820448219776, -0.023608990013599396, 0.006458427291363478, 0.00411573052406311, -0.004884270019829273, 0.006091011222451925, -0.028125843033194542, -0.010348315350711346, -0.013044944033026695, 0.0041224719025194645, 0.018606742843985558, -0.022732585668563843, -0.000661095546092838, -0.009202247485518456, -0.020723596215248108, -0.026278652250766754, 0.020507866516709328, -0.011602247133851051, -0.030525844544172287, -0.005164044909179211, -0.01250561885535717, -0.0010837079025804996, -0.0011882022954523563, 0.014804494567215443, -0.01524943858385086, -0.020413484424352646, 0.0010264045558869839, 0.027492135763168335, -0.025820225477218628, 0.011494382284581661, 0.014669663272798061, 0.017029214650392532, 0.016058428213000298, 0.02146516926586628, 0.013159550726413727, 0.001547191059216857, 0.015991011634469032, -0.015519102104008198, -0.0023426967673003674, 0.020804494619369507, -0.006141573190689087, -0.010442697443068027, 0.013166292570531368, -0.00570000009611249, 0.004365168511867523, -0.02289438247680664, 0.017460674047470093, 0.018984271213412285, 0.00014178371930029243, 0.021519102156162262, 0.00835955049842596, 0.014143820852041245, -0.010004494339227676, 0.0031078653410077095, -0.033977530896663666, -0.0035089890006929636, -0.025982024148106575, 0.009316854178905487, 0.01207415759563446, 0.003291573142632842, -0.020413484424352646, -0.02704719267785549, 0.004078651778399944, 0.010253933258354664, 0.020076405256986618, -0.0038764046039432287, -0.0037146068643778563, -0.0012733147013932467, 0.0012480337172746658, 0.008635954931378365, -0.006401123944669962, 0.018000001087784767, -0.006879775319248438, -0.0078067416325211525, 0.01944269798696041, 0.015991011634469032, 0.03761797770857811, 0.0111842704936862, -0.014521349221467972, -0.0008898876840248704, 0.005514606833457947, -0.0012724719708785415, -0.000263132038526237, 0.02708764187991619, 0.0132808992639184, 0.019240450114011765, -0.016746068373322487, 0.039020225405693054, -0.006030337419360876, -0.016355056315660477, 0.021316854283213615, 0.02146516926586628, -0.013341573067009449, 0.014440449886023998, -0.022058427333831787, 0.015087640844285488, 0.01995505765080452, -0.007982023060321808, 0.0003383427101653069, 0.0013390450039878488, 0.013611236587166786, -0.008056179620325565, 0.013712359592318535, 0.026791011914610863, -0.006697752978652716, -0.0016331460792571306, 0.010098876431584358, 0.004894382320344448, 0.016179775819182396, 0.018579775467514992, -0.013179775327444077, -0.0033691013231873512, 0.004944943822920322, 0.020885394886136055, -0.006859550718218088, -0.0024016855750232935, -0.004931461066007614, -0.017905618995428085, 0.0007242977735586464, 0.0051033711060881615, -0.012788764201104641, 0.012910112738609314, -0.017258428037166595, 0.02189663052558899, 0.008507865481078625, 0.01624719239771366, 0.009080898948013783, 0.001580056268721819, -0.0049348315224051476, -0.017204495146870613, -0.037860676646232605, 0.0013811797834932804, 0.010982022620737553, 0.0059797754511237144, -0.0016188202425837517, -0.007759551052004099, 0.016692135483026505, -0.014480899088084698, -0.0004617977829184383, 0.006067416165024042, 0.005477528087794781, 0.007894381880760193, -0.011191011406481266, 0.004152809269726276, 0.012849438935518265, 0.0037516856100410223, 0.003674157429486513, -0.018647192046046257, 0.010489887557923794, 0.011346068233251572, -0.002158988732844591, -0.024040449410676956, -0.024283146485686302, 0.04365842789411545, -0.01373258512467146, -0.007139326073229313, 0.001948314718902111, -0.009276404976844788, -0.021316854283213615, 0.011993259191513062, 0.002519662957638502, -0.02199101261794567, -0.0008814607281237841, 0.019496629014611244, 0.000921067432500422, -0.011191011406481266, 0.015060674399137497, 0.025766292586922646, 0.008089887909591198, 0.0019011236727237701, -0.02855730429291725, -0.013874157331883907, 0.012303370982408524, 0.06024269759654999, 0.05147865414619446, 0.005750562064349651, 0.003761797910556197, 0.008400000631809235, -0.005335955414921045, -0.013462921604514122, -0.013570787385106087, 0.01750112511217594, -0.021316854283213615, -0.006171910557895899, -0.004712359514087439, 0.01948314718902111, 0.0025280900299549103, 0.022382022812962532, -0.006812359672039747, 0.010429213754832745, 0.013739326037466526, -0.011440449394285679, -0.01831011287868023, 0.008015730418264866, 0.010523595847189426, 0.0010028090327978134, 0.008582022972404957, 0.020750561729073524, -0.022705618292093277, 0.010004494339227676, 0.014386516995728016, -0.00666067423298955, -0.024512359872460365, -0.016570787876844406, 0.016422472894191742, 0.016867415979504585, 0.023595506325364113, -0.003670786740258336, 0.030984271317720413, -0.010961798019707203, -0.013901123777031898, 0.005271910224109888, 0.003761797910556197, 0.008420225232839584, 0.00597303407266736, 0.011056180112063885, 0.0035629214253276587, -0.002297191182151437, 0.0031398877035826445, -0.022058427333831787, 0.003254494396969676, -0.01334831491112709, -0.0033842697739601135, 0.001664325944148004, -0.007462921552360058, 0.018202247098088264, -0.012883146293461323, 0.017676405608654022, 0.018647192046046257, 0.00961348321288824, 0.010597753338515759, -0.00659662950783968, -0.026022473350167274, -0.005447191186249256, -0.001591011299751699, -0.009714607149362564, -0.009337078779935837, -0.0043280902318656445, -0.024849439039826393, -0.010658427141606808, -0.0012724719708785415, -0.025752810761332512, 0.010408989153802395, 0.007388764526695013, 0.002155618043616414, -0.01457528118044138, 0.003350561950355768, 0.011177528649568558, 0.0014030899619683623, -0.0036539328284561634, -0.00469887675717473, -0.01080000028014183, -0.00033686798997223377, -0.006822471972554922, -0.014265169389545918, 0.011507865972816944, -0.022732585668563843, -0.0009623595979064703, 0.015910113230347633, 0.0006484550540335476, 0.0011393259046599269, 0.0003971208061557263, 0.02720898948609829, -0.005025842692703009, 0.008534831926226616, -0.009970786981284618, -0.03184719383716583, -0.0021674158051609993, -0.018417978659272194, 0.006084269843995571, -0.012748314999043941, -0.004516853950917721, -0.020804494619369507, -0.010982022620737553, -0.00023911517928354442, -0.0003802668652497232, -0.006067416165024042, 0.003455056343227625, 0.0009109550737775862, -0.0014207866042852402, 0.01280898880213499, -0.007928090170025826, -0.0019786518532782793, 0.004564044997096062, -0.011170786805450916, -0.0012615169398486614, -0.01326067466288805, 0.011413483880460262, 0.013004494830965996, -0.006111236289143562, 0.025119101628661156, 0.002315730322152376, -0.015397753566503525, 0.012977528385818005, -0.019766293466091156, 0.013408989645540714, 0.024984270334243774, 0.00939101167023182, 0.02324494533240795, -0.02263820357620716, -0.004850562196224928, 0.00382247194647789, -0.012950561940670013, -0.008008989505469799, 0.008352809585630894, -0.0020848314743489027, -0.018674157559871674, -0.0264809001237154, -0.0018539326265454292, 0.0013441011542454362, 0.009323596023023129, -0.023271910846233368, -0.011925843544304371, -0.01887640543282032, 0.004948314744979143, 0.0095662921667099, -0.0037584269884973764, -0.011453933082520962, -0.02579325996339321, -0.0031146069522947073, -0.0025331461802124977, -0.012303370982408524, 0.016638202592730522, 0.005194382276386023, -0.004688763990998268, -0.008265168406069279, -0.002996629336848855, 0.004682022612541914, -0.025685394182801247, 0.009667416103184223, 0.010725842788815498, 0.018566293641924858, 0.017919102683663368, 0.02600898966193199, -0.00043567418470047414, 0.015667416155338287, 0.01194606814533472, -0.008973034098744392, -0.002752247266471386, 0.004975281190127134, -0.010813483968377113, -0.01662471890449524, -0.0027033709920942783, 0.010483146645128727, 0.011575281620025635, 0.010806742124259472, -0.01899775303900242, 0.013186517171561718, 0.004995505791157484, -0.004513483494520187, 0.003269663080573082, 0.004867415875196457, -0.02311011403799057, -0.008258427493274212, 0.011474157683551311, -0.013247191905975342, 0.014683146961033344, -0.02906966395676136, 0.0028247192967683077, 0.05201797932386398, -0.005797753110527992, 0.006566292140632868, 0.004550561774522066, 0.008669663220643997, -0.01572134904563427, -0.0018623595824465156, -0.0200898889452219, -0.00048412923933938146, -0.013125843368470669, 0.01689438335597515, -0.021195506677031517, 0.003455056343227625, 0.04616629332304001, 0.016489887610077858, 0.0033219102770090103, 0.003399438224732876, 0.019901124760508537, 0.0073280902579426765, -0.019186517223715782, 0.01021348312497139, 0.0024151685647666454, -0.0034028091467916965, 0.0006219101487658918, -0.032197754830121994, 0.0028449438977986574, -0.003109550569206476, -0.011103371158242226, -0.0023713484406471252, 0.0191325843334198, 0.006391011644154787, 0.006010112352669239, -0.036566294729709625, -0.014035956002771854, -0.0027589888777583838, -0.013712359592318535, 0.05199101194739342, 0.017555056139826775, -0.002162359654903412, 0.01388764102011919, -0.008346067741513252, -0.015465169213712215, 0.016692135483026505, -0.007955056615173817, -0.011191011406481266, 0.043307866901159286, 0.03182022646069527, -0.007125842850655317, 0.0028955056332051754, 0.010382022708654404, 0.02453932724893093, 0.012262921780347824, -0.01319325901567936, 0.010011236183345318, 0.01771685481071472, -0.0013044944498687983, -0.02177528105676174, -0.009067416191101074, -0.0529618002474308, 0.027006741613149643, 0.005935955327004194, 0.0018404495203867555, -0.011817977763712406, -0.009229213930666447, -0.0200898889452219, 0.005851685535162687, -0.017217978835105896, 0.019577529281377792, 0.008635954931378365, -0.01207415759563446, -0.011608988977968693, 0.01396853942424059, -0.02449887804687023, -0.004368539433926344, -0.005110112484544516, 0.018121348693966866, -0.024175282567739487, 0.004634831566363573, 0.008622472174465656, 0.019550561904907227, -0.012586517259478569, 0.0004609550815075636, 0.0004942415980622172, 0.028880899772047997, -0.016341574490070343, -0.007058427203446627, -0.002661236096173525, -0.0008831460727378726, 0.009856180287897587, -0.00469550583511591, -0.004129213746637106, -0.005558426957577467, -0.011494382284581661, -0.01442696712911129, 0.0055921352468431, 0.008420225232839584, -0.01276179775595665, -0.018080899491906166, -0.0054640453308820724, -0.021128090098500252, -0.01207415759563446, -0.013146067969501019, 0.00014420646766666323, -0.030310112982988358, -0.03659325838088989, 0.016341574490070343, 0.010557304136455059, 0.013294382952153683, 0.005966292228549719, -0.01991460658609867, 0.020507866516709328, 0.040017977356910706, -0.004820224829018116, 0.005022472236305475, 0.0034752809442579746, 0.004408989101648331, -0.022624719887971878, -0.0015117977745831013, -0.00822471920400858, 0.0016592696774750948, 0.021370787173509598, -0.018067415803670883, -0.027573034167289734, -0.011703371070325375, -0.00037373596569523215, 0.013665169477462769, 0.003866292303428054, -0.015478651970624924, 0.00469550583511591, 0.005467415787279606, 0.003731460776180029, 0.018498877063393593, -0.025644944980740547, 0.022665169090032578, -0.0009514045086689293, -0.0064314608462154865, -0.0012042134767398238, -0.02379775419831276, -0.00042450844193808734, 0.004867415875196457, 0.007456180173903704, 0.011420224793255329, -0.040368542075157166, -0.018080899491906166, -0.0022702247370034456, 0.015411236323416233, -0.0032747192308306694, -0.010274157859385014, -0.021707866340875626, -0.0010828651720657945, -0.00939101167023182, -0.0033691013231873512, 0.018283147364854813, -0.014656180515885353, -0.008035955019295216, 0.009808989241719246, -0.0044662924483418465, 0.008582022972404957, -0.007591011468321085, 0.011029213666915894, -0.03524494543671608, -0.016746068373322487, -0.01650337129831314, -0.018579775467514992, -0.006340449675917625, 0.025644944980740547, 0.008710112422704697, -0.007307865656912327, -0.01607191003859043, -0.0127011239528656, -0.039155058562755585, -0.023029213771224022, -0.006161797791719437, -0.002435393398627639, 0.021316854283213615, 0.030687641352415085, -0.00164915737695992, 0.030471911653876305, -0.0010154495248571038, 0.03330337256193161, -0.03546067699790001, -0.011130337603390217, 0.01715056225657463, -0.01930786669254303, -0.00753707904368639, 0.006744944024831057, -0.019469663500785828, -0.0068292138166725636, 0.03896629437804222, 0.004550561774522066, -0.003542696824297309, 0.033276405185461044, -0.0018337079090997577, -0.027667416259646416, -0.008022472262382507, 0.007017978001385927, 0.0011098315007984638, -0.007671910338103771, 0.0011772472644224763, -0.007038202602416277, -0.01086067408323288, -0.002344381995499134, -0.01326067466288805, -0.007193258497864008, 0.004065168555825949, 0.010530337691307068, 0.0018994382116943598, 0.005801123566925526, -0.027222473174333572, -0.012970786541700363, -0.01870112493634224, -0.014858427457511425, 0.027438202872872353, 0.004661798011511564, -0.015047191642224789, 0.03683595731854439, -0.009222472086548805, -0.003043820383027196, -0.016220225021243095, 0.023352809250354767, -0.016611237078905106, -0.012519101612269878, 0.002617415739223361, -0.023352809250354767, -0.023514607921242714, -0.003124719252809882, -0.005197753198444843, -0.02177528105676174, 0.007314607035368681, -0.005015730392187834, -0.010092135518789291, -0.015707865357398987, -0.008871910162270069, 0.006633708253502846, -0.024714607745409012, -0.04578876495361328, -0.02319101244211197, 0.018431460484862328, -0.0006547753000631928, -0.009316854178905487, -0.011750562116503716, -0.014804494567215443, 0.02146516926586628, 0.01084044948220253, -0.011892135255038738, -0.007570786867290735, 0.019968539476394653, 0.011892135255038738, -0.019146068021655083, 0.02107415720820427, 0.22996854782104492, -0.0002972612564917654, 0.012950561940670013, 0.04082696884870529, 0.013382023200392723, 0.01245842780917883, 0.014817978255450726, 0.001580056268721819, -0.01071236003190279, 0.0076516857370734215, 0.00699775293469429, 0.003923595417290926, -0.001387078664265573, -0.0009379214025102556, 0.027397753670811653, 0.012977528385818005, -0.02077752910554409, -0.04028764367103577, -0.011575281620025635, -0.029770787805318832, -0.0008165730396285653, -0.004530337173491716, -0.00020172051154077053, -0.010631460696458817, 0.005838202312588692, -0.009080898948013783, -0.011022472754120827, -0.0038932585157454014, 0.01899775303900242, 0.015262922272086143, -0.010314607061445713, -0.013422472402453423, 0.010442697443068027, 0.007685393560677767, -0.04228314757347107, 0.02099325880408287, 0.014952809549868107, 0.011501124128699303, 0.022449439391493797, 0.014386516995728016, 0.0015573034761473536, -0.017393259331583977, -0.023164045065641403, -0.018849438056349754, -0.0015733146574348211, 0.014103371649980545, 0.008008989505469799, -0.01977977529168129, 0.008440449833869934, 0.0021994381677359343, -0.009721348993480206, 0.014278652146458626, 0.020319102331995964, 0.012296630069613457, 0.00889887660741806, -0.007085393648594618, 0.01662471890449524, 0.013651685789227486, -0.024215731769800186, 0.010577528737485409, -0.008157303556799889, 0.015842696651816368, -0.005217977799475193, 0.01754157431423664, -0.011278651654720306, -0.005261797923594713, -0.015478651970624924, -0.021087640896439552, -0.014561798423528671, -0.0021387641318142414, 0.002919101156294346, 0.005474157631397247, -0.0018185393419116735, 0.0013626405270770192, -0.006289887707680464, -0.01464269682765007, 0.006542697083204985, 0.028773033991456032, 0.017730338498950005, 0.027640450745821, -0.020184271037578583, 0.0008557584369555116, 0.018849438056349754, -0.02336629293859005, -0.025644944980740547, -0.022907866165041924, -0.0027353933546692133, 0.0010078651830554008, -0.009748314507305622, -0.017083147540688515, -0.017959551885724068, -0.01250561885535717, -0.012519101612269878, -0.01597752794623375, 0.017851686105132103, 0.0019264045404270291, -0.015950562432408333, 0.016166292130947113, -0.00659662950783968, -0.001004494377411902, -0.032764047384262085, 0.03991011530160904, 0.0040685394778847694, 0.01471011247485876, 0.0037516856100410223, 8.574438834330067e-05, -0.004496629349887371, 0.006886517163366079, -0.0095258429646492, -0.011804495006799698, 0.01956404559314251, 0.006434831768274307, 0.01572134904563427, -0.008400000631809235, -0.012498877011239529, 0.0212089903652668, 0.0026393260341137648, -0.017123596742749214, 0.002042696811258793, 0.00411573052406311, -0.01991460658609867, -0.005137078929692507, -0.01689438335597515, 0.004230337217450142, -0.01658426970243454, -0.012991012074053288, -0.005511236377060413, -0.004735955037176609, 0.012343821115791798, -0.014912360347807407, 0.0035258429124951363, 0.007591011468321085, 0.006559550762176514, 0.0033657304011285305, -0.007166292518377304, 1.7393786038155667e-05, 0.00045716293971054256, 0.011420224793255329, -0.019847191870212555, 0.015667416155338287, 0.009815731085836887, -0.008015730418264866, 0.0019719102419912815, -0.013361798599362373, 0.0014688202645629644, -0.004948314744979143, 0.009552809409797192, -0.019105618819594383, -0.001889325911179185, -0.01711011305451393, -0.02734382078051567, -0.013233708217740059, -0.00829213485121727, 0.008056179620325565, 0.028826966881752014, -0.016597753390669823, -0.018943820148706436, -0.02730337157845497, 0.016341574490070343, -0.014656180515885353, -0.0340314619243145, -0.000589887669775635, 0.026844944804906845, -0.01883595623075962, 0.00334213487803936, -0.0028230338357388973, -0.1761438250541687, 0.0017780899070203304, 0.017608989030122757, -0.022786518558859825, 0.008710112422704697, -0.012424719519913197, 0.02599550597369671, 0.00697752833366394, -0.0006695225019939244, 0.0031988765113055706, -0.007402247283607721, -0.015195505693554878, -0.03537977486848831, -0.006266292184591293, -0.013644943945109844, 0.006259550806134939, -0.03484044969081879, 0.01075280923396349, 0.018984271213412285, 0.02920449525117874, 0.0037516856100410223, -0.01069213543087244, 0.019119102507829666, -0.03122696653008461, 0.008521348237991333, -0.005811236333101988, -0.0069303372874855995, 0.027060674503445625, -0.004355056211352348, -0.008130337111651897, 0.0036067417822778225, -0.004773033782839775, -0.002428651787340641, 0.005194382276386023, 0.012000000104308128, -0.002334269694983959, 0.010651686228811741, -0.002993258647620678, -0.009444944560527802, 0.020885394886136055, 0.014332585036754608, 0.04117752984166145, 0.003212359733879566, -0.024337079375982285, 0.001838764059357345, 0.007301123812794685, 0.01977977529168129, -0.004867415875196457, 0.0017595506506040692, -0.01336853951215744, 0.0223685409873724, -0.034570787101984024, -0.006121348589658737, -0.0024775280617177486, 0.00019592697208281606, -0.0008308989345096052, 0.003370786551386118, -0.013334832154214382, -0.006198876537382603, 0.008305618539452553, 0.016004495322704315, -0.03540674224495888, 0.010894382372498512, 0.02604943886399269, -0.010739326477050781, -0.011905618011951447, -0.026966292411088943, 0.013206741772592068, -0.00809662975370884, 0.009714607149362564, -0.018471911549568176, -0.021613484248518944, -0.008278652094304562, -0.005764045286923647, 0.002833146136254072, -0.009923595935106277, -0.026184270158410072, 0.022408990189433098, -0.01071236003190279, -0.00900674145668745, -0.02604943886399269, 0.02440449595451355, -0.007415730506181717, 0.019334832206368446, 0.004395505879074335, 0.015128090046346188, -0.02052134834229946, -0.00809662975370884, 0.005467415787279606, 0.013570787385106087, 0.04479101300239563, -0.008696629665791988, -0.015883145853877068, -0.003987640608102083, 0.0036539328284561634, 0.018768539652228355, -0.0017848315183073282, 0.01956404559314251, 0.0039033708162605762, 0.0023612361401319504, -0.0017898876685649157, -0.020723596215248108, -0.00958651676774025, 0.01019325852394104, 0.02915056236088276, 0.014750562608242035, 0.01396853942424059, -0.003495505778118968, 0.02203146182000637, -0.00023890449665486813, -0.04586966335773468, 0.0042438204400241375, 0.015168540179729462, 0.012269663624465466, -0.006064045242965221, 0.037779778242111206, -0.022867416962981224, -0.033492136746644974, 0.00597303407266736, -0.0022887641098350286, 0.04085393249988556, 0.007476404774934053, -0.002049438189715147, 0.011555057018995285, 0.010233708657324314, -0.008420225232839584, -0.08359550684690475, -0.01250561885535717, 0.018674157559871674, 0.03465168550610542, -0.018256179988384247, 0.015262922272086143, -0.011507865972816944, 0.02069663070142269, 0.005029213614761829, 0.0020123596768826246, 0.0030606742948293686, -0.018768539652228355, -0.00835955049842596, -0.02280000038444996, 0.024471910670399666, 0.012337079271674156, -0.0007596910581924021, -0.0057573034428060055, -0.0014941011322662234, 0.021829213947057724, -0.009835955686867237, -0.0026089888997375965, 0.013503370806574821, -0.013247191905975342, 0.002450561849400401, -0.005908988881856203, -0.027613483369350433, 0.023217977955937386, 0.007314607035368681, -0.011703371070325375, -0.0035191013012081385, -0.009808989241719246, 0.020979775115847588, -0.013071910478174686, -0.0047966293059289455, 0.01770337112247944, -0.042822472751140594, -0.009337078779935837, 0.007065168581902981, -0.007591011468321085, 0.002489325823262334, 0.026575282216072083, 0.014008989557623863, -0.04020674154162407, 0.0006867977790534496, -0.011925843544304371, -0.007793258875608444, 0.037725843489170074, 0.005224719177931547, -0.027316855266690254, -0.035568539053201675, 0.016422472894191742, -0.03028314746916294, -0.009303371421992779, 0.03014831617474556, 0.016557304188609123, 0.022408990189433098, -0.001641573035158217, -0.005143820308148861, -0.007665168959647417, -0.006886517163366079, -0.009074158035218716, -0.0026089888997375965, 0.02993258461356163, -0.004735955037176609, 0.005376404616981745, -0.01640898920595646, 0.0008477528463117778, -0.0011823034146800637, -0.013671910390257835, 0.00413595512509346, 0.0022870786488056183, -0.011231460608541965, 0.02089887671172619, -0.007833708077669144, -0.004479775670915842, -0.030094383284449577, -0.024391012266278267, 0.01308539416640997, -0.005268539302051067, -0.017339326441287994, -0.01576179824769497, -0.01066516898572445, 0.004098876379430294, 0.021235955879092216, 0.023528091609477997, 0.004176404792815447, 0.004773033782839775, 0.014629214070737362, -0.03540674224495888, 0.01866067573428154, 0.041662923991680145, -0.009020225144922733, -0.02181573025882244, -0.004537079017609358, 0.0067382026463747025, -0.0008389045251533389, 0.005042696837335825, 0.007220224943011999, -0.004082022700458765, -0.03953258693218231, -0.026278652250766754, -0.06520449370145798, 0.011730337515473366, 0.01067191082984209, -0.024674158543348312, -0.0037584269884973764, 0.01826966367661953, -0.004941573366522789, -0.0041224719025194645, -0.017433708533644676, 0.006714607123285532, -0.02599550597369671, 0.005706741940230131, 0.00879101175814867, -0.0011089887702837586, -0.026292135939002037, -0.0035157303791493177, 0.02064269781112671, 0.0018404495203867555, 0.025456180796027184, 0.025968540459871292, 0.0008401685627177358, -0.02150561846792698, -0.0029764045029878616, 0.011022472754120827, -0.014332585036754608, 0.005544944200664759, -0.02985168620944023, 0.026898877695202827, -0.010341573506593704, -0.021303372457623482, -0.002123595681041479, -0.03918202221393585, 0.0036033708602190018, 0.010995506308972836, -0.0008755618473514915, -0.00250617996789515, -0.0043449439108371735, 0.03303370997309685, 0.005362921394407749, 0.015195505693554878, -0.00831235945224762, -0.022516854107379913, 0.006832584738731384, -0.025200000032782555, 0.0025129213463515043, 0.028449438512325287, -0.025712359696626663, -0.0200494397431612, 0.03554157540202141, 0.009343820624053478, 0.01202696654945612, -0.003950561862438917, -0.02850337140262127, -0.024202248081564903, -0.00872359611093998, -0.00883146096020937, 0.014507865533232689, 0.0014949438627809286, 0.017811236903071404, -0.011015730910003185, 0.03573033958673477, -0.005996629595756531, -0.0024808989837765694, 0.008649438619613647, -0.008817978203296661, 0.009532584808766842, -0.028611237183213234, 0.005608988925814629, -0.008494382724165916, -0.021492134779691696, -0.035137079656124115, -0.023393258452415466, -0.010530337691307068, 0.0382651686668396, 0.02712809108197689, 0.016921348869800568, -0.008170787245035172, 0.022408990189433098, 0.007166292518377304, 0.027829214930534363, 0.01965842768549919, 0.021316854283213615, -0.007928090170025826, 0.00933033786714077, 0.042256180197000504, 0.016651686280965805, -0.022611236199736595, 0.004365168511867523, -0.013550561852753162, 0.009653933346271515, -0.01086067408323288, 0.010719101876020432, 0.013766292482614517, 0.001165449502877891, -0.008548314683139324, -0.013901123777031898, -8.000351226655766e-05, 0.004439326003193855, 0.02195056341588497, 0.018121348693966866, 0.005271910224109888, 0.009532584808766842, -0.002865168731659651, -0.023487640544772148, -0.0089865168556571, -0.003143258625641465, -0.03680898994207382, -0.047191012650728226, -0.000733567459974438, 0.020844943821430206, -0.008015730418264866, -0.013489888049662113, 0.016139326617121696, 0.014521349221467972, -0.03473258391022682, 0.016746068373322487, -0.013483146205544472, -0.010348315350711346, -0.03632359579205513, 0.031253933906555176, -0.014737078920006752, -0.0016382023459300399, 0.039505619555711746, -0.008946067653596401, 0.02362247183918953, 0.008824719116091728, 0.024647191166877747, -0.016665169969201088, -0.00017285815556533635, 0.008177528157830238, -0.0071797757409513, 0.018215730786323547, -0.01276179775595665, -0.02669662982225418, 0.0026308989617973566, -0.011069662868976593, -0.014332585036754608, 0.044764045625925064, -0.003721348475664854, 0.07491236180067062, -0.0030303371604532003, -0.009087640792131424, 0.011062921956181526, -0.015600000508129597, 0.027640450745821, 0.0212089903652668, 0.014413483440876007, -0.012316854670643806, 0.007119101472198963, 0.022665169090032578, 0.007112359628081322, -0.0010095506440848112, -0.016651686280965805, -0.020939325913786888, -0.012714607641100883, -0.01001797802746296, 0.011582022532820702, 0.0032342697959393263, 0.00206797756254673, 0.014251685701310635, -0.0051573035307228565, 0.02107415720820427, 0.016692135483026505, -0.010355056263506413, -0.002453932771459222, 0.028179775923490524, -0.02720898948609829, -0.010975281707942486, -0.016570787876844406, -0.0021168540697544813, -0.003937078639864922, -0.022260675206780434, -0.02526741661131382, 0.0004415730363689363, 0.015465169213712215, -0.008217977359890938, -0.027262922376394272, -0.0056932587176561356, 0.009040449745953083, 0.003997752908617258, 0.028179775923490524, -0.013719101436436176, 0.0024219101760536432, -0.03424719348549843, 0.011116853915154934, -0.00939775351434946, -0.0006509831873700023, -0.01338876411318779], index=0, object='embedding'),\n",
       " Embedding(embedding=[-0.033269647508859634, -0.00999615527689457, 0.00782488752156496, 0.02000618539750576, -0.005979657173156738, 0.016301849856972694, -0.007519661448895931, -0.0157330185174942, -0.034213073551654816, -0.01392940990626812, 0.0059692515060305595, 0.03393559530377388, -0.016634823754429817, 0.008192546665668488, 0.007207498420029879, 0.004831590689718723, 0.01868816278874874, 0.0035395824816077948, 0.0037598307244479656, -0.022836463525891304, 0.0033505503088235855, 0.0010934378951787949, -0.010578859597444534, -0.013339769095182419, -0.02520890347659588, 0.006531145423650742, 0.005448979791253805, -0.011848323047161102, -0.01545554120093584, 0.00973255094140768, -0.006170423701405525, 0.009018043987452984, 0.0009243495296686888, -0.019409606233239174, -0.013825356028974056, -0.016371218487620354, -0.018341315910220146, -0.0063195680268108845, 0.0069924527779221535, -0.009156784042716026, 0.038652725517749786, -0.005063978955149651, 0.0012217715848237276, -0.000659878074657172, -0.006614388898015022, -0.009330207481980324, 0.005996999330818653, -0.01767536625266075, -0.020921863615512848, 0.01603824459016323, 0.03523974120616913, -0.010329129174351692, -0.019909067079424858, -0.014061212539672852, -0.0017932034097611904, 0.026291068643331528, 0.007970564067363739, 0.01003777701407671, -0.015344549901783466, 0.0009321536053903401, 0.018147079274058342, 0.00840065535157919, -0.004751815926283598, 0.02498692087829113, -0.023169437423348427, -0.009704803116619587, 0.0007908131228759885, 0.006375063676387072, -0.004051182884722948, -0.000602648186031729, 0.01945122890174389, -0.010884085670113564, -0.012888866476714611, -0.002082821447402239, 0.017578249797225, -0.01505319681018591, -0.0077485814690589905, -0.005237402860075235, 0.008581016212701797, 0.005070915911346674, 0.014983827248215675, -0.020283663645386696, -0.0015200607012957335, 0.0185355506837368, 0.02093573659658432, 0.016079867258667946, 0.0003973575949203223, 0.013041479513049126, -0.010134894400835037, -0.002993297064676881, 0.02022816799581051, 0.020186545327305794, 0.02389088086783886, 0.015746893361210823, -0.014623105525970459, 0.00999615527689457, 0.010294444859027863, 0.05710503086447716, 0.013880851678550243, -0.024223854765295982, -0.017786357551813126, 0.020519519224762917, -0.022295380011200905, -0.009018043987452984, -0.03379685431718826, 0.005532223265618086, 0.0023707051295787096, -0.007318489719182253, -0.0016848135273903608, 0.010662103071808815, 0.008511646650731564, 0.04026209935545921, 0.0032256850972771645, -0.034268569201231, -0.01354094035923481, 0.0048246537335217, 0.00638546934351325, -0.026499176397919655, -0.01563590206205845, -0.0218791626393795, -0.007103444077074528, -0.005920692812651396, 0.01859104633331299, -0.014623105525970459, 0.00961462315171957, 0.015358423814177513, -0.022683849558234215, -0.01781410537660122, -0.004963392857462168, 0.013312021270394325, 0.023557906970381737, 0.02654079906642437, 0.020450150594115257, -0.01587175764143467, -0.030161889269948006, 0.0044639320112764835, -0.03457379341125488, -0.004276634193956852, -0.021671054884791374, -0.02162943221628666, 0.007540472317487001, 0.009496694430708885, -0.004332129843533039, 0.014761844649910927, 0.006784344092011452, 0.025195028632879257, 0.029162967577576637, 0.017078788951039314, -0.012659947387874126, -0.017495006322860718, 0.019409606233239174, -0.013277336023747921, 0.009829668328166008, -0.006756596267223358, 0.005320646334439516, -0.003184063360095024, 0.011924629099667072, 0.01284724473953247, -0.037570562213659286, 0.008067681454122066, 0.016842931509017944, 0.010530301369726658, 0.02264222875237465, 0.0002577513223513961, 0.013145534321665764, 0.02108835056424141, 0.0353507325053215, -0.016690319404006004, 0.004408436361700296, 0.0017264352645725012, -0.019367985427379608, 0.0016596670029684901, -0.019048884510993958, 0.012701569125056267, 0.013742112554609776, 0.016634823754429817, 0.012555892579257488, -0.007387859281152487, -0.01727302372455597, -0.04553418606519699, 0.008657322265207767, 0.016759688034653664, 0.01759212277829647, 0.007093038875609636, -0.014539862051606178, -0.00661785714328289, 0.004186453763395548, -0.011272555217146873, 0.005015420261770487, 0.010669040493667126, -0.0025441290345042944, 0.013610309921205044, 0.01241715345531702, 0.00844227708876133, -0.6903659701347351, -0.015830136835575104, 0.011452916078269482, -0.027581341564655304, 0.016218606382608414, -0.0008120575803332031, 0.00010904029477387667, -0.011806701309978962, -0.020533394068479538, 0.03005089797079563, -0.002068947535008192, 0.0025736112147569656, -0.013270399533212185, -0.01207030564546585, -0.0007838761666789651, -0.015913380309939384, 0.0021331142634153366, -0.018896272405982018, 0.010537237860262394, 0.007873446680605412, -0.0245845764875412, 0.013943283818662167, -0.0002573177625890821, 0.027414854615926743, -0.006933488883078098, -0.006895335391163826, 0.009704803116619587, -0.002278790343552828, -0.026970889419317245, -0.004037308972328901, -0.01571914553642273, 0.00527555588632822, 0.019367985427379608, -0.029939906671643257, 0.043120127171278, 0.019825823605060577, -0.00698551582172513, 0.008546330966055393, 0.03005089797079563, 0.019798075780272484, -0.028968732804059982, -0.0011697444133460522, 0.005709115881472826, -0.0031424416229128838, -0.010377688333392143, 0.02894098497927189, 0.02522277645766735, 1.84398413693998e-05, -0.010495616123080254, -0.015830136835575104, 0.0005900749238207936, -0.006812091916799545, 0.012389405630528927, -0.002760909032076597, -0.00010210333857685328, 0.014130582101643085, 0.020436275750398636, -0.004210732877254486, -0.0017663227627053857, -0.00630222586914897, 0.011938503012061119, 0.005958846304565668, 0.00026924064150080085, -0.018466180190443993, -0.01922924630343914, 0.012396343052387238, -0.012285351753234863, -0.024875929579138756, 0.024723315611481667, -0.014678601175546646, -0.00032213496160693467, 0.008241104893386364, 0.010134894400835037, -0.013707427307963371, 0.009351018816232681, -0.0032014057505875826, -0.0028164046816527843, -0.019659336656332016, 0.007630653213709593, 0.010100210085511208, 0.0005432504694908857, -5.4628537327516824e-05, -0.043231118470430374, 0.011237870901823044, 0.01280562300235033, 0.0020550736226141453, -0.00011120809358544648, -0.012965173460543156, -0.01921537145972252, -0.004661635495722294, -0.012202108278870583, -0.011688772588968277, 0.0004461330536287278, -0.04117777943611145, 0.0030193105340003967, -0.008747503161430359, -0.007609841879457235, 0.004429247230291367, 0.01999231055378914, -0.03893020376563072, -0.007998311892151833, 0.009496694430708885, 0.0027036790270358324, 0.0030019681435078382, 0.042842648923397064, -8.096730016404763e-05, -0.014928331598639488, 0.009781110100448132, 0.011411294341087341, 4.563217225950211e-05, 0.012507334351539612, 0.01680131070315838, -0.01354094035923481, -0.0078665092587471, -0.0015096552670001984, -0.03954065591096878, 0.025819355621933937, -0.00032256852136924863, 0.013721301220357418, -0.01688455417752266, 0.03027288056910038, 0.022059524431824684, 0.00318232923746109, -0.006687226705253124, 0.02520890347659588, 0.006378532387316227, -0.005716052837669849, -0.0065658302046358585, 0.011147690005600452, 0.00890705268830061, 0.0020672131795436144, -0.015996623784303665, 0.021365828812122345, -0.01673194020986557, 0.00999615527689457, 0.0009356220834888518, 0.019728707149624825, -0.012195170857012272, 0.03360262140631676, -0.041455257683992386, -0.004717131145298481, 0.01221598219126463, 0.00046737748198211193, -0.004828122444450855, -0.0018747126450762153, -0.0116402143612504, -0.01882690191268921, -5.365302786231041e-05, -0.024945298209786415, 0.004921771120280027, 0.012854182161390781, 0.00143421592656523, -0.009378766641020775, 0.013672742992639542, -0.003367892699316144, 0.014997701160609722, 0.010564985685050488, -0.004200327675789595, -0.009038855321705341, -0.023557906970381737, 0.017689241096377373, 0.022364750504493713, 0.00864344835281372, -0.019520597532391548, -0.0032464959658682346, -0.03457379341125488, 0.0033349422737956047, 0.016926174983382225, -0.0010856337612494826, -0.02593034692108631, 0.0035794698633253574, -0.036294158548116684, 0.008019122295081615, 0.01533067598938942, 0.009801920503377914, 0.02608295902609825, -0.025084037333726883, 0.01953447237610817, 0.008886242285370827, -0.020658258348703384, 0.009586875326931477, 0.032575950026512146, -0.008934800513088703, -0.0032048742286860943, 0.045867159962654114, 0.0224202461540699, 0.025708364322781563, 0.02358565479516983, -0.008934800513088703, 0.02816404588520527, 0.014525988139212132, 0.005979657173156738, -0.013991842977702618, 0.006819028872996569, 0.0036904611624777317, 0.006312631070613861, -0.004706725478172302, 0.006687226705253124, 0.004682446364313364, 0.005448979791253805, 0.052415650337934494, 0.007623716257512569, 0.013221840374171734, -0.0009685726836323738, -0.002204218180850148, -0.05854791775345802, 0.0001670289202593267, -0.022780967876315117, 0.023863133043050766, 0.01610761508345604, -0.0019180687377229333, -0.027609089389443398, -0.01696779765188694, -0.008470024913549423, -0.02669341117143631, 0.01241715345531702, 0.0019527535187080503, 0.0034892894327640533, 0.0009252166491933167, 0.004772626794874668, -0.004040777683258057, -0.03371361270546913, 0.027831071987748146, 0.007949752733111382, -0.03931867331266403, 0.004689383320510387, -0.0003321068361401558, 0.028150172904133797, 0.0036696502938866615, 0.0014966485323384404, 0.018008340150117874, 0.025722237303853035, 0.019021136686205864, 0.006621325854212046, 0.010134894400835037, 0.007422544062137604, 0.03604442998766899, -0.01750887930393219, 0.029856663197278976, 0.01642671413719654, -0.005310240667313337, 0.02250348962843418, 0.02778945118188858, -0.011654088273644447, 0.011334988288581371, 0.004561049398034811, 0.02341916784644127, -0.0064756497740745544, -0.01276400126516819, -0.0011350596323609352, 0.005917224567383528, 0.01264607347548008, -0.01882690191268921, 0.004016498103737831, -0.0010258025722578168, -0.015469415113329887, 0.018396811559796333, 0.009281649254262447, 0.00914291013032198, 0.01354094035923481, -0.009038855321705341, 0.004509021993726492, 0.017605997622013092, 0.002660323167219758, 0.004630418960005045, 0.0034771498758345842, 0.01214661169797182, 0.00969092920422554, -0.019978437572717667, -0.001457628095522523, 0.0030990857630968094, -0.01362418383359909, -0.009808857925236225, -0.03043936751782894, 0.011182375252246857, -0.011175437830388546, -0.0009243495296686888, -0.007165876682847738, 0.001593765919096768, 0.025638993829488754, -0.03182676061987877, -0.007651464082300663, -0.025167280808091164, 0.002864963375031948, -0.01082165353000164, -0.011667962186038494, -0.024334846064448357, 0.014047338627278805, 0.005164564587175846, -0.012874992564320564, 0.009781110100448132, 0.013984905555844307, -0.011175437830388546, -0.005129879806190729, -0.026193950325250626, 0.005157627630978823, 0.009621559642255306, -0.01241715345531702, -0.017078788951039314, -0.008317411877214909, 0.006975110620260239, -0.0013449025573208928, 0.009073539637029171, -0.025583498179912567, 0.017314644530415535, -0.007367048412561417, -0.027331611141562462, -0.01225760392844677, 0.00300543662160635, 0.004838527645915747, 0.00457145506516099, -0.0015547455986961722, -0.017314644530415535, 0.010343003086745739, 0.01922924630343914, -0.0034077803138643503, 0.007228309288620949, 0.001866041449829936, 0.036543890833854675, 0.009704803116619587, 0.0051715015433728695, -0.006888398434966803, -0.019714832305908203, 0.021837541833519936, 0.05144447460770607, 0.0178973488509655, -0.006825965829193592, -0.0074711027555167675, 0.00486627547070384, -0.008081555366516113, -0.006094117183238268, -0.011813637800514698, 0.018077710643410683, -0.0087891248986125, -0.019048884510993958, -0.018729785457253456, -0.0036002807319164276, -0.0038118581287562847, 0.003218748141080141, -0.008768313564360142, -0.007131191901862621, -0.012313099578022957, 0.004581860266625881, -0.011834449134767056, -0.017869601026177406, 0.010835527442395687, 0.02076924964785576, 0.01245877519249916, 0.014088960364460945, -0.01517806202173233, 0.02809467725455761, 0.024265475571155548, 0.01596887595951557, -0.010377688333392143, -0.00457145506516099, 0.010197327472269535, 0.0017949376488104463, 0.01603824459016323, 0.004550643730908632, 0.0246816948056221, 0.017495006322860718, -0.008192546665668488, 0.018008340150117874, -0.007367048412561417, -0.0016093740705400705, 0.008157861419022083, 0.016634823754429817, -0.01397796906530857, -0.003898570081219077, -0.0058443862944841385, -0.002185141434893012, 0.016607075929641724, 0.0012148346286267042, -0.01381148211658001, 0.017772484570741653, -0.006926551926881075, -0.017758609727025032, -0.022600606083869934, 0.0020620105788111687, 0.02225375920534134, 0.014373375102877617, 0.006697632372379303, -0.021893037483096123, -0.0530538484454155, -0.017023293301463127, -0.01977032795548439, 0.023016823455691338, 0.000152071108459495, -0.03174351528286934, 0.010849401354789734, -0.052970606833696365, -0.002570142736658454, -0.03851398825645447, 0.0052963667549192905, -0.041455257683992386, -0.01120318565517664, -0.018799154087901115, 0.010107146576046944, 0.029773419722914696, 0.015427793376147747, 0.00573686370626092, -0.00709997583180666, -0.00808849185705185, -0.0031649868469685316, -0.013020669110119343, -0.010322192683815956, -0.007256057113409042, -0.01596887595951557, -0.017605997622013092, 0.015899505466222763, 0.0023030699230730534, -0.007269931025803089, -0.0008289663819596171, 0.005858260206878185, -0.011806701309978962, -0.00402690377086401, 0.012611388228833675, -0.004033840727061033, -0.00860182661563158, 0.009593811817467213, 0.029440445825457573, 0.01085633784532547, -0.001024068333208561, -0.019811950623989105, -0.0014212090754881501, -0.01311778649687767, -0.0016223809216171503, -0.004932176787406206, 0.01483121421188116, -0.015511036850512028, 0.017106536775827408, 0.014456618577241898, -0.006579704117029905, 0.005875602830201387, 0.015275180339813232, -0.01970095932483673, 0.009309397079050541, 0.01626022718846798, 0.003978345077484846, 0.017259148880839348, -0.005896413698792458, 0.015538784675300121, -0.005913755856454372, 0.0070444801822304726, -0.007380922324955463, -0.017495006322860718, 0.009052729234099388, -0.003676587250083685, -0.007609841879457235, 0.02007555402815342, -0.0010977734345942736, -0.02108835056424141, -0.006447901949286461, 0.01116850133985281, -0.019437354058027267, 0.022198263555765152, -0.0027921253349632025, -0.019367985427379608, -0.04103903844952583, -0.01082165353000164, -0.012895803898572922, 0.013027605600655079, -0.01303454302251339, -0.013429949060082436, 0.008733629249036312, -0.014234635978937149, 0.006590109318494797, -0.018174827098846436, 0.009378766641020775, -0.020963484421372414, -0.0035898752976208925, -0.009947597049176693, 0.008823809213936329, 0.023322049528360367, 0.002481696428731084, 0.014914457686245441, -0.017453383654356003, -0.003954065497964621, -0.02375214174389839, -0.017217528074979782, -0.003126833587884903, -0.014019590802490711, 0.015566532500088215, 0.029162967577576637, 0.044951483607292175, -0.02061663754284382, 0.012361657805740833, 0.01899338886141777, -0.016065992414951324, 0.007970564067363739, -0.02443196438252926, -0.005386547185480595, -0.008164798840880394, 0.00969786662608385, 0.017259148880839348, -0.007016732357442379, 0.0035794698633253574, -0.028968732804059982, 0.029828915372490883, 0.026554672047495842, -0.0012798686511814594, 0.008143987506628036, -0.0016275836387649179, -0.006777407135814428, -0.01284724473953247, 0.005018888507038355, -2.602713902888354e-05, 0.01602437160909176, 0.009052729234099388, -0.013249588198959827, 0.024265475571155548, 0.0029828916303813457, 0.010911833494901657, 0.008809935301542282, 0.01311778649687767, -0.0036349655129015446, 0.0062848832458257675, 0.007526598405092955, 0.016079867258667946, -0.018632667139172554, 0.009191468358039856, -0.012056431733071804, -0.007193624507635832, 0.022212136536836624, 0.003697398118674755, 0.016301849856972694, -0.007720833644270897, -0.0065138028003275394, -0.003027981845661998, -0.02513953298330307, -0.047282300889492035, -0.019104380160570145, -0.012361657805740833, 0.006701100617647171, -0.017703114077448845, -0.010072462260723114, -0.019798075780272484, -0.00439456244930625, -0.0006351651391014457, 0.0015608153771609068, -0.005504475440829992, 0.02894098497927189, -0.012202108278870583, -0.01385310385376215, -0.009753362275660038, -0.005788890644907951, 0.03268694132566452, -0.0033175998833030462, 0.005324114579707384, 0.0063542528077960014, 0.014942205511033535, -0.0078665092587471, -0.019035011529922485, -0.005435105878859758, 0.007304615806788206, 0.03027288056910038, 0.011508411727845669, -0.006933488883078098, -0.020061681047081947, 0.009899037890136242, 0.025638993829488754, -0.018244197592139244, -0.0398736298084259, 0.01155697088688612, -0.005563439801335335, 0.008428403176367283, -0.01954834535717964, -0.02233700267970562, -0.018396811559796333, 0.015067070722579956, -0.015746893361210823, 0.03246495872735977, -0.007769392337650061, -0.0022943986114114523, -0.0015512771205976605, 0.0005298100877553225, -0.03449055179953575, 0.00694389408454299, 0.008546330966055393, -0.01766149327158928, -0.013638057745993137, 0.0280253067612648, -0.023793762549757957, -0.012632199563086033, 0.003151112934574485, 0.03659938648343086, -0.013596436008810997, -0.014033464714884758, -0.0008224630146287382, 0.020131049677729607, -0.014692475087940693, -0.0016119754873216152, -0.017384015023708344, 0.028066929429769516, -0.029523689299821854, -0.0040581198409199715, 0.00852552056312561, 0.0041829850524663925, 0.01509481854736805, 0.011154627427458763, -0.012000936083495617, -0.015594280324876308, 0.005074384156614542, 0.0014290132094174623, 0.012653009966015816, -0.0003732950135599822, -0.011341924779117107, 0.002127911662682891, -0.0034407307393848896, -0.029523689299821854, 0.004682446364313364, -0.004273165483027697, 0.010287507437169552, -0.024778811261057854, 0.001626716461032629, 0.02311394177377224, 0.019562220200896263, 0.0013093507150188088, -0.0015798920067027211, 0.0035794698633253574, 0.0012790014734491706, 0.02498692087829113, 0.0028146703261882067, 0.003548253560438752, 0.00026382115902379155, -0.013631121255457401, 0.001568619511090219, 0.028080802410840988, -0.02763683721423149, 0.003312397049739957, 0.012666883878409863, -0.0210189800709486, -0.004724068101495504, 0.016870679333806038, 0.002750503597781062, 0.008470024913549423, -0.0060108732432127, 0.0005024958518333733, 0.030550360679626465, -0.0030123735778033733, 0.01985357142984867, 0.01444274466484785, -0.02110222354531288, 0.0031771264038980007, -0.02662404254078865, 0.005535691976547241, 0.0206998810172081, -0.010495616123080254, -0.002195546869188547, -0.01159165520220995, 0.0004981602542102337, 0.003288117703050375, -0.02380763739347458, -0.0017793294973671436, -0.005355331115424633, 0.02405736781656742, -0.0005866064457222819, -0.022600606083869934, -0.0030644009821116924, -0.003787578549236059, -0.008220294490456581, 0.04531220346689224, 0.023946376517415047, -0.0003279880038462579, 0.00259615620598197, 0.04303688183426857, 0.011175437830388546, 0.006704569328576326, 0.0019302084110677242, -0.01397103164345026, -0.016301849856972694, -0.015622028149664402, -0.012451838701963425, -0.014817340299487114, -0.03479577600955963, 0.02606908604502678, 0.0025788138154894114, -0.016454461961984634, -0.028691254556179047, -0.018174827098846436, 0.0030626666266471148, -0.007838761433959007, 0.003586406819522381, -0.0025059757754206657, 0.006173891946673393, 0.007297678850591183, -0.0007080031791701913, 0.021116098389029503, 0.004359877668321133, 0.013866977766156197, -0.03199324756860733, 0.004124021157622337, 0.017605997622013092, 0.011140753515064716, 0.01077309437096119, 0.0027834540233016014, -0.04866969212889671, -0.019867446273565292, 0.012666883878409863, 0.020575014874339104, 0.000670283508952707, 0.02194853313267231, 0.021143846213817596, -0.002989828586578369, -0.016468336805701256, -0.00010866093361983076, -0.014817340299487114, 0.003147644456475973, 0.023363672196865082, -0.0134230125695467, -0.023766014724969864, -0.009510568343102932, -0.006218982394784689, -0.03351937606930733, 0.011758142150938511, 0.018466180190443993, -0.0025528003461658955, -0.010544175282120705, -0.0162741020321846, -0.029939906671643257, -0.008664259687066078, -0.0072768679820001125, 0.02561124600470066, 0.026249445974826813, -0.025874851271510124, 0.005050105042755604, 0.002936067059636116, -0.008615700528025627, -0.006492991931736469, -0.006825965829193592, -0.02210114523768425, 0.01147372741252184, 0.009989218786358833, -0.0028614948969334364, -0.022683849558234215, -0.012666883878409863, 0.00844227708876133, -0.020977359265089035, 0.005670962389558554, 0.01875753328204155, -0.02482043392956257, 0.003040121402591467, 0.022767093032598495, 0.03393559530377388, -0.0385972298681736, 0.002443543169647455, -0.002117506228387356, -0.02559737302362919, -0.006829434540122747, -0.003388703567907214, -0.013207966461777687, -0.03324189782142639, 0.011043636128306389, -0.008310474455356598, -0.010884085670113564, -0.016440588980913162, -0.021227089688181877, -0.008379844017326832, -0.007554346229881048, 0.002710615983232856, 0.20688781142234802, -0.013700490817427635, -0.010412372648715973, 0.013943283818662167, -0.0056466832756996155, 0.006107991095632315, 0.014428870752453804, 0.012528144754469395, -0.006007404997944832, 0.005566908046603203, 0.0029620807617902756, -0.008268852718174458, -0.021060602739453316, -0.005899881944060326, -0.005126411560922861, -0.0007938480703160167, -0.011827511712908745, -0.029995402321219444, -0.009663181379437447, 0.0005827044369652867, 0.017605997622013092, -0.017384015023708344, 0.012944362126290798, -0.0026585888117551804, 0.01171652041375637, -0.0077832662500441074, -0.0003568197425920516, -0.014304005540907383, 0.010891023091971874, 0.016371218487620354, -0.0184384323656559, -0.005483664572238922, -0.0007145066047087312, 0.01696779765188694, 0.0033366763964295387, -0.0019978436175733805, 0.021421324461698532, -0.013631121255457401, 0.029162967577576637, 0.010183453559875488, -0.0033002574928104877, -0.0017377077601850033, -0.0006035153055563569, -0.012909677810966969, -0.027844946831464767, 0.0062501984648406506, 0.002707147505134344, -0.01563590206205845, 0.00890705268830061, -0.012979047372937202, -0.010273633524775505, 0.012965173460543156, 0.038957953453063965, 0.021060602739453316, 0.005126411560922861, -0.003787578549236059, -0.007956690154969692, 0.006846776697784662, -0.0033817666117101908, 0.0116402143612504, -0.0015486757038161159, 0.02218438871204853, -0.029912158846855164, 0.00741560710594058, 0.007602904923260212, 0.0154139194637537, -0.009087413549423218, -0.0006282281829044223, 0.020824745297431946, -0.017716988921165466, 0.002525052521377802, -0.009545253589749336, -0.017175905406475067, 0.016829058527946472, 0.0037702361587435007, -0.020741501823067665, 0.02047789841890335, 0.03665488213300705, 0.003756362246349454, 0.03601668030023575, -0.012701569125056267, 0.016718067228794098, 0.003898570081219077, -0.03540622815489769, -0.013284273445606232, -0.023391420021653175, 0.035211995244026184, -0.01389472559094429, -0.02007555402815342, -0.00653461366891861, 0.0010318723507225513, -0.04914140701293945, -0.008685070089995861, 0.02294745482504368, 0.013436886481940746, 0.016163110733032227, 0.010460931807756424, 0.006770470179617405, -0.03274243697524071, -0.04708806425333023, -0.017703114077448845, 0.020047806203365326, -0.0034979607444256544, 0.0336303673684597, -0.014387249015271664, -0.02311394177377224, -0.02164330706000328, 0.005702178925275803, 0.01734239235520363, -0.017772484570741653, 0.0008913989877328277, -0.015205809846520424, 0.013762922957539558, 0.011480663903057575, 0.0029984996654093266, 0.011293366551399231, -0.026943141594529152, -0.021365828812122345, 0.0028528235852718353, 0.01039156224578619, -0.012666883878409863, -0.03959615156054497, 0.0014082023408263922, 0.009295523166656494, 0.016149235889315605, -0.007110381033271551, -0.01431787945330143, 0.00977417267858982, -0.004848933313041925, -0.007124254945665598, 0.010613544844090939, -0.03571145609021187, 0.023835385218262672, -0.02071375399827957, -0.007165876682847738, -0.003038387279957533, -0.01108525786548853, -0.006961236707866192, -0.029551437124609947, 0.012979047372937202, -0.0029048507567495108, 6.942376785445958e-05, 0.0033245368395000696, -0.0014029996236786246, 0.017467258498072624, -0.034740280359983444, 0.03213198482990265, 0.03199324756860733, -0.03596118465065956, -0.021698802709579468, -0.00840065535157919, -0.0007535269833169878, -0.021351953968405724, -0.01039156224578619, 0.035378482192754745, -0.02162943221628666, -0.04273165762424469, -0.011834449134767056, -0.012465712614357471, 0.010988140478730202, -0.04278715327382088, -0.034213073551654816, 0.008622637949883938, -0.0048142485320568085, -0.02552800253033638, -0.0027695801109075546, -0.18135981261730194, 0.00914291013032198, 0.01970095932483673, -0.01388778816908598, 0.017619870603084564, 0.0035309111699461937, 0.026499176397919655, 0.008081555366516113, -0.015580406412482262, -0.0029308644589036703, 0.013256525620818138, -0.011869133450090885, -0.028080802410840988, -0.026360437273979187, 0.006017810199409723, -0.010953455232083797, -0.008331285789608955, 0.01712040975689888, 0.02210114523768425, 0.015302928164601326, 0.01003777701407671, -0.023627275601029396, -0.009170657955110073, 0.002443543169647455, 0.01000309269875288, 0.009947597049176693, -0.003954065497964621, 0.010010029189288616, -0.010786968283355236, -0.00737398536875844, -0.01431787945330143, -0.002048136666417122, 0.020977359265089035, -0.003116428153589368, 0.008317411877214909, 0.013797608204185963, 0.005084789823740721, -0.00864344835281372, -0.011820575222373009, -0.006049026735126972, 0.021268710494041443, 0.01650995761156082, -0.009753362275660038, 0.022004028782248497, 0.0017368406988680363, 0.008109303191304207, 0.019367985427379608, -0.018493928015232086, 0.009108224883675575, 0.009316333569586277, 0.015400045551359653, -0.02849701978266239, 0.013062290847301483, 0.003801452461630106, -0.0004378954181447625, 0.013207966461777687, 0.012528144754469395, -0.0007808412774465978, -0.008893178775906563, -0.011321114376187325, 0.0031753922812640667, -0.013249588198959827, 0.01728689670562744, -0.006101054139435291, -0.026055211201310158, 0.000954698771238327, -0.009399577043950558, 0.007915068417787552, -0.0008896647486835718, 0.009330207481980324, 0.0008480430115014315, 0.0003258202050346881, 0.01385310385376215, -0.011494537815451622, 0.008081555366516113, 0.014186077751219273, 0.0008632176322862506, 0.010232011787593365, 0.010502553544938564, -0.01000309269875288, -0.011702646501362324, 0.038264255970716476, -0.015927253291010857, 0.012944362126290798, 0.031410541385412216, 0.01859104633331299, 0.018271945416927338, 0.015927253291010857, -0.011466789990663528, -0.01004471443593502, 0.015233558602631092, -0.012181296944618225, -0.009912911802530289, 0.008005248382687569, -0.0025736112147569656, 0.008809935301542282, 0.0009720411617308855, -0.007554346229881048, 0.006295288912951946, -0.002476493827998638, 0.006087179761379957, 0.0013388327788561583, -0.01198706217110157, 0.0293294545263052, 0.02529214695096016, 0.014900583773851395, 0.003388703567907214, 0.021990153938531876, 0.03232622146606445, -0.019798075780272484, -0.020186545327305794, -0.0016804778715595603, 0.008969485759735107, 0.02108835056424141, 0.023946376517415047, 0.012014809995889664, 0.0040581198409199715, -0.006399343255907297, 0.022850336506962776, 0.007387859281152487, 0.04975185915827751, -0.005386547185480595, 0.0012581906048581004, 0.004748347215354443, 0.02817792072892189, -0.025944219902157784, -0.12575316429138184, -0.01238246913999319, 0.002353362739086151, 0.019187623634934425, -0.003014107933267951, 0.0028025307692587376, 0.011272555217146873, 0.026429807767271996, -0.0184384323656559, 0.015927253291010857, 0.0024262007791548967, 0.0016414575511589646, -0.009441198781132698, 0.0007895124726928771, 0.00848389882594347, 0.020658258348703384, 0.006340378895401955, -0.006218982394784689, -0.014692475087940693, 0.01970095932483673, 0.0034944922663271427, 0.01718978025019169, 0.02133808098733425, 0.003586406819522381, -0.006451370194554329, 0.004581860266625881, -0.027567468583583832, 0.014206888154149055, 0.01007939875125885, -0.010273633524775505, 0.023169437423348427, -0.009829668328166008, -0.011071383953094482, -0.012306162156164646, -0.0017385749379172921, -0.0116402143612504, -0.029357202351093292, -0.005674431100487709, 0.01043318398296833, -0.013797608204185963, -0.0007097374182194471, -0.003947128541767597, 0.024806559085845947, 0.01545554120093584, 0.02124096266925335, -0.014623105525970459, -0.01588563248515129, -0.0024036557879298925, 0.007200561463832855, -0.022753220051527023, -0.023835385218262672, -0.0184384323656559, -0.023613402619957924, -0.022128893062472343, 0.021310333162546158, 0.012389405630528927, 0.009982281364500523, 0.00969786662608385, -0.018271945416927338, 0.005910287611186504, -0.0004394128918647766, -0.011931566521525383, -0.015358423814177513, 0.014172203838825226, 0.005244339816272259, 0.007256057113409042, -0.034435056149959564, -0.02833053283393383, 0.009163720533251762, -0.007242183201014996, -0.00025601708330214024, 0.037709299474954605, -0.017078788951039314, 0.01782798022031784, -0.011008950881659985, -0.0016345205949619412, -0.013124722987413406, -0.006988984532654285, -0.0024175297003239393, -0.0021886099129915237, -0.011334988288581371, -0.017023293301463127, -0.0012321770191192627, -0.010675976984202862, 0.01946510188281536, 0.021851414814591408, 0.027914315462112427, -0.006496460642665625, -0.017605997622013092, -0.015580406412482262, 0.003582938341423869, 0.003711272031068802, -0.025389263406395912, -0.013693553395569324, -0.04386931657791138, 0.010634355247020721, -0.0154139194637537, -0.01688455417752266, 0.00856020487844944, -0.00519231241196394, -0.013658869080245495, -0.01397103164345026, -0.01389472559094429, 0.02240637131035328, -0.02086636796593666, -0.00957300141453743, -0.000989383552223444, -0.018771406263113022, -0.0035326455254107714, -0.0004920904175378382, -0.037792544811964035, 0.00735317450016737, -0.0008398054051212966, 0.004193390719592571, -0.033574871718883514, -0.02437646873295307, -0.010578859597444534, 0.005199249368160963, 0.011466789990663528, -0.0038257320411503315, 0.018549423664808273, 0.01474797073751688, -0.021143846213817596, -0.006975110620260239, 0.023377545177936554, 0.01798059232532978, -0.025028541684150696, 0.00229613296687603, -0.03734857961535454, 0.026984764263033867, -0.002058542100712657, 0.0006030817166902125, 0.0068329027853906155, -0.027900442481040955, -0.005716052837669849, 0.0038361374754458666, -0.0010258025722578168, -0.00977417267858982, 0.015663649886846542, 0.0034632759634405375, 0.014525988139212132, 0.006968173664063215, -0.036294158548116684, -0.015344549901783466, -0.005549565888941288, -0.000110882923763711, -0.028857741504907608, 0.0046234820038080215, 0.0025684083811938763, 0.004106678534299135, 0.01767536625266075, -0.003967939410358667, 0.03557271510362625, 0.013277336023747921, 0.03215973451733589, -0.041843727231025696, -0.010266697034239769, 0.003808389650657773, 0.0029169905465096235, 0.0018469648202881217, 0.00309388292953372, -0.016079867258667946, 0.016246354207396507, 0.0060906484723091125, 0.029468193650245667, -0.010953455232083797, -0.019576093181967735, 0.01202868390828371, 0.016468336805701256, -0.013020669110119343, -0.004557580687105656, -0.036377403885126114, -0.006971641909331083, 0.002283993177115917, 0.012139675207436085, 0.01008633617311716, 0.01578851416707039, 0.002875368809327483, 0.0008614833932369947, 0.005199249368160963, -0.014650853350758553, 0.015441667288541794, 0.01431787945330143, 0.002244105562567711, -0.01666257157921791, -0.0016978202620521188, 0.02709575556218624, 0.010232011787593365, 0.004724068101495504, 0.004078930709511042, 0.004065056797116995, 0.014609231613576412, -0.021185467019677162, -0.00084674236131832, 0.008005248382687569, 0.005712584126740694, 0.00739479623734951, 0.028233416378498077, -0.0193957332521677, 0.013048416934907436, -0.009808857925236225, 0.01649608463048935, -0.0034407307393848896, 0.006829434540122747, -0.012222918681800365, -0.00318232923746109, -0.006659478880465031, -0.007720833644270897, -0.014692475087940693, 0.0023481601383537054, 0.007817951031029224, 0.012472649104893208, 0.003628028556704521, 0.006784344092011452, 0.01727302372455597, 0.01868816278874874, -0.038569483906030655, 0.02303069829940796, -0.0008753573056310415, -0.01207030564546585, -0.010280570946633816, 0.03659938648343086, 0.025791607797145844, 0.008698944002389908, 0.012576703913509846, 0.010884085670113564, 0.03671037778258324, 0.00636465847492218, 0.0014975155936554074, -0.0107800317928195, 0.02910747192800045, 0.008546330966055393, 0.0029100535903126, -0.016385093331336975, -0.007734707556664944, -0.01735626719892025, -0.021615559235215187, -0.027539720758795738, -0.002766111632809043, 0.050778526812791824, -0.00965624488890171, 0.05976882204413414, 0.001170611591078341, -0.021365828812122345, 0.012035620398819447, -0.008733629249036312, 0.027803324162960052, -0.005868665874004364, 0.009129035286605358, -0.004155237227678299, -0.009045791812241077, 0.011119942180812359, -0.01680131070315838, 0.004099741578102112, -0.04489598795771599, -0.013256525620818138, -0.024945298209786415, -0.0009070071391761303, 0.005077852867543697, -0.01626022718846798, -0.008629574440419674, 0.033269647508859634, -0.0096493074670434, 0.016940049827098846, 0.005986594129353762, -0.007408670149743557, -0.014088960364460945, 0.013922473415732384, -0.04309237748384476, -0.0184384323656559, -0.033963341265916824, -0.001298078102990985, -0.008470024913549423, -0.028996480628848076, -0.019742580130696297, -0.012035620398819447, 0.03052261285483837, 0.003908975515514612, -0.011952376924455166, 0.016163110733032227, 0.013561751693487167, -0.007908130995929241, 0.008657322265207767, -0.012271477840840816, -0.027498098090291023, 0.004013029858469963, -0.018937893211841583, -0.017536627128720284, 0.00024344385019503534, -0.006520739756524563], index=1, object='embedding')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector embeddings for each document generated by the model\n",
    "res.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have created two vectors (one for each sentence input)\n",
    "len(res.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536, 1536)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have created two 1536-dimensional vectors\n",
    "len(res.data[0].embedding), len(res.data[1].embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0031264047138392925,\n",
       " 0.011723595671355724,\n",
       " -0.005217977799475193,\n",
       " -0.027155056595802307,\n",
       " -0.016435954719781876,\n",
       " 0.03246741741895676,\n",
       " -0.01624719239771366,\n",
       " -0.0010095506440848112,\n",
       " -0.025928091257810593,\n",
       " -0.006556179840117693,\n",
       " 0.0201303381472826,\n",
       " 0.01667865179479122,\n",
       " -0.009155056439340115,\n",
       " 0.02344719134271145,\n",
       " -0.010247191414237022,\n",
       " 0.013449438847601414,\n",
       " 0.025213483721017838,\n",
       " -0.016853932291269302,\n",
       " 0.0121617978438735,\n",
       " -0.01624719239771366,\n",
       " -0.0043820226565003395,\n",
       " -0.006495506037026644,\n",
       " -0.004368539433926344,\n",
       " 0.020723596215248108,\n",
       " -0.01062471978366375,\n",
       " -0.0037584269884973764,\n",
       " 0.013712359592318535,\n",
       " -0.026251686736941338,\n",
       " -0.0003962781047448516,\n",
       " -0.002147190971300006,\n",
       " 0.005831460934132338,\n",
       " -0.010092135518789291,\n",
       " -0.028179775923490524,\n",
       " -0.016206741333007812,\n",
       " -0.004317977465689182,\n",
       " 0.007469663396477699,\n",
       " -0.002902247244492173,\n",
       " -0.031550563871860504,\n",
       " 0.024000000208616257,\n",
       " -0.03338427096605301,\n",
       " -0.0003642556257545948,\n",
       " 0.013051685877144337,\n",
       " 0.007186517119407654,\n",
       " -0.005642696749418974,\n",
       " 0.0031870787497609854,\n",
       " -0.02985168620944023,\n",
       " 0.02626516856253147,\n",
       " -0.004651685710996389,\n",
       " 0.006630337331444025,\n",
       " 0.017339326441287994,\n",
       " 0.02742471918463707,\n",
       " 0.01576179824769497,\n",
       " -0.022139325737953186,\n",
       " 0.0029410114511847496,\n",
       " -0.006583146285265684,\n",
       " 0.006451685447245836,\n",
       " -0.017002247273921967,\n",
       " 0.0200898889452219,\n",
       " 0.0035494384355843067,\n",
       " -0.0034752809442579746,\n",
       " -0.0011005618143826723,\n",
       " 0.0035662923473864794,\n",
       " -0.00267303385771811,\n",
       " -0.01259325910359621,\n",
       " -0.0180134829133749,\n",
       " -0.03543370962142944,\n",
       " -0.03173932805657387,\n",
       " 0.007496629375964403,\n",
       " 0.0072067417204380035,\n",
       " 0.0055348314344882965,\n",
       " 0.020804494619369507,\n",
       " 0.011029213666915894,\n",
       " -0.011521348729729652,\n",
       " -0.01744719222187996,\n",
       " 0.006626966409385204,\n",
       " 0.01013258472084999,\n",
       " -0.012175281532108784,\n",
       " -0.012465168721973896,\n",
       " 0.000285042158793658,\n",
       " -0.0011679775780066848,\n",
       " 0.004644943866878748,\n",
       " -0.026723597198724747,\n",
       " -0.002341011306270957,\n",
       " 0.032062921673059464,\n",
       " 0.009060674346983433,\n",
       " 0.014022472314536572,\n",
       " 0.018256179988384247,\n",
       " 0.02906966395676136,\n",
       " -0.021020226180553436,\n",
       " -0.017352810129523277,\n",
       " -0.006047191098332405,\n",
       " 0.015869664028286934,\n",
       " -0.00440561817958951,\n",
       " 0.01709662936627865,\n",
       " -0.013186517171561718,\n",
       " 0.02199101261794567,\n",
       " -0.00543033704161644,\n",
       " 0.024323595687747,\n",
       " 0.003819101257249713,\n",
       " -0.04085393249988556,\n",
       " 0.008467416279017925,\n",
       " 0.009964045137166977,\n",
       " -0.012121348641812801,\n",
       " -0.009600000455975533,\n",
       " -0.03942472115159035,\n",
       " 0.005807865411043167,\n",
       " 0.016260674223303795,\n",
       " -0.014844944700598717,\n",
       " 0.016125842928886414,\n",
       " 0.014507865533232689,\n",
       " -0.021519102156162262,\n",
       " 0.012707865796983242,\n",
       " -0.004702247213572264,\n",
       " -0.03322247415781021,\n",
       " 0.014400000683963299,\n",
       " 0.004614606965333223,\n",
       " -0.004439326003193855,\n",
       " -0.02203146182000637,\n",
       " 0.0011081461561843753,\n",
       " -0.0051573035307228565,\n",
       " -0.01330112386494875,\n",
       " 0.026157304644584656,\n",
       " 0.04007191210985184,\n",
       " -0.016570787876844406,\n",
       " 0.01395505666732788,\n",
       " 0.023649439215660095,\n",
       " -0.005130337085574865,\n",
       " -0.03192809224128723,\n",
       " 0.012842697091400623,\n",
       " -0.0059797754511237144,\n",
       " 0.018121348693966866,\n",
       " 0.042606744915246964,\n",
       " 0.024215731769800186,\n",
       " 0.020588764920830727,\n",
       " -0.02820674329996109,\n",
       " 0.018849438056349754,\n",
       " -0.04549213498830795,\n",
       " 0.01922696642577648,\n",
       " -0.021802248433232307,\n",
       " -0.017555056139826775,\n",
       " 0.00885842740535736,\n",
       " 0.03494831547141075,\n",
       " -0.006128089968115091,\n",
       " -0.006249438505619764,\n",
       " 0.006943820510059595,\n",
       " 0.011164044961333275,\n",
       " 0.0006421348662115633,\n",
       " -0.021155057474970818,\n",
       " 0.01077303383499384,\n",
       " -0.013833708129823208,\n",
       " 0.010874157771468163,\n",
       " 0.0023797752801328897,\n",
       " -0.007166292518377304,\n",
       " 0.01205393299460411,\n",
       " 0.003680899040773511,\n",
       " 0.02626516856253147,\n",
       " 0.012357303872704506,\n",
       " -0.003916854038834572,\n",
       " -0.011386517435312271,\n",
       " -0.020494382828474045,\n",
       " 0.00820449460297823,\n",
       " 0.01457528118044138,\n",
       " 0.019321348518133163,\n",
       " -0.010071910917758942,\n",
       " 0.010422471910715103,\n",
       " 0.04150112345814705,\n",
       " 0.002576966304332018,\n",
       " -0.01077977567911148,\n",
       " 0.00036088484921492636,\n",
       " -0.01766292192041874,\n",
       " -0.02453932724893093,\n",
       " 0.016880899667739868,\n",
       " -0.04565393552184105,\n",
       " 0.003964045085012913,\n",
       " -0.03322247415781021,\n",
       " 0.024593260139226913,\n",
       " 0.014925843104720116,\n",
       " 0.015087640844285488,\n",
       " -0.008973034098744392,\n",
       " -0.02315056324005127,\n",
       " -0.01977977529168129,\n",
       " 0.007941572926938534,\n",
       " 0.011858426965773106,\n",
       " 0.03724044933915138,\n",
       " -0.03662022575736046,\n",
       " -0.00367752811871469,\n",
       " -0.015775281935930252,\n",
       " 0.0005119382403790951,\n",
       " 0.002644382184371352,\n",
       " 0.0007259831763803959,\n",
       " 0.007968539372086525,\n",
       " 0.010496629402041435,\n",
       " 0.005069663282483816,\n",
       " -0.023555057123303413,\n",
       " -0.6899056434631348,\n",
       " -0.021182022988796234,\n",
       " -0.003812359645962715,\n",
       " -0.011669663712382317,\n",
       " 0.025752810761332512,\n",
       " 0.020629214122891426,\n",
       " 0.011737079359591007,\n",
       " 0.010334831662476063,\n",
       " -0.010442697443068027,\n",
       " 0.014346067793667316,\n",
       " -0.02311011403799057,\n",
       " 0.0053022475913167,\n",
       " -0.010995506308972836,\n",
       " -0.0028955056332051754,\n",
       " -0.01771685481071472,\n",
       " -0.0190112367272377,\n",
       " 0.00014968399773351848,\n",
       " 0.00377865182235837,\n",
       " -0.019200000911951065,\n",
       " 0.0078067416325211525,\n",
       " 0.0002972612564917654,\n",
       " 0.013503370806574821,\n",
       " -0.02906966395676136,\n",
       " 0.01384719181805849,\n",
       " 0.012620225548744202,\n",
       " -0.0010129213333129883,\n",
       " 0.005005618091672659,\n",
       " -0.016476405784487724,\n",
       " 0.00298651703633368,\n",
       " 0.024471910670399666,\n",
       " -0.037510111927986145,\n",
       " -0.0111842704936862,\n",
       " -0.005113483406603336,\n",
       " 0.022449439391493797,\n",
       " 0.05377078801393509,\n",
       " -6.44662941340357e-05,\n",
       " -1.1843838365166448e-05,\n",
       " -0.0074292137287557125,\n",
       " 0.011238202452659607,\n",
       " 0.013274157419800758,\n",
       " -0.018391011282801628,\n",
       " -0.01754157431423664,\n",
       " 0.006202247459441423,\n",
       " -0.015910113230347633,\n",
       " -0.0014039325760677457,\n",
       " 0.0015817416133359075,\n",
       " 0.03001348488032818,\n",
       " 0.011669663712382317,\n",
       " 0.01770337112247944,\n",
       " 0.02730337157845497,\n",
       " -0.0056561799719929695,\n",
       " 0.0009455056278966367,\n",
       " 0.015586517751216888,\n",
       " -0.0059157307259738445,\n",
       " 0.011858426965773106,\n",
       " 0.0019213483901694417,\n",
       " 0.03675505891442299,\n",
       " -0.02444494515657425,\n",
       " 0.016557304188609123,\n",
       " 0.026844944804906845,\n",
       " 0.005248314701020718,\n",
       " 0.022705618292093277,\n",
       " -0.014548314735293388,\n",
       " -0.0180134829133749,\n",
       " -0.005861797835677862,\n",
       " 0.006782022770494223,\n",
       " -0.010038202628493309,\n",
       " 0.004055056255310774,\n",
       " 0.02751910127699375,\n",
       " -0.014817978255450726,\n",
       " 0.011137079447507858,\n",
       " 0.018849438056349754,\n",
       " -0.021006742492318153,\n",
       " -0.024417977780103683,\n",
       " 0.00545393256470561,\n",
       " 0.012000000104308128,\n",
       " 0.013793258927762508,\n",
       " -0.00500898901373148,\n",
       " -0.01140674203634262,\n",
       " 0.01680000126361847,\n",
       " 0.018647192046046257,\n",
       " 0.007901123724877834,\n",
       " -0.03705168515443802,\n",
       " -0.01568089984357357,\n",
       " 0.018862921744585037,\n",
       " -0.003940449561923742,\n",
       " -0.04206741601228714,\n",
       " -0.006471910513937473,\n",
       " 0.002123595681041479,\n",
       " 0.009060674346983433,\n",
       " 0.009957303293049335,\n",
       " 0.021492134779691696,\n",
       " -0.006643820554018021,\n",
       " 0.0069303372874855995,\n",
       " 0.00503258453682065,\n",
       " 0.011474157683551311,\n",
       " -0.0029426966793835163,\n",
       " 0.006519101560115814,\n",
       " 0.009283146820962429,\n",
       " -0.005568539723753929,\n",
       " 0.0023578652180731297,\n",
       " 0.02444494515657425,\n",
       " -0.014224719256162643,\n",
       " 0.006991011556237936,\n",
       " 0.030687641352415085,\n",
       " 0.0017966292798519135,\n",
       " -0.0019365169573575258,\n",
       " 0.011217977851629257,\n",
       " 0.01697528176009655,\n",
       " -0.014116854406893253,\n",
       " 0.002674719085916877,\n",
       " -0.0002783005766104907,\n",
       " -0.008676405064761639,\n",
       " -0.024134831503033638,\n",
       " -0.017137078568339348,\n",
       " -0.03144269809126854,\n",
       " 0.01187865249812603,\n",
       " 0.00035014047170989215,\n",
       " 0.015276405028998852,\n",
       " 0.009795505553483963,\n",
       " 0.01973932608962059,\n",
       " 0.010287640616297722,\n",
       " -0.0026292135007679462,\n",
       " 0.0007061798241920769,\n",
       " 0.015573034062981606,\n",
       " 0.006525842938572168,\n",
       " -0.010638202540576458,\n",
       " -0.03238651901483536,\n",
       " -0.0029477528296411037,\n",
       " -0.011993259191513062,\n",
       " -0.012020224705338478,\n",
       " 0.002821348374709487,\n",
       " 0.04535730555653572,\n",
       " -0.01624719239771366,\n",
       " 0.013570787385106087,\n",
       " 0.004226966295391321,\n",
       " 0.019038202241063118,\n",
       " -0.00630674185231328,\n",
       " -0.005457303486764431,\n",
       " -0.014035956002771854,\n",
       " -0.023474158719182014,\n",
       " 0.015033707953989506,\n",
       " -0.006970786955207586,\n",
       " -0.011157304048538208,\n",
       " 0.009869663044810295,\n",
       " -0.020197752863168716,\n",
       " -0.024647191166877747,\n",
       " -0.0023022473324090242,\n",
       " 0.004001123830676079,\n",
       " -0.0044831461273133755,\n",
       " -0.011265168897807598,\n",
       " -0.010543820448219776,\n",
       " -0.023608990013599396,\n",
       " 0.006458427291363478,\n",
       " 0.00411573052406311,\n",
       " -0.004884270019829273,\n",
       " 0.006091011222451925,\n",
       " -0.028125843033194542,\n",
       " -0.010348315350711346,\n",
       " -0.013044944033026695,\n",
       " 0.0041224719025194645,\n",
       " 0.018606742843985558,\n",
       " -0.022732585668563843,\n",
       " -0.000661095546092838,\n",
       " -0.009202247485518456,\n",
       " -0.020723596215248108,\n",
       " -0.026278652250766754,\n",
       " 0.020507866516709328,\n",
       " -0.011602247133851051,\n",
       " -0.030525844544172287,\n",
       " -0.005164044909179211,\n",
       " -0.01250561885535717,\n",
       " -0.0010837079025804996,\n",
       " -0.0011882022954523563,\n",
       " 0.014804494567215443,\n",
       " -0.01524943858385086,\n",
       " -0.020413484424352646,\n",
       " 0.0010264045558869839,\n",
       " 0.027492135763168335,\n",
       " -0.025820225477218628,\n",
       " 0.011494382284581661,\n",
       " 0.014669663272798061,\n",
       " 0.017029214650392532,\n",
       " 0.016058428213000298,\n",
       " 0.02146516926586628,\n",
       " 0.013159550726413727,\n",
       " 0.001547191059216857,\n",
       " 0.015991011634469032,\n",
       " -0.015519102104008198,\n",
       " -0.0023426967673003674,\n",
       " 0.020804494619369507,\n",
       " -0.006141573190689087,\n",
       " -0.010442697443068027,\n",
       " 0.013166292570531368,\n",
       " -0.00570000009611249,\n",
       " 0.004365168511867523,\n",
       " -0.02289438247680664,\n",
       " 0.017460674047470093,\n",
       " 0.018984271213412285,\n",
       " 0.00014178371930029243,\n",
       " 0.021519102156162262,\n",
       " 0.00835955049842596,\n",
       " 0.014143820852041245,\n",
       " -0.010004494339227676,\n",
       " 0.0031078653410077095,\n",
       " -0.033977530896663666,\n",
       " -0.0035089890006929636,\n",
       " -0.025982024148106575,\n",
       " 0.009316854178905487,\n",
       " 0.01207415759563446,\n",
       " 0.003291573142632842,\n",
       " -0.020413484424352646,\n",
       " -0.02704719267785549,\n",
       " 0.004078651778399944,\n",
       " 0.010253933258354664,\n",
       " 0.020076405256986618,\n",
       " -0.0038764046039432287,\n",
       " -0.0037146068643778563,\n",
       " -0.0012733147013932467,\n",
       " 0.0012480337172746658,\n",
       " 0.008635954931378365,\n",
       " -0.006401123944669962,\n",
       " 0.018000001087784767,\n",
       " -0.006879775319248438,\n",
       " -0.0078067416325211525,\n",
       " 0.01944269798696041,\n",
       " 0.015991011634469032,\n",
       " 0.03761797770857811,\n",
       " 0.0111842704936862,\n",
       " -0.014521349221467972,\n",
       " -0.0008898876840248704,\n",
       " 0.005514606833457947,\n",
       " -0.0012724719708785415,\n",
       " -0.000263132038526237,\n",
       " 0.02708764187991619,\n",
       " 0.0132808992639184,\n",
       " 0.019240450114011765,\n",
       " -0.016746068373322487,\n",
       " 0.039020225405693054,\n",
       " -0.006030337419360876,\n",
       " -0.016355056315660477,\n",
       " 0.021316854283213615,\n",
       " 0.02146516926586628,\n",
       " -0.013341573067009449,\n",
       " 0.014440449886023998,\n",
       " -0.022058427333831787,\n",
       " 0.015087640844285488,\n",
       " 0.01995505765080452,\n",
       " -0.007982023060321808,\n",
       " 0.0003383427101653069,\n",
       " 0.0013390450039878488,\n",
       " 0.013611236587166786,\n",
       " -0.008056179620325565,\n",
       " 0.013712359592318535,\n",
       " 0.026791011914610863,\n",
       " -0.006697752978652716,\n",
       " -0.0016331460792571306,\n",
       " 0.010098876431584358,\n",
       " 0.004894382320344448,\n",
       " 0.016179775819182396,\n",
       " 0.018579775467514992,\n",
       " -0.013179775327444077,\n",
       " -0.0033691013231873512,\n",
       " 0.004944943822920322,\n",
       " 0.020885394886136055,\n",
       " -0.006859550718218088,\n",
       " -0.0024016855750232935,\n",
       " -0.004931461066007614,\n",
       " -0.017905618995428085,\n",
       " 0.0007242977735586464,\n",
       " 0.0051033711060881615,\n",
       " -0.012788764201104641,\n",
       " 0.012910112738609314,\n",
       " -0.017258428037166595,\n",
       " 0.02189663052558899,\n",
       " 0.008507865481078625,\n",
       " 0.01624719239771366,\n",
       " 0.009080898948013783,\n",
       " 0.001580056268721819,\n",
       " -0.0049348315224051476,\n",
       " -0.017204495146870613,\n",
       " -0.037860676646232605,\n",
       " 0.0013811797834932804,\n",
       " 0.010982022620737553,\n",
       " 0.0059797754511237144,\n",
       " -0.0016188202425837517,\n",
       " -0.007759551052004099,\n",
       " 0.016692135483026505,\n",
       " -0.014480899088084698,\n",
       " -0.0004617977829184383,\n",
       " 0.006067416165024042,\n",
       " 0.005477528087794781,\n",
       " 0.007894381880760193,\n",
       " -0.011191011406481266,\n",
       " 0.004152809269726276,\n",
       " 0.012849438935518265,\n",
       " 0.0037516856100410223,\n",
       " 0.003674157429486513,\n",
       " -0.018647192046046257,\n",
       " 0.010489887557923794,\n",
       " 0.011346068233251572,\n",
       " -0.002158988732844591,\n",
       " -0.024040449410676956,\n",
       " -0.024283146485686302,\n",
       " 0.04365842789411545,\n",
       " -0.01373258512467146,\n",
       " -0.007139326073229313,\n",
       " 0.001948314718902111,\n",
       " -0.009276404976844788,\n",
       " -0.021316854283213615,\n",
       " 0.011993259191513062,\n",
       " 0.002519662957638502,\n",
       " -0.02199101261794567,\n",
       " -0.0008814607281237841,\n",
       " 0.019496629014611244,\n",
       " 0.000921067432500422,\n",
       " -0.011191011406481266,\n",
       " 0.015060674399137497,\n",
       " 0.025766292586922646,\n",
       " 0.008089887909591198,\n",
       " 0.0019011236727237701,\n",
       " -0.02855730429291725,\n",
       " -0.013874157331883907,\n",
       " 0.012303370982408524,\n",
       " 0.06024269759654999,\n",
       " 0.05147865414619446,\n",
       " 0.005750562064349651,\n",
       " 0.003761797910556197,\n",
       " 0.008400000631809235,\n",
       " -0.005335955414921045,\n",
       " -0.013462921604514122,\n",
       " -0.013570787385106087,\n",
       " 0.01750112511217594,\n",
       " -0.021316854283213615,\n",
       " -0.006171910557895899,\n",
       " -0.004712359514087439,\n",
       " 0.01948314718902111,\n",
       " 0.0025280900299549103,\n",
       " 0.022382022812962532,\n",
       " -0.006812359672039747,\n",
       " 0.010429213754832745,\n",
       " 0.013739326037466526,\n",
       " -0.011440449394285679,\n",
       " -0.01831011287868023,\n",
       " 0.008015730418264866,\n",
       " 0.010523595847189426,\n",
       " 0.0010028090327978134,\n",
       " 0.008582022972404957,\n",
       " 0.020750561729073524,\n",
       " -0.022705618292093277,\n",
       " 0.010004494339227676,\n",
       " 0.014386516995728016,\n",
       " -0.00666067423298955,\n",
       " -0.024512359872460365,\n",
       " -0.016570787876844406,\n",
       " 0.016422472894191742,\n",
       " 0.016867415979504585,\n",
       " 0.023595506325364113,\n",
       " -0.003670786740258336,\n",
       " 0.030984271317720413,\n",
       " -0.010961798019707203,\n",
       " -0.013901123777031898,\n",
       " 0.005271910224109888,\n",
       " 0.003761797910556197,\n",
       " 0.008420225232839584,\n",
       " 0.00597303407266736,\n",
       " 0.011056180112063885,\n",
       " 0.0035629214253276587,\n",
       " -0.002297191182151437,\n",
       " 0.0031398877035826445,\n",
       " -0.022058427333831787,\n",
       " 0.003254494396969676,\n",
       " -0.01334831491112709,\n",
       " -0.0033842697739601135,\n",
       " 0.001664325944148004,\n",
       " -0.007462921552360058,\n",
       " 0.018202247098088264,\n",
       " -0.012883146293461323,\n",
       " 0.017676405608654022,\n",
       " 0.018647192046046257,\n",
       " 0.00961348321288824,\n",
       " 0.010597753338515759,\n",
       " -0.00659662950783968,\n",
       " -0.026022473350167274,\n",
       " -0.005447191186249256,\n",
       " -0.001591011299751699,\n",
       " -0.009714607149362564,\n",
       " -0.009337078779935837,\n",
       " -0.0043280902318656445,\n",
       " -0.024849439039826393,\n",
       " -0.010658427141606808,\n",
       " -0.0012724719708785415,\n",
       " -0.025752810761332512,\n",
       " 0.010408989153802395,\n",
       " 0.007388764526695013,\n",
       " 0.002155618043616414,\n",
       " -0.01457528118044138,\n",
       " 0.003350561950355768,\n",
       " 0.011177528649568558,\n",
       " 0.0014030899619683623,\n",
       " -0.0036539328284561634,\n",
       " -0.00469887675717473,\n",
       " -0.01080000028014183,\n",
       " -0.00033686798997223377,\n",
       " -0.006822471972554922,\n",
       " -0.014265169389545918,\n",
       " 0.011507865972816944,\n",
       " -0.022732585668563843,\n",
       " -0.0009623595979064703,\n",
       " 0.015910113230347633,\n",
       " 0.0006484550540335476,\n",
       " 0.0011393259046599269,\n",
       " 0.0003971208061557263,\n",
       " 0.02720898948609829,\n",
       " -0.005025842692703009,\n",
       " 0.008534831926226616,\n",
       " -0.009970786981284618,\n",
       " -0.03184719383716583,\n",
       " -0.0021674158051609993,\n",
       " -0.018417978659272194,\n",
       " 0.006084269843995571,\n",
       " -0.012748314999043941,\n",
       " -0.004516853950917721,\n",
       " -0.020804494619369507,\n",
       " -0.010982022620737553,\n",
       " -0.00023911517928354442,\n",
       " -0.0003802668652497232,\n",
       " -0.006067416165024042,\n",
       " 0.003455056343227625,\n",
       " 0.0009109550737775862,\n",
       " -0.0014207866042852402,\n",
       " 0.01280898880213499,\n",
       " -0.007928090170025826,\n",
       " -0.0019786518532782793,\n",
       " 0.004564044997096062,\n",
       " -0.011170786805450916,\n",
       " -0.0012615169398486614,\n",
       " -0.01326067466288805,\n",
       " 0.011413483880460262,\n",
       " 0.013004494830965996,\n",
       " -0.006111236289143562,\n",
       " 0.025119101628661156,\n",
       " 0.002315730322152376,\n",
       " -0.015397753566503525,\n",
       " 0.012977528385818005,\n",
       " -0.019766293466091156,\n",
       " 0.013408989645540714,\n",
       " 0.024984270334243774,\n",
       " 0.00939101167023182,\n",
       " 0.02324494533240795,\n",
       " -0.02263820357620716,\n",
       " -0.004850562196224928,\n",
       " 0.00382247194647789,\n",
       " -0.012950561940670013,\n",
       " -0.008008989505469799,\n",
       " 0.008352809585630894,\n",
       " -0.0020848314743489027,\n",
       " -0.018674157559871674,\n",
       " -0.0264809001237154,\n",
       " -0.0018539326265454292,\n",
       " 0.0013441011542454362,\n",
       " 0.009323596023023129,\n",
       " -0.023271910846233368,\n",
       " -0.011925843544304371,\n",
       " -0.01887640543282032,\n",
       " 0.004948314744979143,\n",
       " 0.0095662921667099,\n",
       " -0.0037584269884973764,\n",
       " -0.011453933082520962,\n",
       " -0.02579325996339321,\n",
       " -0.0031146069522947073,\n",
       " -0.0025331461802124977,\n",
       " -0.012303370982408524,\n",
       " 0.016638202592730522,\n",
       " 0.005194382276386023,\n",
       " -0.004688763990998268,\n",
       " -0.008265168406069279,\n",
       " -0.002996629336848855,\n",
       " 0.004682022612541914,\n",
       " -0.025685394182801247,\n",
       " 0.009667416103184223,\n",
       " 0.010725842788815498,\n",
       " 0.018566293641924858,\n",
       " 0.017919102683663368,\n",
       " 0.02600898966193199,\n",
       " -0.00043567418470047414,\n",
       " 0.015667416155338287,\n",
       " 0.01194606814533472,\n",
       " -0.008973034098744392,\n",
       " -0.002752247266471386,\n",
       " 0.004975281190127134,\n",
       " -0.010813483968377113,\n",
       " -0.01662471890449524,\n",
       " -0.0027033709920942783,\n",
       " 0.010483146645128727,\n",
       " 0.011575281620025635,\n",
       " 0.010806742124259472,\n",
       " -0.01899775303900242,\n",
       " 0.013186517171561718,\n",
       " 0.004995505791157484,\n",
       " -0.004513483494520187,\n",
       " 0.003269663080573082,\n",
       " 0.004867415875196457,\n",
       " -0.02311011403799057,\n",
       " -0.008258427493274212,\n",
       " 0.011474157683551311,\n",
       " -0.013247191905975342,\n",
       " 0.014683146961033344,\n",
       " -0.02906966395676136,\n",
       " 0.0028247192967683077,\n",
       " 0.05201797932386398,\n",
       " -0.005797753110527992,\n",
       " 0.006566292140632868,\n",
       " 0.004550561774522066,\n",
       " 0.008669663220643997,\n",
       " -0.01572134904563427,\n",
       " -0.0018623595824465156,\n",
       " -0.0200898889452219,\n",
       " -0.00048412923933938146,\n",
       " -0.013125843368470669,\n",
       " 0.01689438335597515,\n",
       " -0.021195506677031517,\n",
       " 0.003455056343227625,\n",
       " 0.04616629332304001,\n",
       " 0.016489887610077858,\n",
       " 0.0033219102770090103,\n",
       " 0.003399438224732876,\n",
       " 0.019901124760508537,\n",
       " 0.0073280902579426765,\n",
       " -0.019186517223715782,\n",
       " 0.01021348312497139,\n",
       " 0.0024151685647666454,\n",
       " -0.0034028091467916965,\n",
       " 0.0006219101487658918,\n",
       " -0.032197754830121994,\n",
       " 0.0028449438977986574,\n",
       " -0.003109550569206476,\n",
       " -0.011103371158242226,\n",
       " -0.0023713484406471252,\n",
       " 0.0191325843334198,\n",
       " 0.006391011644154787,\n",
       " 0.006010112352669239,\n",
       " -0.036566294729709625,\n",
       " -0.014035956002771854,\n",
       " -0.0027589888777583838,\n",
       " -0.013712359592318535,\n",
       " 0.05199101194739342,\n",
       " 0.017555056139826775,\n",
       " -0.002162359654903412,\n",
       " 0.01388764102011919,\n",
       " -0.008346067741513252,\n",
       " -0.015465169213712215,\n",
       " 0.016692135483026505,\n",
       " -0.007955056615173817,\n",
       " -0.011191011406481266,\n",
       " 0.043307866901159286,\n",
       " 0.03182022646069527,\n",
       " -0.007125842850655317,\n",
       " 0.0028955056332051754,\n",
       " 0.010382022708654404,\n",
       " 0.02453932724893093,\n",
       " 0.012262921780347824,\n",
       " -0.01319325901567936,\n",
       " 0.010011236183345318,\n",
       " 0.01771685481071472,\n",
       " -0.0013044944498687983,\n",
       " -0.02177528105676174,\n",
       " -0.009067416191101074,\n",
       " -0.0529618002474308,\n",
       " 0.027006741613149643,\n",
       " 0.005935955327004194,\n",
       " 0.0018404495203867555,\n",
       " -0.011817977763712406,\n",
       " -0.009229213930666447,\n",
       " -0.0200898889452219,\n",
       " 0.005851685535162687,\n",
       " -0.017217978835105896,\n",
       " 0.019577529281377792,\n",
       " 0.008635954931378365,\n",
       " -0.01207415759563446,\n",
       " -0.011608988977968693,\n",
       " 0.01396853942424059,\n",
       " -0.02449887804687023,\n",
       " -0.004368539433926344,\n",
       " -0.005110112484544516,\n",
       " 0.018121348693966866,\n",
       " -0.024175282567739487,\n",
       " 0.004634831566363573,\n",
       " 0.008622472174465656,\n",
       " 0.019550561904907227,\n",
       " -0.012586517259478569,\n",
       " 0.0004609550815075636,\n",
       " 0.0004942415980622172,\n",
       " 0.028880899772047997,\n",
       " -0.016341574490070343,\n",
       " -0.007058427203446627,\n",
       " -0.002661236096173525,\n",
       " -0.0008831460727378726,\n",
       " 0.009856180287897587,\n",
       " -0.00469550583511591,\n",
       " -0.004129213746637106,\n",
       " -0.005558426957577467,\n",
       " -0.011494382284581661,\n",
       " -0.01442696712911129,\n",
       " 0.0055921352468431,\n",
       " 0.008420225232839584,\n",
       " -0.01276179775595665,\n",
       " -0.018080899491906166,\n",
       " -0.0054640453308820724,\n",
       " -0.021128090098500252,\n",
       " -0.01207415759563446,\n",
       " -0.013146067969501019,\n",
       " 0.00014420646766666323,\n",
       " -0.030310112982988358,\n",
       " -0.03659325838088989,\n",
       " 0.016341574490070343,\n",
       " 0.010557304136455059,\n",
       " 0.013294382952153683,\n",
       " 0.005966292228549719,\n",
       " -0.01991460658609867,\n",
       " 0.020507866516709328,\n",
       " 0.040017977356910706,\n",
       " -0.004820224829018116,\n",
       " 0.005022472236305475,\n",
       " 0.0034752809442579746,\n",
       " 0.004408989101648331,\n",
       " -0.022624719887971878,\n",
       " -0.0015117977745831013,\n",
       " -0.00822471920400858,\n",
       " 0.0016592696774750948,\n",
       " 0.021370787173509598,\n",
       " -0.018067415803670883,\n",
       " -0.027573034167289734,\n",
       " -0.011703371070325375,\n",
       " -0.00037373596569523215,\n",
       " 0.013665169477462769,\n",
       " 0.003866292303428054,\n",
       " -0.015478651970624924,\n",
       " 0.00469550583511591,\n",
       " 0.005467415787279606,\n",
       " 0.003731460776180029,\n",
       " 0.018498877063393593,\n",
       " -0.025644944980740547,\n",
       " 0.022665169090032578,\n",
       " -0.0009514045086689293,\n",
       " -0.0064314608462154865,\n",
       " -0.0012042134767398238,\n",
       " -0.02379775419831276,\n",
       " -0.00042450844193808734,\n",
       " 0.004867415875196457,\n",
       " 0.007456180173903704,\n",
       " 0.011420224793255329,\n",
       " -0.040368542075157166,\n",
       " -0.018080899491906166,\n",
       " -0.0022702247370034456,\n",
       " 0.015411236323416233,\n",
       " -0.0032747192308306694,\n",
       " -0.010274157859385014,\n",
       " -0.021707866340875626,\n",
       " -0.0010828651720657945,\n",
       " -0.00939101167023182,\n",
       " -0.0033691013231873512,\n",
       " 0.018283147364854813,\n",
       " -0.014656180515885353,\n",
       " -0.008035955019295216,\n",
       " 0.009808989241719246,\n",
       " -0.0044662924483418465,\n",
       " 0.008582022972404957,\n",
       " -0.007591011468321085,\n",
       " 0.011029213666915894,\n",
       " -0.03524494543671608,\n",
       " -0.016746068373322487,\n",
       " -0.01650337129831314,\n",
       " -0.018579775467514992,\n",
       " -0.006340449675917625,\n",
       " 0.025644944980740547,\n",
       " 0.008710112422704697,\n",
       " -0.007307865656912327,\n",
       " -0.01607191003859043,\n",
       " -0.0127011239528656,\n",
       " -0.039155058562755585,\n",
       " -0.023029213771224022,\n",
       " -0.006161797791719437,\n",
       " -0.002435393398627639,\n",
       " 0.021316854283213615,\n",
       " 0.030687641352415085,\n",
       " -0.00164915737695992,\n",
       " 0.030471911653876305,\n",
       " -0.0010154495248571038,\n",
       " 0.03330337256193161,\n",
       " -0.03546067699790001,\n",
       " -0.011130337603390217,\n",
       " 0.01715056225657463,\n",
       " -0.01930786669254303,\n",
       " -0.00753707904368639,\n",
       " 0.006744944024831057,\n",
       " -0.019469663500785828,\n",
       " -0.0068292138166725636,\n",
       " 0.03896629437804222,\n",
       " 0.004550561774522066,\n",
       " -0.003542696824297309,\n",
       " 0.033276405185461044,\n",
       " -0.0018337079090997577,\n",
       " -0.027667416259646416,\n",
       " -0.008022472262382507,\n",
       " 0.007017978001385927,\n",
       " 0.0011098315007984638,\n",
       " -0.007671910338103771,\n",
       " 0.0011772472644224763,\n",
       " -0.007038202602416277,\n",
       " -0.01086067408323288,\n",
       " -0.002344381995499134,\n",
       " -0.01326067466288805,\n",
       " -0.007193258497864008,\n",
       " 0.004065168555825949,\n",
       " 0.010530337691307068,\n",
       " 0.0018994382116943598,\n",
       " 0.005801123566925526,\n",
       " -0.027222473174333572,\n",
       " -0.012970786541700363,\n",
       " -0.01870112493634224,\n",
       " -0.014858427457511425,\n",
       " 0.027438202872872353,\n",
       " 0.004661798011511564,\n",
       " -0.015047191642224789,\n",
       " 0.03683595731854439,\n",
       " -0.009222472086548805,\n",
       " -0.003043820383027196,\n",
       " -0.016220225021243095,\n",
       " 0.023352809250354767,\n",
       " -0.016611237078905106,\n",
       " -0.012519101612269878,\n",
       " 0.002617415739223361,\n",
       " -0.023352809250354767,\n",
       " -0.023514607921242714,\n",
       " -0.003124719252809882,\n",
       " -0.005197753198444843,\n",
       " -0.02177528105676174,\n",
       " 0.007314607035368681,\n",
       " -0.005015730392187834,\n",
       " -0.010092135518789291,\n",
       " -0.015707865357398987,\n",
       " -0.008871910162270069,\n",
       " 0.006633708253502846,\n",
       " -0.024714607745409012,\n",
       " -0.04578876495361328,\n",
       " -0.02319101244211197,\n",
       " 0.018431460484862328,\n",
       " -0.0006547753000631928,\n",
       " -0.009316854178905487,\n",
       " -0.011750562116503716,\n",
       " -0.014804494567215443,\n",
       " 0.02146516926586628,\n",
       " 0.01084044948220253,\n",
       " -0.011892135255038738,\n",
       " -0.007570786867290735,\n",
       " 0.019968539476394653,\n",
       " 0.011892135255038738,\n",
       " -0.019146068021655083,\n",
       " 0.02107415720820427,\n",
       " 0.22996854782104492,\n",
       " -0.0002972612564917654,\n",
       " 0.012950561940670013,\n",
       " 0.04082696884870529,\n",
       " 0.013382023200392723,\n",
       " 0.01245842780917883,\n",
       " 0.014817978255450726,\n",
       " 0.001580056268721819,\n",
       " -0.01071236003190279,\n",
       " 0.0076516857370734215,\n",
       " 0.00699775293469429,\n",
       " 0.003923595417290926,\n",
       " -0.001387078664265573,\n",
       " -0.0009379214025102556,\n",
       " 0.027397753670811653,\n",
       " 0.012977528385818005,\n",
       " -0.02077752910554409,\n",
       " -0.04028764367103577,\n",
       " -0.011575281620025635,\n",
       " -0.029770787805318832,\n",
       " -0.0008165730396285653,\n",
       " -0.004530337173491716,\n",
       " -0.00020172051154077053,\n",
       " -0.010631460696458817,\n",
       " 0.005838202312588692,\n",
       " -0.009080898948013783,\n",
       " -0.011022472754120827,\n",
       " -0.0038932585157454014,\n",
       " 0.01899775303900242,\n",
       " 0.015262922272086143,\n",
       " -0.010314607061445713,\n",
       " -0.013422472402453423,\n",
       " 0.010442697443068027,\n",
       " 0.007685393560677767,\n",
       " -0.04228314757347107,\n",
       " 0.02099325880408287,\n",
       " 0.014952809549868107,\n",
       " 0.011501124128699303,\n",
       " 0.022449439391493797,\n",
       " 0.014386516995728016,\n",
       " 0.0015573034761473536,\n",
       " -0.017393259331583977,\n",
       " -0.023164045065641403,\n",
       " -0.018849438056349754,\n",
       " -0.0015733146574348211,\n",
       " 0.014103371649980545,\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also get the vector for a single sentence\n",
    "res.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\datasets--jamescalam--youtube-transcriptions. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208619/208619 [00:00<00:00, 1711554.12 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'published', 'url', 'video_id', 'channel_id', 'id', 'text', 'start', 'end'],\n",
       "    num_rows: 208619\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Downloading data from a youtubbe transcription dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset('jamescalam/youtube-transcriptions', split='train')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Training and Testing an Italian BERT - Transformers From Scratch #4',\n",
       " 'published': '2021-07-06 13:00:03 UTC',\n",
       " 'url': 'https://youtu.be/35Pdoyi6ZoQ',\n",
       " 'video_id': '35Pdoyi6ZoQ',\n",
       " 'channel_id': 'UCv83tO5cePwHMt1952IVVHw',\n",
       " 'id': '35Pdoyi6ZoQ-t0.0',\n",
       " 'text': 'Hi, welcome to the video.',\n",
       " 'start': 0.0,\n",
       " 'end': 9.36}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52155/52155 [00:24<00:00, 2110.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# tqdm.auto automatically selects the best progress bar visualization\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "new_data = []\n",
    "\n",
    "window = 20  # number of sentences to combine\n",
    "stride = 4  # number of sentences to 'stride' over, used to create overlap\n",
    "\n",
    "for i in tqdm(range(0, len(data), stride)):\n",
    "    i_end = min(len(data)-1, i+window)\n",
    "    if data[i]['title'] != data[i_end]['title']:\n",
    "        # in this case we skip this entry as we have start/end of two videos\n",
    "        continue\n",
    "    text = ' '.join(data[i:i_end]['text'])\n",
    "    # create the new merged dataset\n",
    "    new_data.append({\n",
    "        'start': data[i]['start'],\n",
    "        'end': data[i_end]['end'],\n",
    "        'title': data[i]['title'],\n",
    "        'text': text,\n",
    "        'id': data[i]['id'],\n",
    "        'url': data[i]['url'],\n",
    "        'published': data[i]['published'],\n",
    "        'channel_id': data[i]['channel_id']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': 0.0,\n",
       " 'end': 74.12,\n",
       " 'title': 'Training and Testing an Italian BERT - Transformers From Scratch #4',\n",
       " 'text': \"Hi, welcome to the video. So this is the fourth video in a Transformers from Scratch mini series. So if you haven't been following along, we've essentially covered what you can see on the screen. So we got some data. We built a tokenizer with it. And then we've set up our input pipeline ready to begin actually training our model, which is what we're going to cover in this video. So let's move over to the code. And we see here that we have essentially everything we've done so far. So we've built our input data, our input pipeline. And we're now at a point where we have a data loader, PyTorch data loader, ready. And we can begin training a model with it. So there are a few things to be aware of. So I mean, first, let's just have a quick look at the structure of our data.\",\n",
       " 'id': '35Pdoyi6ZoQ-t0.0',\n",
       " 'url': 'https://youtu.be/35Pdoyi6ZoQ',\n",
       " 'published': '2021-07-06 13:00:03 UTC',\n",
       " 'channel_id': 'UCv83tO5cePwHMt1952IVVHw'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Previously I created this index on the pinecone dashboard\n",
    "index_name = \"firstdatabase\"\n",
    "environment = \"us-east-1\"\n",
    "pc = Pinecone()  # This reads the PINECONE_API_KEY env var\n",
    "\n",
    "# Create the index if it doesn't exist\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,  # Using the same vector dimensions as text-embedding-ada-002\n",
    "        metric=\"cosine\",\n",
    "        spec=PodSpec(\n",
    "            environment=environment,\n",
    "            pod_type=\"p1.x1\",\n",
    "            pods=1,\n",
    "            metadata_config={\"indexed\": [\"batch\"]},\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Index:\n",
    "index = pc.Index(name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'deletion_protection': 'disabled',\n",
      " 'dimension': 1536,\n",
      " 'host': 'firstdatabase-tri9qtn.svc.aped-4627-b74a.pinecone.io',\n",
      " 'metric': 'cosine',\n",
      " 'name': 'firstdatabase',\n",
      " 'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      " 'status': {'ready': True, 'state': 'Ready'},\n",
      " 'tags': {'embedding_model': 'text-embedding-3-small'},\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "# Describe the Index:\n",
    "description = pc.describe_index(name=index_name)\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 487/487 [22:34<00:00,  2.78s/it]\n"
     ]
    }
   ],
   "source": [
    "# Insert the data into the Pinecone index\n",
    "# We will insert the embeddings in batches to avoid rate limiting\n",
    "# We will also insert the metadata along with the embeddings\n",
    "from tqdm.auto import tqdm\n",
    "import datetime\n",
    "from time import sleep\n",
    "\n",
    "batch_size = 100  # how many embeddings we create and insert at once\n",
    "\n",
    "for i in tqdm(range(0, len(new_data), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(len(new_data), i+batch_size)\n",
    "    meta_batch = new_data[i:i_end]\n",
    "    # get ids\n",
    "    ids_batch = [x['id'] for x in meta_batch]\n",
    "    # get texts to encode\n",
    "    texts = [x['text'] for x in meta_batch]\n",
    "    # create embeddings (try-except added to avoid RateLimitError)\n",
    "    try:\n",
    "        res = client.embeddings.create(input=texts, model=embed_model)\n",
    "    except:\n",
    "        done = False\n",
    "        while not done:\n",
    "            sleep(5)\n",
    "            try:\n",
    "                res = client.embeddings.create(input=texts, model=embed_model)\n",
    "                done = True\n",
    "            except:\n",
    "                pass\n",
    "    embeds = [record.embedding for record in res.data]\n",
    "    # cleanup metadata\n",
    "    # we only need a few fields from the metadata\n",
    "    meta_batch = [{\n",
    "        'start': x['start'],\n",
    "        'end': x['end'],\n",
    "        'title': x['title'],\n",
    "        'text': x['text'],\n",
    "        'url': x['url'],\n",
    "        'published': x['published'],\n",
    "        'channel_id': x['channel_id']\n",
    "    } for x in meta_batch]\n",
    "    to_upsert = list(zip(ids_batch, embeds, meta_batch))\n",
    "    \n",
    "    # Upsert to Pinecone\n",
    "    index.upsert(vectors=to_upsert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.embeddings.create(\n",
    "    input=[query],\n",
    "    model=embed_model\n",
    ")\n",
    "\n",
    "# retrieve from Pinecone\n",
    "text_vector = res.data[0].embedding\n",
    "\n",
    "# get relevant contexts (including the questions)\n",
    "res = index.query(vector=text_vector, top_k=2, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': 'NNS5pOpjvAQ-t503.36',\n",
       "              'metadata': {'channel_id': 'UCv83tO5cePwHMt1952IVVHw',\n",
       "                           'end': 673.76,\n",
       "                           'published': '2021-11-04 13:00:10 UTC',\n",
       "                           'start': 503.36,\n",
       "                           'text': 'And another thing is that we also need '\n",
       "                                   'something called hard negatives in the '\n",
       "                                   'training data in order for this model to '\n",
       "                                   'perform well. So what I mean by hard '\n",
       "                                   'negative is, say we have our, you know, we '\n",
       "                                   'have our source sentence A here and we '\n",
       "                                   'have this source B, which is like a '\n",
       "                                   'similar sentence, a high similarity '\n",
       "                                   'sentence. They mean basically the same '\n",
       "                                   \"thing. We'd also have to add a source C \"\n",
       "                                   'and this source C will have to be similar '\n",
       "                                   'in the words that uses to source A, but '\n",
       "                                   'actually means something different. So '\n",
       "                                   \"it's harder for the model to differentiate \"\n",
       "                                   'between them. Again, the model would have '\n",
       "                                   'to figure out, you know, these two '\n",
       "                                   'sentences are not similar, even though '\n",
       "                                   \"they seem similar at first, but they're \"\n",
       "                                   'not. So it makes the task, the training '\n",
       "                                   'task harder for the model, which of course '\n",
       "                                   'makes the model better. So that is '\n",
       "                                   \"training approach number one. And we've \"\n",
       "                                   \"mentioned the parallel data there. That's \"\n",
       "                                   \"the data set we're going to be using for \"\n",
       "                                   'the second training approach. And that '\n",
       "                                   'second training approach is called '\n",
       "                                   'multi-lingual knowledge distillation. So '\n",
       "                                   'that is a mouthful and takes me a while to '\n",
       "                                   'write down, sorry. So multi-lingual '\n",
       "                                   'knowledge distillation. So this was '\n",
       "                                   'introduced in 2020 by, you know, who we '\n",
       "                                   'mentioned before, the sentence '\n",
       "                                   'transformers people, Nils Reimers and '\n",
       "                                   'Irenia Gurevich. And the sort of advantage '\n",
       "                                   'of using this approach is that we only '\n",
       "                                   'need the parallel data set. So we only '\n",
       "                                   'need those translation pairs and the '\n",
       "                                   'amount of training data you need is a lot '\n",
       "                                   'smaller. And using this approach, the '\n",
       "                                   'sentence transformers people have actually '\n",
       "                                   'trained sentence transformers that can use '\n",
       "                                   'all more than 50 languages at once. And '\n",
       "                                   \"the performance is good. It's not just \"\n",
       "                                   'that they, you know, managed to get a few '\n",
       "                                   'phrases correct. The performance is '\n",
       "                                   'actually quite good. So I think, you know, '\n",
       "                                   \"it's pretty impressive. And, you know, the \"\n",
       "                                   'training time for these is super quick,',\n",
       "                           'title': 'All You Need to Know on Multilingual '\n",
       "                                    'Sentence Vectors (1 Model, 50+ Languages)',\n",
       "                           'url': 'https://youtu.be/NNS5pOpjvAQ'},\n",
       "              'score': 0.862277746,\n",
       "              'values': []},\n",
       "             {'id': 'pNvujJ1XyeQ-t295.64',\n",
       "              'metadata': {'channel_id': 'UCv83tO5cePwHMt1952IVVHw',\n",
       "                           'end': 461.76,\n",
       "                           'published': '2021-11-24 16:24:24 UTC',\n",
       "                           'start': 295.64,\n",
       "                           'text': 'Transformer-based Sequential Denoising '\n",
       "                                   \"Autoencoder. So what we'll do is jump \"\n",
       "                                   'straight into it and take a look at where '\n",
       "                                   'we might want to use this training '\n",
       "                                   'approach and and how we can actually '\n",
       "                                   'implement it. So the first question we '\n",
       "                                   'need to ask is do we really need to resort '\n",
       "                                   \"to unsupervised training? Now what we're \"\n",
       "                                   'going to do here is just have a look at a '\n",
       "                                   'few of the most popular training '\n",
       "                                   'approaches and what sort of data we need '\n",
       "                                   \"for that. So the first one we're looking \"\n",
       "                                   'at here is Natural Language Inference or '\n",
       "                                   'NLI and NLI requires that we have pairs of '\n",
       "                                   'sentences that are labeled as either '\n",
       "                                   \"contradictory, neutral which means they're \"\n",
       "                                   'not necessarily related or as entailing or '\n",
       "                                   'as inferring each other. So you have pairs '\n",
       "                                   'that entail each other so they are both '\n",
       "                                   'very similar pairs that are neutral and '\n",
       "                                   'also pairs that are contradictory. And '\n",
       "                                   'this is the traditional NLI data. Now '\n",
       "                                   'using another version of fine-tuning with '\n",
       "                                   'NLI called a multiple negatives ranking '\n",
       "                                   'loss you can get by with only entailment '\n",
       "                                   'pairs so pairs that are related to each '\n",
       "                                   'other or positive pairs and it can also '\n",
       "                                   'use contradictory pairs to improve the '\n",
       "                                   'performance of training as well but you '\n",
       "                                   \"don't need it. So if you have positive \"\n",
       "                                   'pairs of related sentences you can go '\n",
       "                                   'ahead and actually try training or '\n",
       "                                   'fine-tuning using NLI with multiple '\n",
       "                                   \"negative ranking loss. If you don't have \"\n",
       "                                   'that fine. Another option is that you have '\n",
       "                                   'a semantic textual similarity data set or '\n",
       "                                   'STS and what this is is you have so you '\n",
       "                                   'have sentence A here, sentence B',\n",
       "                           'title': 'Today Unsupervised Sentence Transformers, '\n",
       "                                    'Tomorrow Skynet (how TSDAE works)',\n",
       "                           'url': 'https://youtu.be/pNvujJ1XyeQ'},\n",
       "              'score': 0.856238186,\n",
       "              'values': []}],\n",
       " 'namespace': '',\n",
       " 'usage': {'read_units': 7}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 3750\n",
    "query = (\n",
    "    \"Which training approach is best for sentence transformers when I only have related sentence pairs?\"\n",
    ")\n",
    "\n",
    "def retrieve(query):\n",
    "    res = client.embeddings.create(\n",
    "        input=[query],\n",
    "        model=embed_model\n",
    "    )\n",
    "\n",
    "    # retrieve from Pinecone\n",
    "    text_vector = res.data[0].embedding\n",
    "\n",
    "    # get relevant contexts\n",
    "    res = index.query(vector=text_vector, top_k=3, include_metadata=True)\n",
    "    contexts = [\n",
    "        x['metadata']['text'] for x in res['matches']\n",
    "    ]\n",
    "\n",
    "    # build our prompt with the retrieved contexts included\n",
    "    prompt_start = (\n",
    "        \"Answer the question based on the context below.\\n\\n\"+\n",
    "        \"Context:\\n\"\n",
    "    )\n",
    "    prompt_end = (\n",
    "        f\"\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    )\n",
    "    # append contexts until hitting limit\n",
    "    # if we hit the limit, we stop and use the contexts up to that point\n",
    "    for i in range(1, len(contexts)):\n",
    "        if len(\"\\n\\n---\\n\\n\".join(contexts[:i])) >= limit:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(contexts[:i-1]) +\n",
    "                prompt_end\n",
    "            )\n",
    "            break\n",
    "        elif i == len(contexts)-1:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(contexts) +\n",
    "                prompt_end\n",
    "            )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Answer the question based on the context below.\\n\\nContext:\\nAnd another thing is that we also need something called hard negatives in the training data in order for this model to perform well. So what I mean by hard negative is, say we have our, you know, we have our source sentence A here and we have this source B, which is like a similar sentence, a high similarity sentence. They mean basically the same thing. We'd also have to add a source C and this source C will have to be similar in the words that uses to source A, but actually means something different. So it's harder for the model to differentiate between them. Again, the model would have to figure out, you know, these two sentences are not similar, even though they seem similar at first, but they're not. So it makes the task, the training task harder for the model, which of course makes the model better. So that is training approach number one. And we've mentioned the parallel data there. That's the data set we're going to be using for the second training approach. And that second training approach is called multi-lingual knowledge distillation. So that is a mouthful and takes me a while to write down, sorry. So multi-lingual knowledge distillation. So this was introduced in 2020 by, you know, who we mentioned before, the sentence transformers people, Nils Reimers and Irenia Gurevich. And the sort of advantage of using this approach is that we only need the parallel data set. So we only need those translation pairs and the amount of training data you need is a lot smaller. And using this approach, the sentence transformers people have actually trained sentence transformers that can use all more than 50 languages at once. And the performance is good. It's not just that they, you know, managed to get a few phrases correct. The performance is actually quite good. So I think, you know, it's pretty impressive. And, you know, the training time for these is super quick,\\n\\n---\\n\\nTransformer-based Sequential Denoising Autoencoder. So what we'll do is jump straight into it and take a look at where we might want to use this training approach and and how we can actually implement it. So the first question we need to ask is do we really need to resort to unsupervised training? Now what we're going to do here is just have a look at a few of the most popular training approaches and what sort of data we need for that. So the first one we're looking at here is Natural Language Inference or NLI and NLI requires that we have pairs of sentences that are labeled as either contradictory, neutral which means they're not necessarily related or as entailing or as inferring each other. So you have pairs that entail each other so they are both very similar pairs that are neutral and also pairs that are contradictory. And this is the traditional NLI data. Now using another version of fine-tuning with NLI called a multiple negatives ranking loss you can get by with only entailment pairs so pairs that are related to each other or positive pairs and it can also use contradictory pairs to improve the performance of training as well but you don't need it. So if you have positive pairs of related sentences you can go ahead and actually try training or fine-tuning using NLI with multiple negative ranking loss. If you don't have that fine. Another option is that you have a semantic textual similarity data set or STS and what this is is you have so you have sentence A here, sentence B\\n\\n---\\n\\nwere actually more accurate. So we can't really do that. We can't use this what is called a mean pooling approach. Or we can't use it in its current form. Now the solution to this problem was introduced by two people in 2019 Nils Reimers and Irenia Gurevich. They introduced what is the first sentence transformer or sentence BERT. And it was found that sentence BERT or S BERT outformed all of the previous Save the Art models on pretty much all benchmarks. Not all of them but most of them. And it did it in a very quick time. So if we compare it to BERT, if we wanted to find the most similar sentence pair from 10,000 sentences in that 2019 paper they found that with BERT that took 65 hours. With S BERT embeddings they could create all the embeddings in just around five seconds. And then they could compare all those with cosine similarity in 0.01 seconds. So it's a lot faster. We go from 65 hours to just over five seconds which is I think pretty incredible. Now I think that's pretty much all the context we need behind sentence transformers. And what we do now is dive into a little bit of how they actually work. Now we said before we have the core transform models and what S BERT does is fine tunes on sentence pairs using what is called a Siamese architecture or Siamese network. What we mean by a Siamese network is that we have what we can see, what can view as two BERT models that are identical and the weights between those two models are tied. Now in reality when implementing this we just use a single BERT model. And what we do is we process one sentence, a sentence A through the model and then we process another sentence, sentence B through the model. And that's the sentence pair. So with our cross-linked we were processing the sentence pair together. We were putting them both together, processing them all at once. This time we process them separately. And during training what happens is the weights\\n\\nQuestion: Which training approach is best for sentence transformers when I only have related sentence pairs?\\nAnswer:\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we retrieve relevant items from Pinecone\n",
    "query_with_contexts = retrieve(query)\n",
    "query_with_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the question based on the context below.\n",
      "\n",
      "Context:\n",
      "And another thing is that we also need something called hard negatives in the training data in order for this model to perform well. So what I mean by hard negative is, say we have our, you know, we have our source sentence A here and we have this source B, which is like a similar sentence, a high similarity sentence. They mean basically the same thing. We'd also have to add a source C and this source C will have to be similar in the words that uses to source A, but actually means something different. So it's harder for the model to differentiate between them. Again, the model would have to figure out, you know, these two sentences are not similar, even though they seem similar at first, but they're not. So it makes the task, the training task harder for the model, which of course makes the model better. So that is training approach number one. And we've mentioned the parallel data there. That's the data set we're going to be using for the second training approach. And that second training approach is called multi-lingual knowledge distillation. So that is a mouthful and takes me a while to write down, sorry. So multi-lingual knowledge distillation. So this was introduced in 2020 by, you know, who we mentioned before, the sentence transformers people, Nils Reimers and Irenia Gurevich. And the sort of advantage of using this approach is that we only need the parallel data set. So we only need those translation pairs and the amount of training data you need is a lot smaller. And using this approach, the sentence transformers people have actually trained sentence transformers that can use all more than 50 languages at once. And the performance is good. It's not just that they, you know, managed to get a few phrases correct. The performance is actually quite good. So I think, you know, it's pretty impressive. And, you know, the training time for these is super quick,\n",
      "\n",
      "---\n",
      "\n",
      "Transformer-based Sequential Denoising Autoencoder. So what we'll do is jump straight into it and take a look at where we might want to use this training approach and and how we can actually implement it. So the first question we need to ask is do we really need to resort to unsupervised training? Now what we're going to do here is just have a look at a few of the most popular training approaches and what sort of data we need for that. So the first one we're looking at here is Natural Language Inference or NLI and NLI requires that we have pairs of sentences that are labeled as either contradictory, neutral which means they're not necessarily related or as entailing or as inferring each other. So you have pairs that entail each other so they are both very similar pairs that are neutral and also pairs that are contradictory. And this is the traditional NLI data. Now using another version of fine-tuning with NLI called a multiple negatives ranking loss you can get by with only entailment pairs so pairs that are related to each other or positive pairs and it can also use contradictory pairs to improve the performance of training as well but you don't need it. So if you have positive pairs of related sentences you can go ahead and actually try training or fine-tuning using NLI with multiple negative ranking loss. If you don't have that fine. Another option is that you have a semantic textual similarity data set or STS and what this is is you have so you have sentence A here, sentence B\n",
      "\n",
      "---\n",
      "\n",
      "were actually more accurate. So we can't really do that. We can't use this what is called a mean pooling approach. Or we can't use it in its current form. Now the solution to this problem was introduced by two people in 2019 Nils Reimers and Irenia Gurevich. They introduced what is the first sentence transformer or sentence BERT. And it was found that sentence BERT or S BERT outformed all of the previous Save the Art models on pretty much all benchmarks. Not all of them but most of them. And it did it in a very quick time. So if we compare it to BERT, if we wanted to find the most similar sentence pair from 10,000 sentences in that 2019 paper they found that with BERT that took 65 hours. With S BERT embeddings they could create all the embeddings in just around five seconds. And then they could compare all those with cosine similarity in 0.01 seconds. So it's a lot faster. We go from 65 hours to just over five seconds which is I think pretty incredible. Now I think that's pretty much all the context we need behind sentence transformers. And what we do now is dive into a little bit of how they actually work. Now we said before we have the core transform models and what S BERT does is fine tunes on sentence pairs using what is called a Siamese architecture or Siamese network. What we mean by a Siamese network is that we have what we can see, what can view as two BERT models that are identical and the weights between those two models are tied. Now in reality when implementing this we just use a single BERT model. And what we do is we process one sentence, a sentence A through the model and then we process another sentence, sentence B through the model. And that's the sentence pair. So with our cross-linked we were processing the sentence pair together. We were putting them both together, processing them all at once. This time we process them separately. And during training what happens is the weights\n",
      "\n",
      "Question: Which training approach is best for sentence transformers when I only have related sentence pairs?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(query_with_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The best training approach for sentence transformers when you only have related sentence pairs is to use Natural Language Inference (NLI) with multiple negatives ranking loss. This approach allows you to train or fine-tune the model using only entailment (positive) pairs while also being able to utilize contradictory pairs to further improve performance, even if you don't have a full dataset of different types of pairs.\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "askGpt(query_with_contexts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
