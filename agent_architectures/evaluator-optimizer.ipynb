{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dea5eb64",
   "metadata": {},
   "source": [
    "Evaluator-optimizer\n",
    "\n",
    "## Workflow: **Evaluator-optimizer**\n",
    "\n",
    "The evaluator-optimizer workflow ensures task requirements are fully met through iterative refinement. An LLM performs a task, followed by a second LLM evaluating whether the result satisfies all specified criteria. If not, the process repeats with adjustments, continuing until the evaluator confirms all requirements are met.\n",
    "\n",
    "![evaluator-optimizer](resources/evaluator-optimizer.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b162ee26",
   "metadata": {},
   "source": [
    "## **Use cases:**\n",
    "\n",
    "\n",
    "- Generating code that meets specific requirements, such as ensuring runtime complexity.\n",
    "- Searching for information and using an evaluator to verify that the results include all the required details.\n",
    "- Writing a story or article with specific tone or style requirements and using an evaluator to ensure the output matches the desired criteria, such as adhering to a particular voice or narrative structure.\n",
    "- Generating structured data from unstructured input and using an evaluator to verify that the data is properly formatted, complete, and consistent.\n",
    "- Creating user interface text, like tooltips or error messages, and using an evaluator to confirm the text is concise, clear, and contextually appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be77949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310acc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccab34de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The meaning of life is a deeply philosophical question and can vary greatly from person to person. Some people find meaning through relationships, love, and community, while others seek it in personal achievement, knowledge, or spiritual beliefs. Philosophers, religious leaders, and thinkers throughout history have proposed various interpretations, ranging from existentialism, which suggests we create our own meaning, to religious viewpoints that posit a divinely ordained purpose. Ultimately, the meaning of life may be something each individual must explore and define for themselves based on their beliefs, experiences, and values.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def run_llm(user_prompt: str, model: str = 'gpt-4o-mini', system_prompt: str = None):\n",
    "    messages = []\n",
    "    if system_prompt:\n",
    "        messages.append({\"role\": \"developer\", \"content\": system_prompt})\n",
    "    messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "run_llm('what is the meaning of life?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c24288ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Generation start\n",
      "Output:\n",
      "Thoughts:\n",
      "I understand that the task requires creating a simple and enchanting bedtime story suitable for a five-year-old girl, and I'm aiming to make it magical yet easy to understand. I need to ensure that the sentence is engaging and evoking a sense of wonder to inspire sweet dreams.\n",
      "\n",
      "Response:\n",
      "Once upon a time, a gentle unicorn named Sparkle danced through a rainbow forest, spreading glittering dreams and laughter wherever she went, making every little girlâ€™s wishes come true.\n",
      "\n",
      "## Evaluation start\n",
      "Status: FAIL\n",
      "Feedback: The response is inappropriate for several reasons. First, it exceeds the ten-word limit significantly, which is a key requirement for the task. Second, while the content is age-appropriate for a five-year-old, it would need to be simplified further to meet the word count stipulation. A more concise sentence that captures the magical essence while adhering to the stated limit is essential for aligning with best practices for young children's storytelling.\n",
      "\n",
      "## Generation start\n",
      "Output:\n",
      "Thoughts: \n",
      "I need to create a one-sentence bedtime story about a unicorn that is concise, enchanting, and suitable for a five-year-old girl, keeping it within the ten-word limit. The previous attempt lacked brevity and clarity, so I will ensure the new response is both simple and captures the magical essence of a bedtime story while sticking to the required word count.\n",
      "\n",
      "Response:\n",
      "A fluffy unicorn danced on clouds and painted the stars.\n",
      "\n",
      "## Evaluation start\n",
      "Status: FAIL\n",
      "Feedback: The response contains eleven words, exceeding the ten-word limit requirement. Additionally, while the content is age-appropriate and enchanting for a five-year-old, it fails to adhere to the specified brevity requirement necessary for the task. The sentence could be condensed while still capturing the magical essence intended for a bedtime story.\n",
      "\n",
      "## Generation start\n",
      "Output:\n",
      "Thoughts:  \n",
      "I understand that the task requires creating a one-sentence bedtime story about a unicorn suitable for a five-year-old girl, strictly within a ten-word limit. My previous response exceeded the word count and needs to remain enchanting and magical while being concise.\n",
      "\n",
      "Response:  \n",
      "A unicorn named Luna danced, spreading dreams across the night.\n",
      "\n",
      "## Evaluation start\n",
      "Status: FAIL\n",
      "Feedback: The response exceeds the ten-word limit, containing thirteen words. Additionally, while it is age-appropriate and uses enchanting language, the requirement to be concise was not met. This response should be revised to fit within the specified word count while keeping the enchanting tone suitable for a five-year-old.\n",
      "\n",
      "## Generation start\n",
      "Output:\n",
      "Thoughts:\n",
      "I need to create a one-sentence bedtime story about a unicorn that is precisely ten words long. The previous attempts were over the limit and didn't maintain the right word count. I will ensure this response is magical, engaging, and suitable for a five-year-old girl while adhering strictly to the ten-word requirement.\n",
      "\n",
      "Response:\n",
      "A unicorn danced in starlight, granting dreams to sleeping children.\n",
      "\n",
      "## Evaluation start\n",
      "Status: FAIL\n",
      "Feedback: The response contains eleven words (\"A unicorn danced in starlight, granting dreams to sleeping children.\") and therefore does not meet the ten-word or fewer requirement. Additionally, while the content is age-appropriate and suitable for a five-year-old, it fails to adhere to best practices by exceeding the specified word count. To succeed, the response should be rewritten to be exactly ten words long.\n",
      "\n",
      "## Generation start\n",
      "Output:\n",
      "Thoughts:  \n",
      "I need to produce a one-sentence bedtime story about a unicorn that is exactly ten words long. Ensuring the story remains magical, engaging, and suitable for a five-year-old is essential. I will carefully count the words in my response to meet the specified requirement and improve on clarity and enchantment.\n",
      "\n",
      "Response:  \n",
      "A magical unicorn flew over rainbows, spreading sweet dreams everywhere.\n",
      "\n",
      "## Evaluation start\n",
      "Status: FAIL\n",
      "Feedback: The response contains eleven words, which does not adhere to the requirement of being ten words or fewer. Additionally, while the story is age-appropriate and engaging, a more concise format should be pursued to meet the task specifications.\n",
      "\n",
      "## Generation start\n",
      "Output:\n",
      "Thoughts:  \n",
      "I understand that the task requires a one-sentence bedtime story about a unicorn that is exactly ten words long while being enchanting and suitable for a five-year-old girl. Previous attempts did not meet the word count requirement, so I will ensure to carefully count and keep the response concise and magical.\n",
      "\n",
      "Response:  \n",
      "A unicorn danced under stars, painting dreams in the sky.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "task = \"\"\"\n",
    "Write a one-sentence bedtime story about a unicorn, for a five year old girl\n",
    "\"\"\"\n",
    "\n",
    "GENERATOR_PROMPT = \"\"\"\n",
    "Your goal is to complete the task based on <user input>. If there are feedback\n",
    "from your previous generations, you should reflect on them to improve your solution\n",
    "\n",
    "Output your answer concisely in the following format:\n",
    "\n",
    "Thoughts:\n",
    "[Your understanding of the task and feedback and how you plan to improve]\n",
    "\n",
    "Response:\n",
    "[Your response here]\n",
    "\"\"\"\n",
    "\n",
    "def generate(task: str, generator_prompt: str, context: str=\"\") -> tuple[str, str]:\n",
    "    \"\"\"Generate and improve a solution based on feedback.\"\"\"\n",
    "    full_prompt = f\"{generator_prompt}\\n{context}\\nTask: {task}\" if context else f\"{generator_prompt}\\nTask: {task}\"\n",
    "\n",
    "    response = run_llm(full_prompt)\n",
    "\n",
    "    print(\"\\n## Generation start\")\n",
    "    print(f\"Output:\\n{response}\\n\")\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "EVALUATOR_PROMPT = \"\"\"\n",
    "Evaluate this following response for:\n",
    "1. age appropriateness\n",
    "2. is only ten words or fewer\n",
    "3. style and best practices\n",
    "\n",
    "You should be evaluating only and not attempting to solve the task.\n",
    "\n",
    "Only output \"PASS\" if all criteria are met and you have no further suggestions for improvements.\n",
    "\n",
    "Provide detailed feedback if there are areas that need improvement. You should specify what needs improvement and why.\n",
    "\n",
    "Return in this format:\n",
    "Status: [PASS/FAIL]\n",
    "Feedback: [Your feedback here]\n",
    "\"\"\"\n",
    "\n",
    "def evaluate(task: str, evaluator_prompt: str, generated_content: str) -> tuple[str, str]:\n",
    "    \"\"\"Evaluate if a solution meets requirements\"\"\"\n",
    "\n",
    "    full_prompt = f\"{evaluator_prompt}\\nOriginal task: {task}\\nContent to evaluate: {generated_content}\"\n",
    "\n",
    "    response = run_llm(full_prompt)\n",
    "\n",
    "    status_match = re.search(r\"Status:\\s*(.*?)(?:\\n|$)\", response, re.IGNORECASE)\n",
    "    feedback_match = re.search(r\"Feedback:\\s*([\\s\\S]*)\", response, re.IGNORECASE)\n",
    "\n",
    "    if status_match is None or feedback_match is None:\n",
    "        raise ValueError(\"Could not parse evaluation response. Expected format: 'Status: [PASS/FAIL]\\\\nFeedback: [feedback]'\")\n",
    "\n",
    "    evaluation = status_match.group(1).strip()\n",
    "    feedback = feedback_match.group(1).strip()\n",
    "\n",
    "    print(\"## Evaluation start\")\n",
    "    print(f\"Status: {evaluation}\")\n",
    "    print(f\"Feedback: {feedback}\")\n",
    "\n",
    "    return evaluation, feedback\n",
    "\n",
    "def loop_workflow(task: str, generator_prompt: str, evaluator_prompt: str, context: str = \"\") -> tuple[str, list[dict]]:\n",
    "    \"\"\"Keep generating and evaluating until the evaluator passes the last generated response.\"\"\"\n",
    "    memory = []\n",
    "\n",
    "    response = generate(task, generator_prompt)\n",
    "    memory.append(response)\n",
    "\n",
    "    max_iterations = 5\n",
    "    while max_iterations > 0:\n",
    "        evaluation, feedback = evaluate(task, evaluator_prompt, response)\n",
    "\n",
    "        if evaluation.upper() == \"PASS\":\n",
    "            return response\n",
    "\n",
    "        context = \"\\n\".join([\n",
    "            \"Previous attempts:\",\n",
    "            *[f\"- {m}\" for m in memory],\n",
    "            f\"\\nFeedback: {feedback}\"\n",
    "        ])\n",
    "        response = generate(task, generator_prompt, context)\n",
    "        memory.append(response)\n",
    "\n",
    "        max_iterations -= 1\n",
    "\n",
    "loop_workflow(task, GENERATOR_PROMPT, EVALUATOR_PROMPT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
