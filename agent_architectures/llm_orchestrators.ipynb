{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260cc488",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai pydantic nest-asyncio  upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f04ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d679a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import AsyncOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd0f0e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "952db6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncOpenAI()\n",
    "MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ffe06ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubTask(BaseModel):\n",
    "    name: str = Field(..., description=\"The name of the subtask\")\n",
    "    description: str = Field(..., description=\"The description of the subtask\")\n",
    "\n",
    "class OrchestratorOutput(BaseModel):\n",
    "    objective: str = Field(..., description=\"Summary of the coding task\")\n",
    "    subtasks: list[SubTask] = Field(..., description=\"List of subtasks to solve the coding task\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f54ec673",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORCHESTRATOR_PROMPT = \"\"\"\n",
    "You are a skilled software engineer.\n",
    "Read the coding problem and break it down into subtasks in JSON format.\n",
    "\n",
    "Problem:\n",
    "{problem}\n",
    "\n",
    "1. Summarize the objective of the task.\n",
    "2. List the subtasks needed to solve the task.\n",
    "3. Provide your answer in JSON format with fields:\n",
    "    - objective: str\n",
    "    - subtasks: List[SubTask], where each subtask includes:\n",
    "        - name: str (a short title for the subtask)\n",
    "        - description: str (a detailed description of the subtask)\n",
    "\"\"\"\n",
    "\n",
    "WORKER_PROMPT = \"\"\"\n",
    "You are a skilled software engineer.\n",
    "Read the subtask and generate code to solve the subtask.\n",
    "Subtask name : {name}\n",
    "Subtask description : {description}\n",
    "\n",
    "Return only the code. Do not include any other text or comments.\n",
    "Make sure that the code is valid Python code.\n",
    "\"\"\"\n",
    "\n",
    "AGGREGATOR_PROMPT = \"\"\"\n",
    "You are an experienced integrator of code.\n",
    "We have code snippets from different sub-tasks.\n",
    "Your job is the code snippets into a complete solution.\n",
    "Subtasks Code: \n",
    "{subtasks_code}\n",
    "\n",
    "Return only the complete code. Do not include any other text or comments.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b2d5383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "async def call_orchestrator(problem: str, model = MODEL) -> OrchestratorOutput:\n",
    "    prompt = ORCHESTRATOR_PROMPT.format(problem=problem)\n",
    "    \n",
    "    response = await client.beta.chat.completions.parse(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    raw_content = response.choices[0].message.content.strip()\n",
    "    \n",
    "    if raw_content.startswith(\"```json\"):\n",
    "        raw_content = raw_content[len(\"```json\"):].strip()\n",
    "    if raw_content.endswith(\"```\"):\n",
    "        raw_content = raw_content[:-len(\"```\")].strip()\n",
    "    \n",
    "    try:\n",
    "        parsed = json.loads(raw_content)\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(f\"JSON parsing error: {e.msg}\\nContent:\\n{raw_content}\")\n",
    "    \n",
    "    return OrchestratorOutput(**parsed)\n",
    "\n",
    "async def call_worker(name: str, description: str, model: str = MODEL) -> str:\n",
    "    prompt = WORKER_PROMPT.format(name=name, description=description)\n",
    "    response = await client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "async def call_aggregator(subtasks_code: str, model: str = MODEL) -> str:\n",
    "    prompt = AGGREGATOR_PROMPT.format(subtasks_code=subtasks_code)\n",
    "    response = await client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ba90fcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def orchestrator_worker_flow(problem: str, model: str = MODEL) -> str:\n",
    "    \n",
    "    orchestrator_output = await call_orchestrator(problem, model)\n",
    "\n",
    "    subtasks_code = await asyncio.gather(*[call_worker(subtask.name, subtask.description, model) for subtask in orchestrator_output.subtasks])\n",
    "\n",
    "    return await call_aggregator(subtasks_code, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "093b1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    problem = \"Create a Python script that reads a CSV file, processes the data and outputs a summary in JSON format. This solution should handle missing values gracefully and hightlight data anomalies.\"\n",
    "    final_code = await orchestrator_worker_flow(problem)\n",
    "    print(final_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "68af172b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import csv\n",
      "import json\n",
      "import os\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import unittest\n",
      "\n",
      "def read_csv_file(file_path):\n",
      "    with open(file_path, mode='r') as file:\n",
      "        csv_reader = csv.reader(file)\n",
      "        data = []\n",
      "        for row in csv_reader:\n",
      "            data.append(row)\n",
      "    return data\n",
      "\n",
      "def handle_missing_values(df, strategy='fill', fill_value=0):\n",
      "    if strategy == 'fill':\n",
      "        return df.fillna(fill_value)\n",
      "    elif strategy == 'remove':\n",
      "        return df.dropna()\n",
      "    elif strategy == 'interpolate':\n",
      "        return df.interpolate()\n",
      "    else:\n",
      "        raise ValueError(\"Invalid strategy. Use 'fill', 'remove', or 'interpolate'.\")\n",
      "\n",
      "def identify_anomalies(data, column, threshold=1.5):\n",
      "    Q1 = data[column].quantile(0.25)\n",
      "    Q3 = data[column].quantile(0.75)\n",
      "    IQR = Q3 - Q1\n",
      "    lower_bound = Q1 - (threshold * IQR)\n",
      "    upper_bound = Q3 + (threshold * IQR)\n",
      "    anomalies = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
      "    return anomalies\n",
      "\n",
      "def summarize_data(data):\n",
      "    summary = {}\n",
      "    \n",
      "    summary['mean'] = data.mean()\n",
      "    summary['median'] = data.median()\n",
      "    summary['std_dev'] = data.std()\n",
      "    summary['min'] = data.min()\n",
      "    summary['max'] = data.max()\n",
      "    \n",
      "    summary['missing_values'] = data.isnull().sum()\n",
      "    \n",
      "    anomalies = data[(data - summary['mean']).abs() > (3 * summary['std_dev'])]\n",
      "    summary['anomalies'] = anomalies.dropna()\n",
      "    \n",
      "    return summary\n",
      "\n",
      "def output_summary(summary, output_file=None):\n",
      "    json_summary = json.dumps(summary, indent=4)\n",
      "    \n",
      "    if output_file:\n",
      "        with open(output_file, 'w') as file:\n",
      "            file.write(json_summary)\n",
      "    else:\n",
      "        print(json_summary)\n",
      "\n",
      "def read_file(file_path):\n",
      "    try:\n",
      "        if not os.path.exists(file_path):\n",
      "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
      "        with open(file_path, 'r') as file:\n",
      "            data = file.readlines()\n",
      "        return data\n",
      "    except Exception as e:\n",
      "        print(f\"Error reading file: {e}\")\n",
      "        return None\n",
      "\n",
      "def process_data(data):\n",
      "    try:\n",
      "        if data is None or len(data) == 0:\n",
      "            raise ValueError(\"No data to process\")\n",
      "        processed = [line.strip() for line in data if line.strip()]\n",
      "        return processed\n",
      "    except Exception as e:\n",
      "        print(f\"Error processing data: {e}\")\n",
      "        return []\n",
      "\n",
      "def detect_anomalies(data):\n",
      "    try:\n",
      "        if not data:\n",
      "            raise ValueError(\"Data is empty for anomaly detection\")\n",
      "        anomalies = [item for item in data if not item.isnumeric()]\n",
      "        return anomalies\n",
      "    except Exception as e:\n",
      "        print(f\"Error detecting anomalies: {e}\")\n",
      "        return []\n",
      "\n",
      "def main(file_path):\n",
      "    data = read_file(file_path)\n",
      "    processed_data = process_data(data)\n",
      "    anomalies = detect_anomalies(processed_data)\n",
      "    if anomalies:\n",
      "        print(f\"Anomalies detected: {anomalies}\")\n",
      "    else:\n",
      "        print(\"No anomalies detected.\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main(\"data.txt\")\n",
      "\n",
      "class TestScriptFunctionality(unittest.TestCase):\n",
      "    def test_valid_input(self):\n",
      "        result = script_function([1, 2, 3, 4])\n",
      "        self.assertEqual(result, expected_output)\n",
      "\n",
      "    def test_missing_values(self):\n",
      "        result = script_function([1, None, 3, 4])\n",
      "        self.assertEqual(result, expected_output_with_missing)\n",
      "\n",
      "    def test_anomalies(self):\n",
      "        result = script_function([1, 2, -999, 4])\n",
      "        self.assertEqual(result, expected_output_with_anomaly)\n",
      "\n",
      "    def test_empty_input(self):\n",
      "        result = script_function([])\n",
      "        self.assertEqual(result, expected_output_empty)\n",
      "\n",
      "    def test_all_missing_values(self):\n",
      "        result = script_function([None, None])\n",
      "        self.assertEqual(result, expected_output_all_missing)\n",
      "\n",
      "    def test_large_numbers(self):\n",
      "        result = script_function([1e6, 2e6, 3e6])\n",
      "        self.assertEqual(result, expected_output_large_numbers)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    unittest.main()\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "def run_main():\n",
    "    asyncio.run(main())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import threading\n",
    "    thread = threading.Thread(target=run_main)\n",
    "    thread.start()\n",
    "    thread.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
