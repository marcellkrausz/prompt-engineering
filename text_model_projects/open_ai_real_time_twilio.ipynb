{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5480ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "import asyncio\n",
    "import websockets\n",
    "from fastapi import FastAPI, WebSocket, Request\n",
    "from fastapi.responses import HTMLResponse\n",
    "from fastapi.websockets import WebSocketDisconnect\n",
    "from twilio.twiml.voice_response import VoiceResponse, Connect # type: ignore\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "PORT = 5050\n",
    "\n",
    "SYSTEM_MESSAGE = (\n",
    "    \"You are a professional receptionist for a chartered surveyor's office. We offer a comprehensive range \"\n",
    "    \"of surveying services for both Commercial properties. Your role is to: \"\n",
    "    \"1. Determine if the inquiry is for Commercial or Residential property \"\n",
    "    \"2. Identify which of our services the client needs. We offer: \"\n",
    "    \"   - Rent reviews \"\n",
    "    \"   - Lease renewals \"\n",
    "    \"   - Property valuations \"\n",
    "    \"   - Building surveys \"\n",
    "    \"   - Dilapidations \"\n",
    "    \"   - Property management \"\n",
    "    \"   - Investment advice \"\n",
    "    \"3. Gather the following essential information: \"\n",
    "    \"   - Full name \"\n",
    "    \"   - Company name (or 'Independent' if none) \"\n",
    "    \"   - Position/Role \"\n",
    "    \"   - Phone number \"\n",
    "    \"   - Email address \"\n",
    "    \"   - Timeframe/Urgency of the request \"\n",
    "    \"   - How they found us (Source) \"\n",
    "    \"4. Once you have this information, tell them to send an email to info@phoenixandpartners.co.uk. If they ask for a phone number don't give them one. Then end the call. \"\n",
    "    \"\\nPlease be polite and professional, confirming that we do offer the service they need and asking \"\n",
    "    \"clear questions to categorize the inquiry correctly. If the inquiry doesn't fit into these categories, \"\n",
    "    \"acknowledge this and gather relevant information to pass on to our surveying team.\"\n",
    ")\n",
    "VOICE = 'alloy'\n",
    "LOG_EVENT_TYPES = [\n",
    "    'error', 'response.content.done', 'rate_limits.updated',\n",
    "    'response.done', 'input_audio_buffer.committed',\n",
    "    'input_audio_buffer.speech_stopped', 'input_audio_buffer.speech_started',\n",
    "    'session.created'\n",
    "]\n",
    "SHOW_TIMING_MATH = False\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError('Missing the OpenAI API key. Please set it in the .env file.')\n",
    "\n",
    "@app.get(\"/\", response_class=HTMLResponse)\n",
    "async def index_page():\n",
    "    return {\"message\": \"Twilio Media Stream Server is running!\"}\n",
    "\n",
    "@app.api_route(\"/incoming-call\", methods=[\"GET\", \"POST\"])\n",
    "async def handle_incoming_call(request: Request):\n",
    "    \"\"\"Handle incoming call and return TwiML response to connect to Media Stream.\"\"\"\n",
    "    response = VoiceResponse()\n",
    "    host = request.url.hostname\n",
    "    connect = Connect()\n",
    "    connect.stream(url=f'wss://{host}/media-stream')\n",
    "    response.append(connect)\n",
    "    return HTMLResponse(content=str(response), media_type=\"application/xml\")\n",
    "\n",
    "@app.websocket(\"/media-stream\")\n",
    "async def handle_media_stream(websocket: WebSocket):\n",
    "    \"\"\"Handle WebSocket connections between Twilio and OpenAI.\"\"\"\n",
    "    print(\"Client connected\")\n",
    "    await websocket.accept()\n",
    "\n",
    "    async with websockets.connect(\n",
    "        'wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01',\n",
    "        extra_headers={\n",
    "            \"Authorization\": f\"Bearer {OPENAI_API_KEY}\",\n",
    "            \"OpenAI-Beta\": \"realtime=v1\"\n",
    "        }\n",
    "    ) as openai_ws:\n",
    "        await initialize_session(openai_ws)\n",
    "\n",
    "        # Connection specific state\n",
    "        stream_sid = None\n",
    "        latest_media_timestamp = 0\n",
    "        last_assistant_item = None\n",
    "        mark_queue: list[str] = []\n",
    "        response_start_timestamp_twilio = None\n",
    "        \n",
    "        async def receive_from_twilio():\n",
    "            \"\"\"Receive audio data from Twilio and send it to the OpenAI Realtime API.\"\"\"\n",
    "            nonlocal stream_sid, latest_media_timestamp\n",
    "            try:\n",
    "                async for message in websocket.iter_text():\n",
    "                    data = json.loads(message)\n",
    "                    if data['event'] == 'media' and openai_ws.open:\n",
    "                        latest_media_timestamp = int(data['media']['timestamp'])\n",
    "                        audio_append = {\n",
    "                            \"type\": \"input_audio_buffer.append\",\n",
    "                            \"audio\": data['media']['payload']\n",
    "                        }\n",
    "                        await openai_ws.send(json.dumps(audio_append))\n",
    "                    elif data['event'] == 'start':\n",
    "                        stream_sid = data['start']['streamSid']\n",
    "                        print(f\"Incoming stream has started {stream_sid}\")\n",
    "                        response_start_timestamp_twilio = None\n",
    "                        latest_media_timestamp = 0\n",
    "                        last_assistant_item = None\n",
    "                    elif data['event'] == 'mark':\n",
    "                        if mark_queue:\n",
    "                            mark_queue.pop(0)\n",
    "            except WebSocketDisconnect:\n",
    "                print(\"Client disconnected.\")\n",
    "                if openai_ws.open:\n",
    "                    await openai_ws.close()\n",
    "\n",
    "        async def send_to_twilio():\n",
    "            \"\"\"Receive events from the OpenAI Realtime API, send audio back to Twilio.\"\"\"\n",
    "            nonlocal stream_sid, last_assistant_item, response_start_timestamp_twilio\n",
    "            try:\n",
    "                async for openai_message in openai_ws:\n",
    "                    response = json.loads(openai_message)\n",
    "                    if response['type'] in LOG_EVENT_TYPES:\n",
    "                        print(f\"Received event: {response['type']}\", response)\n",
    "\n",
    "                    if response.get('type') == 'response.audio.delta' and 'delta' in response:\n",
    "                        audio_payload = base64.b64encode(base64.b64decode(response['delta'])).decode('utf-8')\n",
    "                        audio_delta = {\n",
    "                            \"event\": \"media\",\n",
    "                            \"streamSid\": stream_sid,\n",
    "                            \"media\": {\n",
    "                                \"payload\": audio_payload\n",
    "                            }\n",
    "                        }\n",
    "                        await websocket.send_json(audio_delta)\n",
    "\n",
    "                        if response_start_timestamp_twilio is None:\n",
    "                            response_start_timestamp_twilio = latest_media_timestamp\n",
    "                            if SHOW_TIMING_MATH:\n",
    "                                print(f\"Setting start timestamp for new response: {response_start_timestamp_twilio}ms\")\n",
    "\n",
    "                        # Update last_assistant_item safely\n",
    "                        if response.get('item_id'):\n",
    "                            last_assistant_item = response['item_id']\n",
    "\n",
    "                        await send_mark(websocket, stream_sid)\n",
    "\n",
    "                    # Trigger an interruption. Your use case might work better using `input_audio_buffer.speech_stopped`, or combining the two.\n",
    "                    if response.get('type') == 'input_audio_buffer.speech_started':\n",
    "                        print(\"Speech started detected.\")\n",
    "                        if last_assistant_item:\n",
    "                            print(f\"Interrupting response with id: {last_assistant_item}\")\n",
    "                            await handle_speech_started_event()\n",
    "            except Exception as e:\n",
    "                print(f\"Error in send_to_twilio: {e}\")\n",
    "\n",
    "        async def handle_speech_started_event():\n",
    "            \"\"\"Handle interruption when the caller's speech starts.\"\"\"\n",
    "            nonlocal response_start_timestamp_twilio, last_assistant_item\n",
    "            print(\"Handling speech started event.\")\n",
    "            if mark_queue and response_start_timestamp_twilio is not None:\n",
    "                elapsed_time = latest_media_timestamp - response_start_timestamp_twilio\n",
    "                if SHOW_TIMING_MATH:\n",
    "                    print(f\"Calculating elapsed time for truncation: {latest_media_timestamp} - {response_start_timestamp_twilio} = {elapsed_time}ms\")\n",
    "\n",
    "                if last_assistant_item:\n",
    "                    if SHOW_TIMING_MATH:\n",
    "                        print(f\"Truncating item with ID: {last_assistant_item}, Truncated at: {elapsed_time}ms\")\n",
    "\n",
    "                    truncate_event = {\n",
    "                        \"type\": \"conversation.item.truncate\",\n",
    "                        \"item_id\": last_assistant_item,\n",
    "                        \"content_index\": 0,\n",
    "                        \"audio_end_ms\": elapsed_time\n",
    "                    }\n",
    "                    await openai_ws.send(json.dumps(truncate_event))\n",
    "\n",
    "                await websocket.send_json({\n",
    "                    \"event\": \"clear\",\n",
    "                    \"streamSid\": stream_sid\n",
    "                })\n",
    "\n",
    "                mark_queue.clear()\n",
    "                last_assistant_item = None\n",
    "                response_start_timestamp_twilio = None\n",
    "\n",
    "        async def send_mark(connection, stream_sid):\n",
    "            if stream_sid:\n",
    "                mark_event = {\n",
    "                    \"event\": \"mark\",\n",
    "                    \"streamSid\": stream_sid,\n",
    "                    \"mark\": {\"name\": \"responsePart\"}\n",
    "                }\n",
    "                await connection.send_json(mark_event)\n",
    "                mark_queue.append('responsePart')\n",
    "\n",
    "        await asyncio.gather(receive_from_twilio(), send_to_twilio())\n",
    "\n",
    "async def send_initial_conversation_item(openai_ws):\n",
    "    \"\"\"Send initial conversation item if AI talks first.\"\"\"\n",
    "    initial_conversation_item = {\n",
    "        \"type\": \"conversation.item.create\",\n",
    "        \"item\": {\n",
    "            \"type\": \"message\",\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"input_text\",\n",
    "                    \"text\": \"Greet the user with 'Hello there! I am an AI voice assistant powered by Twilio and the OpenAI Realtime API. You can ask me for facts, jokes, or anything you can imagine. How can I help you?'\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    await openai_ws.send(json.dumps(initial_conversation_item))\n",
    "    await openai_ws.send(json.dumps({\"type\": \"response.create\"}))\n",
    "\n",
    "\n",
    "async def initialize_session(openai_ws):\n",
    "    \"\"\"Control initial session with OpenAI.\"\"\"\n",
    "    session_update = {\n",
    "        \"type\": \"session.update\",\n",
    "        \"session\": {\n",
    "            \"turn_detection\": {\"type\": \"server_vad\"},\n",
    "            \"input_audio_format\": \"g711_ulaw\",\n",
    "            \"output_audio_format\": \"g711_ulaw\",\n",
    "            \"voice\": VOICE,\n",
    "            \"instructions\": SYSTEM_MESSAGE,\n",
    "            \"modalities\": [\"text\", \"audio\"],\n",
    "            \"temperature\": 0.8,\n",
    "        }\n",
    "    }\n",
    "    print('Sending session update:', json.dumps(session_update))\n",
    "    await openai_ws.send(json.dumps(session_update))\n",
    "\n",
    "    # Uncomment the next line to have the AI speak first\n",
    "    # await send_initial_conversation_item(openai_ws)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=PORT)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
