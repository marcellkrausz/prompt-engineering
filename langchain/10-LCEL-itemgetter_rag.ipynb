{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.20)\n",
      "Requirement already satisfied: langchain_openai in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.8)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.19)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (0.3.44)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_openai) (1.65.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (3.11.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (2.8.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community) (2.2.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.8)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain) (3.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>4->openai<2.0.0,>=1.58.1->langchain_openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain_openai langchain-community --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import (\n",
    "    RunnablePassthrough,\n",
    "    RunnableParallel,\n",
    "    RunnableLambda,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'origin': 1, 'modified': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'original': 'hello world', 'parsed': 'dlrow olleh'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable = RunnableParallel(\n",
    "    origin=RunnablePassthrough(),\n",
    "    modified=lambda x: x+1\n",
    ")\n",
    "\n",
    "print(runnable.invoke(1)) # {'origin': 1, 'modified': 2}\n",
    "\n",
    "\n",
    "def fake_llm(prompt: str) -> str: # Fake LLM for the example\n",
    "    return prompt + \" world\"\n",
    "\n",
    "chain = RunnableLambda(fake_llm) | {\n",
    "    'original': RunnablePassthrough(), # Original LLM output\n",
    "    'parsed': lambda text: text[::-1] # Parsing logic\n",
    "}\n",
    "\n",
    "chain.invoke('hello') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROMPT + MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Tell me a joke about {topic}'), additional_kwargs={})]) middle=[] last=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000163639EAD50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000163639EE5D0>, root_client=<openai.OpenAI object at 0x000001637EA16490>, root_async_client=<openai.AsyncOpenAI object at 0x00000163639EAE90>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********'))\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "prompt = ChatPromptTemplate.from_template('Tell me a joke about {topic}')\n",
    "\n",
    "chain = prompt | chat\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first input_variables=['topic'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Tell me a joke about {topic}'), additional_kwargs={})]\n",
      "last client=<openai.resources.chat.completions.completions.Completions object at 0x00000163639EAD50> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000163639EE5D0> root_client=<openai.OpenAI object at 0x000001637EA16490> root_async_client=<openai.AsyncOpenAI object at 0x00000163639EAE90> model_name='gpt-4o-mini' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "print(\"first\", chain.first)\n",
    "print(\"last\", chain.last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Stream:\n",
      "\n",
      "Why do bears never use cell phones?\n",
      "\n",
      "Because they always get stuck in \"bear\" reception!\n",
      "\n",
      "Invoke:\n",
      "\n",
      "Why do bears have hairy coats?\n",
      "\n",
      "Because they look silly in sweaters!\n",
      "\n",
      "\n",
      "Batch:\n",
      "\n",
      "[AIMessage(content='Why did the bear sit on a log?\\n\\nBecause it wanted to log its hours!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 13, 'total_tokens': 31, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_3267753c5d', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd458130-892e-483b-ae50-7fb1789f00e3-0', usage_metadata={'input_tokens': 13, 'output_tokens': 18, 'total_tokens': 31, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Why was the cat sitting on the computer?  \\n\\nBecause it wanted to keep an eye on the mouse! üê±üíª', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 13, 'total_tokens': 40, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-16825725-d943-46e1-a9d4-c2a6e2cb8874-0', usage_metadata={'input_tokens': 13, 'output_tokens': 27, 'total_tokens': 40, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content=\"Why did the dog sit in the shade? \\n\\nBecause he didn't want to become a hot dog!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 13, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-c2af2e59-e313-45ba-844e-1942243588f3-0', usage_metadata={'input_tokens': 13, 'output_tokens': 21, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
     ]
    }
   ],
   "source": [
    "# Stream:\n",
    "print('\\n\\nStream:\\n')\n",
    "for s in chain.stream({\"topic\": \"bears\"}):\n",
    "    print(s.content, end=\"\", flush=True)\n",
    "\n",
    "# Invoke:\n",
    "print('\\n\\nInvoke:\\n')\n",
    "print(chain.invoke({\"topic\": \"bears\"}).content)\n",
    "\n",
    "# Batch: \n",
    "print('\\n\\nBatch:\\n')\n",
    "print(chain.batch([{\"topic\": \"bears\"}, {\"topic\": \"cats\"}, {\"topic\": \"dogs\"}]))\n",
    "#this is the most const effective way to use the API. Multiple prompts are sent in a single request and multiple responses are returned in a single response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieval Augmented Generation (RAG) in LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain openai faiss-cpu tiktoken --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.vectorstores.faiss import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Facebook AI Similarity Search (FAISS) vector store\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"Marcell Krausz is learning data engineering and LLM at home.\", \"Marcell has an age of 31 years old.\"], embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "#minimize the hallucination by using the context\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model \n",
    "    | StrOutputParser() #parse the output\n",
    ")\n",
    "\n",
    "# It's the same as this, but the tuple allows for line breaks:\n",
    "# {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Marcell is learning data engineering and LLM at home.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What does Marcell learn at home?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Marcell's age is 31 years old.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What is Marcell's age?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operator.itemgetter({'data': ['This is a test', 'Another entry...']})\n",
      "['This is a test', 'Another entry...']\n"
     ]
    }
   ],
   "source": [
    "# How itemgetter works\n",
    "test = {\n",
    "    \"data\": ['This is a test', 'Another entry...']\n",
    "}\n",
    "\n",
    "print(itemgetter(test))\n",
    "print(itemgetter('data')(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Marcell Krausz is a Java Engineer.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template('''What is the profession of Marcell Krausz? His profession is {profession}.''')\n",
    "\n",
    "first_chain = RunnableParallel(\n",
    "    name=lambda x: \"Marcell Krausz\",\n",
    "    age=lambda x: 31\n",
    ")\n",
    "\n",
    "second_chain = {\n",
    "    # itemgetter is used to get the value from the dictionary from the previous step: (note this is only the previous step, not the whole chain)\n",
    "    'name': itemgetter('name'),\n",
    "    'age': itemgetter('age'),\n",
    "    # You can not use string values, either use itemgetter or a lambda, or RunnablePassthrough\n",
    "    'profession': lambda x: \"Java Engineer\"\n",
    "}\n",
    "\n",
    "chain = first_chain | second_chain |  prompt |  ChatOpenAI(model=\"gpt-4o-mini\") | StrOutputParser()\n",
    "chain.invoke({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
