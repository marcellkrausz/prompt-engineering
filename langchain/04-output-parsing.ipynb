{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the openai secret key:\n",
    "import getpass\n",
    "\n",
    "secret_key = getpass.getpass('Please enter your openai key:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(api_key=secret_key, model=\"gpt-4o-mini\", max_completion_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Joke(BaseModel):\n",
    "    joke: str = Field(description=\"The joke\")\n",
    "    punchline: str = Field(description=\"The punchline\")\n",
    "    \n",
    "class Jokes[BaseModel]:\n",
    "    jokes: List[Joke] = Field(description=\"A list of jokes\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=PromptTemplate(input_variables=['format_instructions', 'query'], input_types={}, partial_variables={}, template='Answer the user query.\\n{format_instructions}\\n{query}') additional_kwargs={}\n",
      "input_variables=['format_instructions', 'query'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_instructions', 'query'], input_types={}, partial_variables={}, template='Answer the user query.\\n{format_instructions}\\n{query}'), additional_kwargs={})]\n",
      "messages=[SystemMessage(content='Answer the user query.\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"joke\": {\"description\": \"The joke\", \"title\": \"Joke\", \"type\": \"string\"}, \"punchline\": {\"description\": \"The punchline\", \"title\": \"Punchline\", \"type\": \"string\"}}, \"required\": [\"joke\", \"punchline\"]}\\n```\\nTell me a really funny joke about pingvins?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "template = \"Answer the user query.\\n{format_instructions}\\n{query}\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt])\n",
    "\n",
    "print(system_message_prompt)\n",
    "print(chat_prompt)\n",
    "\n",
    "messages = chat_prompt.invoke({\n",
    "    \"query\": \"Tell me a really funny joke about pingvins?\",\n",
    "    \"format_instructions\": parser.get_format_instructions()\n",
    "})\n",
    "\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't penguins like talking to strangers at parties?\n",
      "Because they find it hard to break the ice!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    joke_object = parser.parse(result.content)\n",
    "    print(joke_object.joke)\n",
    "    print(joke_object.punchline)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm = model.with_structured_output(Joke)\n",
    "result = structured_llm.invoke(\"Tell me a really funny joke about pingvins?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They find it hard to break the ice!\n",
      "<class '__main__.Joke'>\n"
     ]
    }
   ],
   "source": [
    "print(result.punchline)\n",
    "print(type(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
